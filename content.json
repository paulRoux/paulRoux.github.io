{"meta":{"title":"Shirsen’s Blog","subtitle":"","description":"我思故我在......","author":"Shirsen","url":"http://roux.top"},"pages":[{"title":"About","date":"2017-10-08T15:26:29.000Z","updated":"2018-10-22T07:25:50.906Z","comments":false,"path":"about/index.html","permalink":"http://roux.top/about/index.html","excerpt":"","text":"Motto 天下古今之庸人，皆以一惰字致败；天下古今之人才，皆以一傲字致败。—曾国藩 Name&emsp;&emsp;CN：夏顺兴 (xiaShunXing) &emsp;&emsp;EN: Shirsen &emsp;&emsp;花名: 城歌 Rant&emsp;&emsp;2015.09 – 2019.07 &emsp;&emsp;西安理工大学&emsp;&emsp;2018.06 – 2018.09 &emsp;&emsp;阿里巴巴(实习)&emsp;&emsp;2019.07 – &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;阿里巴巴(准入职) &emsp;&emsp;喜欢折腾，对技术保持好奇心和探索欲，乐于与人交流与分享。&emsp;&emsp;喜欢一个人时听音乐、看书、练口琴，也喜欢和大家一起打打球。 Contact &emsp;&emsp;CSDN: Paul_roux &emsp;&emsp;掘金: Vkey &emsp;&emsp;GitHub: paulRoux &emsp;&emsp;网易云：Paul_roux &emsp;&emsp;Email: vkeyroux@gmail.com"},{"title":"书单","date":"2017-12-01T16:00:00.000Z","updated":"2018-10-23T14:39:55.231Z","comments":false,"path":"book/books.html","permalink":"http://roux.top/book/books.html","excerpt":"","text":"2018年 技术类 《剑指Offer》—强烈推荐 《编程之美》 《C++Primer》—在看 《Effective C++》—在看 《大话设计模式》—更推荐《设计模式之禅》 《操作系统——精髓与设计原理》—还是很不错的 《STL源码剖析》—在看 《Redis入门指南》—不太推荐 《C++沉思录》 《Python核心编程》—在看 《代码整洁之道》—还好 《Redis设计与实现》—在看 《STL源码剖析》—在看 《程序员修炼之道》—在看 文学类 《瓦尔登湖》 《伊豆的舞女》—计划看 《平凡的世界》—计划看 计划中 微服务 分布式 大数据 推荐算法 2017年 技术类 《程序员的自我修养》—强烈推荐 《跟阿铭学Linux》—命令较多 《计算机网络——谢希仁》—推荐 《C陷阱与缺陷》—复读 《C和指针》—强烈推荐 《C专家编程》—不错 《大话数据结构》—推荐(简单易懂) 《Unix网络编程卷1》—推荐 《Unix网络编程卷2》—推荐 《Unix环境高级编程》—建议作为第一本阅读 《Linux高性能服务器编程》—强烈推荐配合前面三本 《图解HTTP》—入门级别 文学类 《雪中悍刀行》—少有的江湖网文上乘之作 《剑来》—在看(连载中) 2016年 技术类 《Unix网络编程卷1》—未看完 《C陷阱与缺陷》—强烈推荐 《C语言程序设计》—电子版 《C语言深度剖析》—电子版 《数学之美》—强烈推荐 《啊哈！算法》—通俗易懂 文学类 《雪国》—细腻 《古都》—叙事技巧巧妙 《你要好好的爱自己》"},{"title":"留言","date":"2017-10-08T10:19:10.000Z","updated":"2018-04-21T11:07:52.405Z","comments":true,"path":"message/index.html","permalink":"http://roux.top/message/index.html","excerpt":"","text":"可以在下方留言区进行留言哦(^__^)"},{"title":"","date":"2018-05-09T15:04:23.828Z","updated":"2017-11-28T12:04:51.156Z","comments":true,"path":"photos/data.json","permalink":"http://roux.top/photos/data.json","excerpt":"","text":"{\"list\":[{\"date\":\"2017-11\",\"arr\":{\"month\":11,\"text\":[\"clock\",\"sword\",\"victory\"],\"year\":2017,\"link\":[\"2017-11-28_clock.jpg\",\"2017-11-28_sword.jpg\",\"2017-11-28_victory.jpg\"],\"type\":[\"image\",\"image\",\"image\"]}}]}"},{"title":"categories","date":"2017-10-08T10:22:47.000Z","updated":"2017-10-09T05:48:05.468Z","comments":false,"path":"categories/index.html","permalink":"http://roux.top/categories/index.html","excerpt":"","text":""},{"title":"相册","slug":"photos","date":"2018-05-09T15:03:19.660Z","updated":"2017-11-28T12:31:16.819Z","comments":false,"path":"photos/index.html","permalink":"http://roux.top/photos/index.html","excerpt":"","text":"Photos Videos 图片正在加载中… (function() { var loadScript = function(path) { var $script = document.createElement('script') document.getElementsByTagName('body')[0].appendChild($script) $script.setAttribute('src', path) } setTimeout(function() { loadScript('./ins.js') }, 0) })()"},{"title":"","date":"2018-05-09T15:03:19.600Z","updated":"2017-11-28T12:12:55.016Z","comments":true,"path":"photos/ins.css","permalink":"http://roux.top/photos/ins.css","excerpt":"","text":"#post-instagram{ padding: 30px; } #post-instagram .article-entry{ padding-right: 0; } .instagram{ position: relative; min-height: 500px; } .instagram img { width: 100%; } .instagram .year { font-size: 16px; } .instagram .open-ins{ padding: 10px 0; color: #cdcdcd; } .instagram .open-ins:hover{ color: #657b83; } .instagram .year{ display: inline; } .instagram .thumb { width: 25%; height: 0; padding-bottom: 25%; position: relative; display: inline-block; text-align: center; background: #ededed; outline: 1px solid #ddd; } .instagram .thumb a { position: relative; } .instagram .album h1 em{ font-style: normal; font-size: 14px; margin-left: 10px; } .instagram .album ul{ display: flex; flex-wrap: wrap; clear: both; width: 100%; text-align: left; } .instagram .album li{ list-style: none; display: inline-block; box-sizing: border-box; padding: 0 5px; margin-bottom: -10px; height: 0; width: 25%; position: relative; padding-bottom: 25%; } .instagram .album li:before{ display: none; } .instagram .album div.img-box{ position: absolute; width: 90%; height: 90%; -webkit-box-shadow: 0 1px 0 rgba(255,255,255,0.4), 0 1px 0 1px rgba(255,255,255,0.1); -moz-box-shadow: 0 1px 0 rgba(255,255,255,0.4), 0 1px 0 1px rgba(255,255,255,0.1); box-shadow: 0 1px 0 rgba(255,255,255,0.4), 0 1px 0 1px rgba(255,255,255,0.1); } .instagram .album div.img-box img{ width: 100%; height: 100%; position: absolute; z-index: 2; } .instagram .album div.img-box .img-bg{ position: absolute; top: 0; left: 0; bottom: 0px; width: 100%; margin: -5px; padding: 5px; -webkit-box-shadow: 0 0 0 1px rgba(0,0,0,.04), 0 1px 5px rgba(0,0,0,0.1); -moz-box-shadow: 0 0 0 1px rgba(0,0,0,.04), 0 1px 5px rgba(0,0,0,0.1); box-shadow: 0 0 0 1px rgba(0,0,0,.04), 0 1px 5px rgba(0,0,0,0.1); -webkit-transition: all 0.15s ease-out 0.1s; -moz-transition: all 0.15s ease-out 0.1s; -o-transition: all 0.15s ease-out 0.1s; transition: all 0.15s ease-out 0.1s; opacity: 0.2; cursor: pointer; display: block; z-index: 3; } .instagram .album div.img-box .icon { font-size: 14px; position: absolute; left: 50%; top: 50%; margin-left: -7px; margin-top: -7px; color: #999; z-index: 1; } .instagram .album div.img-box .img-bg:hover{ opacity: 0; } .photos-btn-wrap { border-bottom: 1px solid #e5e5e5; margin-bottom: 20px; } .photos-btn { font-size: 16px; color: #333; margin-bottom: -4px; padding: 5px 8px 3px; } .photos-btn.active { color: #08c; border: 1px solid #e5e5e5; border-bottom: 5px solid #fff; } /* ====== video ===== */ .video-container { z-index: 1; position: relative; padding-bottom: 56.25%; margin: 0 auto; } .video-container iframe, .video-container object, .video-container embed {z-index: 1;position: absolute;top: 0;left: 7%;width: 85%;height: 85%;box-shadow: 0px 0px 20px 2px #888888;} @media screen and (max-width:600px) { .instagram .thumb { width: 50%; padding-bottom: 50%; } .instagram .album li { width: 100%; position: relative; padding-bottom: 100%; text-align: center; } .instagram .album div.img-box{ margin: 0; width: 90%; height: 90%; } }"},{"title":"","date":"2018-05-09T15:04:21.508Z","updated":"2017-11-28T03:23:25.162Z","comments":true,"path":"photos/ins.js","permalink":"http://roux.top/photos/ins.js","excerpt":"","text":"/******/ (function(modules) { // webpackBootstrap /******/ // The module cache /******/ var installedModules = {}; /******/ /******/ // The require function /******/ function __webpack_require__(moduleId) { /******/ /******/ // Check if module is in cache /******/ if (installedModules[moduleId]) /******/ return installedModules[moduleId].exports; /******/ /******/ // Create a new module (and put it into the cache) /******/ var module = installedModules[moduleId] = { /******/ exports: {}, /******/ id: moduleId, /******/ loaded: false /******/ }; /******/ /******/ // Execute the module function /******/ modules[moduleId].call(module.exports, module, module.exports, __webpack_require__); /******/ /******/ // Flag the module as loaded /******/ module.loaded = true; /******/ /******/ // Return the exports of the module /******/ return module.exports; /******/ } /******/ /******/ /******/ // expose the modules object (__webpack_modules__) /******/ __webpack_require__.m = modules; /******/ /******/ // expose the module cache /******/ __webpack_require__.c = installedModules; /******/ /******/ // __webpack_public_path__ /******/ __webpack_require__.p = \"/dist/\"; /******/ /******/ // Load entry module and return exports /******/ return __webpack_require__(0); /******/ }) /************************************************************************/ /******/ ([ /* 0 */ /***/ function(module, exports, __webpack_require__) { 'use strict'; __webpack_require__(1); var _view = __webpack_require__(2); var _view2 = _interopRequireDefault(_view); function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; } /** * @name impush-client * @description 这个项目让我发家致富… * @date 2016-12-1 */ var _collection = []; var _count = 0; var searchData; function addMask(elem) { var rect = elem.getBoundingClientRect(); var style = getComputedStyle(elem, null); var mask = document.createElement('i'); mask.className = 'icon-film'; mask.style.color = '#fff'; mask.style.fontSize = '26px'; mask.style.position = 'absolute'; mask.style.right = '10px'; mask.style.bottom = '10px'; mask.style.zIndex = 1; elem.parentNode.appendChild(mask); } var createVideoIncon = function createVideoIncon() { var $videoImg = document.querySelectorAll('.thumb a[data-type=\"video\"]'); for (var i = 0, len = $videoImg.length; i < len; i++) { addMask($videoImg[i]); } }; var render = function render(res) { var ulTmpl = \"\"; for (var j = 0, len2 = res.list.length; j < len2; j++) { var data = res.list[j].arr; var liTmpl = \"\"; for (var i = 0, len = data.link.length; i < len; i++) { var minSrc = 'https://raw.githubusercontent.com/paulRoux/blog_pic/master/min_photos/' + data.link[i]; var src = 'https://raw.githubusercontent.com/paulRoux/blog_pic/master/photos/' + data.link[i]; var type = data.type[i]; var target = src + (type === 'video' ? '.mp4' : '.jpg'); src += ''; liTmpl += '\\ \\ \\ \\ ' + data.text[i] + '\\ '; } ulTmpl = ulTmpl + '' + data.year + '年' + data.month + '月\\ ' + liTmpl + '\\ '; } document.querySelector('.instagram').innerHTML = '' + ulTmpl + ''; createVideoIncon(); _view2.default.init(); }; var replacer = function replacer(str) { var arr = str.split(\"/\"); return \"/assets/ins/\" + arr[arr.length - 1]; }; var ctrler = function ctrler(data) { var imgObj = {}; for (var i = 0, len = data.length; i < len; i++) { var y = data[i].y; var m = data[i].m; var src = replacer(data[i].src); var text = data[i].text; var key = y + \"\" + ((m + \"\").length == 1 ? \"0\" + m : m); if (imgObj[key]) { imgObj[key].srclist.push(src); imgObj[key].text.push(text); } else { imgObj[key] = { year: y, month: m, srclist: [src], text: [text] }; } } render(imgObj); }; function loadData(success) { if (!searchData) { var xhr = new XMLHttpRequest(); xhr.open('GET', './data.json?t=' + +new Date(), true); xhr.onload = function() { if (this.status >= 200 && this.status < 300) { var res = JSON.parse(this.response); searchData = res; success(searchData); } else { console.error(this.statusText); } }; xhr.onerror = function() { console.error(this.statusText); }; xhr.send(); } else { success(searchData); } } var Ins = { init: function init() { loadData(function(data) { render(data); }); } }; Ins.init(); // export default impush; /***/ }, /* 1 */ /***/ function(module, exports, __webpack_require__) { /* WEBPACK VAR INJECTION */ (function(global) { 'use strict'; var inViewport = __webpack_require__(3); var lazyAttrs = ['data-src']; global.lzld = lazyload(); // Provide libs using getAttribute early to get the good src // and not the fake data-src replaceGetAttribute('Image'); replaceGetAttribute('IFrame'); function registerLazyAttr(attr) { if (indexOf.call(lazyAttrs, attr) === -1) { lazyAttrs.push(attr); } } function lazyload(opts) { opts = merge({ 'offset': 333, 'src': 'data-src', 'container': false }, opts || {}); if (typeof opts.src === 'string') { registerLazyAttr(opts.src); } var elts = []; function show(elt) { var src = findRealSrc(elt); if (src) { elt.src = src; } elt.setAttribute('data-lzled', true); elts[indexOf.call(elts, elt)] = null; } function findRealSrc(elt) { if (typeof opts.src === 'function') { return opts.src(elt); } return elt.getAttribute(opts.src); } function register(elt) { elt.onload = null; elt.removeAttribute('onload'); elt.onerror = null; elt.removeAttribute('onerror'); if (indexOf.call(elts, elt) === -1) { inViewport(elt, opts, show); } } return register; } function replaceGetAttribute(elementName) { var fullname = 'HTML' + elementName + 'Element'; if (fullname in global === false) { return; } var original = global[fullname].prototype.getAttribute; global[fullname].prototype.getAttribute = function(name) { if (name === 'src') { var realSrc; for (var i = 0, max = lazyAttrs.length; i < max; i++) { realSrc = original.call(this, lazyAttrs[i]); if (realSrc) { break; } } return realSrc || original.call(this, name); } // our own lazyloader will go through theses lines // because we use getAttribute(opts.src) return original.call(this, name); }; } function merge(defaults, opts) { for (var name in defaults) { if (opts[name] === undefined) { opts[name] = defaults[name]; } } return opts; } // http://webreflection.blogspot.fr/2011/06/partial-polyfills.html function indexOf(value) { for (var i = this.length; i-- && this[i] !== value;) {} return i; } module.exports = lazyload; // export default impush; /* WEBPACK VAR INJECTION */ }.call(exports, (function() { return this; }()))) /***/ }, /* 2 */ /***/ function(module, exports) { 'use strict'; var initPhotoSwipeFromDOM = function initPhotoSwipeFromDOM(gallerySelector) { // parse slide data (url, title, size ...) from DOM elements // (children of gallerySelector) var parseThumbnailElements = function parseThumbnailElements(el) { el = el.parentNode.parentNode; var thumbElements = el.getElementsByClassName('thumb'), numNodes = thumbElements.length, items = [], figureEl, linkEl, size, type, // video or not target, item; for (var i = 0; i < numNodes; i++) { figureEl = thumbElements[i]; // // include only element nodes if (figureEl.nodeType !== 1) { continue; } linkEl = figureEl.children[0]; // size = linkEl.getAttribute('data-size').split('x'); type = linkEl.getAttribute('data-type'); target = linkEl.getAttribute('data-target'); // create slide object item = { src: linkEl.getAttribute('href'), w: parseInt(size[0], 10), h: parseInt(size[1], 10) }; if (figureEl.children.length > 1) { item.title = figureEl.children[1].innerHTML; } if (linkEl.children.length > 0) { item.msrc = linkEl.children[0].getAttribute('src'); item.type = type; item.target = target; item.html = ''; if (type === 'video') { //item.src = null; } } item.el = figureEl; // save link to element for getThumbBoundsFn items.push(item); } return items; }; // find nearest parent element var closest = function closest(el, fn) { return el && (fn(el) ? el : closest(el.parentNode, fn)); }; // triggers when user clicks on thumbnail var onThumbnailsClick = function onThumbnailsClick(e) { e = e || window.event; e.preventDefault ? e.preventDefault() : e.returnValue = false; var eTarget = e.target || e.srcElement; // find root element of slide var clickedListItem = closest(eTarget, function(el) { return el.tagName && el.tagName.toUpperCase() === 'FIGURE'; }); if (!clickedListItem) { return; } // find index of clicked item by looping through all child nodes // alternatively, you may define index via data- attribute var clickedGallery = clickedListItem.parentNode, // childNodes = clickedListItem.parentNode.childNodes, // numChildNodes = childNodes.length, childNodes = document.getElementsByClassName('thumb'), numChildNodes = childNodes.length, nodeIndex = 0, index; for (var i = 0; i < numChildNodes; i++) { if (childNodes[i].nodeType !== 1) { continue; } if (childNodes[i] === clickedListItem) { index = nodeIndex; break; } nodeIndex++; } if (index >= 0) { // open PhotoSwipe if valid index found openPhotoSwipe(index, clickedGallery); } return false; }; // parse picture index and gallery index from URL (#&pid=1&gid=2) var photoswipeParseHash = function photoswipeParseHash() { var hash = window.location.hash.substring(1), params = {}; if (hash.length < 5) { return params; } var vars = hash.split('&'); for (var i = 0; i < vars.length; i++) { if (!vars[i]) { continue; } var pair = vars[i].split('='); if (pair.length < 2) { continue; } params[pair[0]] = pair[1]; } if (params.gid) { params.gid = parseInt(params.gid, 10); } return params; }; var openPhotoSwipe = function openPhotoSwipe(index, galleryElement, disableAnimation, fromURL) { var pswpElement = document.querySelectorAll('.pswp')[0], gallery, options, items; items = parseThumbnailElements(galleryElement); // define options (if needed) options = { // define gallery index (for URL) galleryUID: galleryElement.getAttribute('data-pswp-uid'), getThumbBoundsFn: function getThumbBoundsFn(index) { // See Options -> getThumbBoundsFn section of documentation for more info var thumbnail = items[index].el.getElementsByTagName('img')[0], // find thumbnail pageYScroll = window.pageYOffset || document.documentElement.scrollTop, rect = thumbnail.getBoundingClientRect(); return { x: rect.left, y: rect.top + pageYScroll, w: rect.width }; } }; // PhotoSwipe opened from URL if (fromURL) { if (options.galleryPIDs) { // parse real index when custom PIDs are used // http://photoswipe.com/documentation/faq.html#custom-pid-in-url for (var j = 0; j < items.length; j++) { if (items[j].pid == index) { options.index = j; break; } } } else { // in URL indexes start from 1 options.index = parseInt(index, 10) - 1; } } else { options.index = parseInt(index, 10); } // exit if index not found if (isNaN(options.index)) { return; } if (disableAnimation) { options.showAnimationDuration = 0; } // Pass data to PhotoSwipe and initialize it gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, options); gallery.init(); var $tempVideo; var stopVideoHandle = function stopVideoHandle() { if ($tempVideo) { $tempVideo.remove(); $tempVideo = null; } }; var changeHandle = function changeHandle() { var item = gallery.currItem; stopVideoHandle(); if (item.type === 'video') { var $ctn = item.container; var style = $ctn.getElementsByClassName('pswp__img')[0].style; var $video = document.createElement('video'); $video.setAttribute('autoplay', 'autoplay'); $video.setAttribute('controls', 'controls'); $video.setAttribute('src', item.target); $video.style.width = style.width; $video.style.height = style.height; $video.style.position = 'absolute'; $video.style.zIndex = 2; $tempVideo = $video; $ctn.appendChild($video); } }; gallery.listen('initialZoomIn', changeHandle); gallery.listen('afterChange', changeHandle); gallery.listen('initialZoomOut', stopVideoHandle); }; // loop through all gallery elements and bind events var galleryElements = document.querySelectorAll(gallerySelector); for (var i = 0, l = galleryElements.length; i < l; i++) { galleryElements[i].setAttribute('data-pswp-uid', i + 1); galleryElements[i].onclick = onThumbnailsClick; } // Parse URL and open gallery if it contains #&pid=3&gid=1 var hashData = photoswipeParseHash(); if (hashData.pid && hashData.gid) { openPhotoSwipe(hashData.pid, galleryElements[hashData.gid - 1], true, true); } }; var Viewer = function() { function init() { initPhotoSwipeFromDOM('.photos'); } return { init: init }; }(); module.exports = Viewer; /***/ }, /* 3 */ /***/ function(module, exports) { /* WEBPACK VAR INJECTION */ (function(global) { module.exports = inViewport; var instances = []; var supportsMutationObserver = typeof global.MutationObserver === 'function'; function inViewport(elt, params, cb) { var opts = { container: global.document.body, offset: 0 }; if (params === undefined || typeof params === 'function') { cb = params; params = {}; } var container = opts.container = params.container || opts.container; var offset = opts.offset = params.offset || opts.offset; for (var i = 0; i < instances.length; i++) { if (instances[i].container === container) { return instances[i].isInViewport(elt, offset, cb); } } return instances[ instances.push(createInViewport(container)) - 1 ].isInViewport(elt, offset, cb); } function addEvent(el, type, fn) { if (el.attachEvent) { el.attachEvent('on' + type, fn); } else { el.addEventListener(type, fn, false); } } function debounce(func, wait, immediate) { var timeout; return function() { var context = this, args = arguments; var callNow = immediate && !timeout; clearTimeout(timeout); timeout = setTimeout(later, wait); if (callNow) func.apply(context, args); function later() { timeout = null; if (!immediate) func.apply(context, args); } }; } // https://github.com/jquery/sizzle/blob/3136f48b90e3edc84cbaaa6f6f7734ef03775a07/sizzle.js#L708 var contains = function() { if (!global.document) { return true; } return global.document.documentElement.compareDocumentPosition ? function(a, b) { return !!(a.compareDocumentPosition(b) & 16); } : global.document.documentElement.contains ? function(a, b) { return a !== b && (a.contains ? a.contains(b) : false); } : function(a, b) { while (b = b.parentNode) { if (b === a) { return true; } } return false; }; } function createInViewport(container) { var watches = createWatches(); var scrollContainer = container === global.document.body ? global : container; var debouncedCheck = debounce(watches.checkAll(watchInViewport), 15); addEvent(scrollContainer, 'scroll', debouncedCheck); if (scrollContainer === global) { addEvent(global, 'resize', debouncedCheck); } if (supportsMutationObserver) { observeDOM(watches, container, debouncedCheck); } // failsafe check, every 200ms we check for visible images // usecase: a hidden parent containing eleements // when the parent becomes visible, we have no event that the children // became visible setInterval(debouncedCheck, 150); function isInViewport(elt, offset, cb) { if (!cb) { return isVisible(elt, offset); } var remote = createRemote(elt, offset, cb); remote.watch(); return remote; } function createRemote(elt, offset, cb) { function watch() { watches.add(elt, offset, cb); } function dispose() { watches.remove(elt); } return { watch: watch, dispose: dispose }; } function watchInViewport(elt, offset, cb) { if (isVisible(elt, offset)) { watches.remove(elt); cb(elt); } } function isVisible(elt, offset) { if (!contains(global.document.documentElement, elt) || !contains(global.document.documentElement, container)) { return false; } // Check if the element is visible // https://github.com/jquery/jquery/blob/740e190223d19a114d5373758127285d14d6b71e/src/css/hiddenVisibleSelectors.js if (!elt.offsetWidth || !elt.offsetHeight) { return false; } var eltRect = elt.getBoundingClientRect(); var viewport = {}; if (container === global.document.body) { viewport = { top: -offset, left: -offset, right: global.document.documentElement.clientWidth + offset, bottom: global.document.documentElement.clientHeight + offset }; } else { var containerRect = container.getBoundingClientRect(); viewport = { top: containerRect.top - offset, left: containerRect.left - offset, right: containerRect.right + offset, bottom: containerRect.bottom + offset }; } // The element must overlap with the visible part of the viewport var visible = ( (eltRect.right > viewport.left) && (eltRect.left < viewport.right) && (eltRect.bottom > viewport.top) && (eltRect.top < viewport.bottom) ); return visible; } return { container: container, isInViewport: isInViewport }; } function createWatches() { var watches = []; function add(elt, offset, cb) { if (!isWatched(elt)) { watches.push([elt, offset, cb]); } } function remove(elt) { var pos = indexOf(elt); if (pos !== -1) { watches.splice(pos, 1); } } function indexOf(elt) { for (var i = watches.length - 1; i >= 0; i--) { if (watches[i][0] === elt) { return i; } } return -1; } function isWatched(elt) { return indexOf(elt) !== -1; } function checkAll(cb) { return function() { for (var i = watches.length - 1; i >= 0; i--) { cb.apply(this, watches[i]); } }; } return { add: add, remove: remove, isWatched: isWatched, checkAll: checkAll }; } function observeDOM(watches, container, cb) { var observer = new MutationObserver(watch); var filter = Array.prototype.filter; var concat = Array.prototype.concat; observer.observe(container, { childList: true, subtree: true, // changes like style/width/height/display will be catched attributes: true }); function watch(mutations) { // some new DOM nodes where previously watched // we should check their positions if (mutations.some(knownNodes) === true) { setTimeout(cb, 0); } } function knownNodes(mutation) { var nodes = concat.call([], Array.prototype.slice.call(mutation.addedNodes), mutation.target ); return filter.call(nodes, watches.isWatched).length > 0; } } /* WEBPACK VAR INJECTION */ }.call(exports, (function() { return this; }()))) /***/ } /******/ ]);"},{"title":"相册","slug":"photos","date":"2018-05-09T15:03:19.680Z","updated":"2017-11-28T13:46:22.423Z","comments":false,"path":"photos/videos.html","permalink":"http://roux.top/photos/videos.html","excerpt":"","text":"Photos Videos 遇见你在最美的流年"},{"title":"","date":"2018-05-09T15:04:21.708Z","updated":"2017-11-13T15:21:36.000Z","comments":true,"path":"photos/lazyload.min.js","permalink":"http://roux.top/photos/lazyload.min.js","excerpt":"","text":"/*! * An jQuery | zepto plugin for lazy loading images. * author -> jieyou * see https://github.com/jieyou/lazyload * use some tuupola's code https://github.com/tuupola/jquery_lazyload (BSD) * use component's throttle https://github.com/component/throttle (MIT) */ !function(a){\"function\"==typeof define&&define.amd?define([\"jquery\"],a):a(window.jQuery||window.Zepto)}(function(a){function g(){}function h(a,b){var e;return e=b._$container==d?(\"innerHeight\"in c?c.innerHeight:d.height())+d.scrollTop():b._$container.offset().top+b._$container.height(),e=a.offset().top+b.threshold+a.height()}function k(b,e){var f;return f=e._$container==d?a.fn.scrollLeft?d.scrollLeft():c.pageXOffset:e._$container.offset().left,f>=b.offset().left+e.threshold+b.width()}function l(a,b){var c=0;a.each(function(d){function g(){f.trigger(\"_lazyload_appear\"),c=0}var f=a.eq(d);if(!(f.width()b.failure_limit)return!1}else g()})}function m(a){return a.filter(function(b){return!a.eq(b)._lazyload_loadStarted})}function n(a,b){function h(){f=0,g=+new Date,e=a.apply(c,d),c=null,d=null}var c,d,e,f,g=0;return function(){c=this,d=arguments;var a=new Date-g;return f||(a>=b?h():f=setTimeout(h,b-a)),e}}var f,c=window,d=a(c),e={threshold:0,failure_limit:0,event:\"scroll\",effect:\"show\",effect_params:null,container:c,data_attribute:\"original\",data_srcset_attribute:\"original-srcset\",skip_invisible:!0,appear:g,load:g,vertical_only:!1,check_appear_throttle_time:300,url_rewriter_fn:g,no_fake_img_loader:!1,placeholder_data_img:\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsQAAA7EAZUrDhsAAAANSURBVBhXYzh8+PB/AAffA0nNPuCLAAAAAElFTkSuQmCC\",placeholder_real_img:\"http://ditu.baidu.cn/yyfm/lazyload/0.0.1/img/placeholder.png\"};f=function(){var a=Object.prototype.toString;return function(b){return a.call(b).replace(\"[object \",\"\").replace(\"]\",\"\")}}(),a.fn.hasOwnProperty(\"lazyload\")||(a.fn.lazyload=function(b){var i,j,k,h=this;return a.isPlainObject(b)||(b={}),a.each(e,function(g,h){var i=f(b[g]);-1!=a.inArray(g,[\"threshold\",\"failure_limit\",\"check_appear_throttle_time\"])?\"String\"==i?b[g]=parseInt(b[g],10):\"Number\"!=i&&(b[g]=h):\"container\"==g?(b._$container=b.hasOwnProperty(g)?b[g]==c||b[g]==document?d:a(b[g]):d,delete b.container):!e.hasOwnProperty(g)||b.hasOwnProperty(g)&&i==f(e[g])||(b[g]=h)}),i=\"scroll\"==b.event,k=0==b.check_appear_throttle_time?l:n(l,b.check_appear_throttle_time),j=i||\"scrollstart\"==b.event||\"scrollstop\"==b.event,h.each(function(c){var e=this,f=h.eq(c),i=f.attr(\"src\"),k=f.attr(\"data-\"+b.data_attribute),l=b.url_rewriter_fn==g?k:b.url_rewriter_fn.call(e,f,k),n=f.attr(\"data-\"+b.data_srcset_attribute),o=f.is(\"img\");return 1==f._lazyload_loadStarted||i==l?(f._lazyload_loadStarted=!0,h=m(h),void 0):(f._lazyload_loadStarted=!1,o&&!i&&f.one(\"error\",function(){f.attr(\"src\",b.placeholder_real_img)}).attr(\"src\",b.placeholder_data_img),f.one(\"_lazyload_appear\",function(){function i(){d&&f.hide(),o?(n&&f.attr(\"srcset\",n),l&&f.attr(\"src\",l)):f.css(\"background-image\",'url(\"'+l+'\")'),d&&f[b.effect].apply(f,c?b.effect_params:[]),h=m(h)}var d,c=a.isArray(b.effect_params);f._lazyload_loadStarted||(d=\"show\"!=b.effect&&a.fn[b.effect]&&(!b.effect_params||c&&0==b.effect_params.length),b.appear!=g&&b.appear.call(e,f,h.length,b),f._lazyload_loadStarted=!0,b.no_fake_img_loader||n?(b.load!=g&&f.one(\"load\",function(){b.load.call(e,f,h.length,b)}),i()):a(\"\").one(\"load\",function(){i(),b.load!=g&&b.load.call(e,f,h.length,b)}).attr(\"src\",l))}),j||f.on(b.event,function(){f._lazyload_loadStarted||f.trigger(\"_lazyload_appear\")}),void 0)}),j&&b._$container.on(b.event,function(){k(h,b)}),d.on(\"resize load\",function(){k(h,b)}),a(function(){k(h,b)}),this})});"},{"title":"tags","date":"2017-10-08T10:19:10.000Z","updated":"2017-10-09T07:31:27.908Z","comments":false,"path":"tags/index.html","permalink":"http://roux.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"不将就","slug":"不将就","date":"2018-10-23T16:00:00.000Z","updated":"2018-10-24T10:23:59.467Z","comments":true,"path":"2018/10/24/不将就/","link":"","permalink":"http://roux.top/2018/10/24/不将就/","excerpt":"&emsp;&emsp;对最近的一段时间进行梳理。","text":"&emsp;&emsp;对最近的一段时间进行梳理。 &emsp;&emsp;自从实习结束并回到学校后，持续过了一个月的“闲人”生活，期间，中秋结束后和好基友张越完成了为期11天的旅游，欣赏了这个世界的美丽(当然包括小姐姐们，享受脸.jpg)，也享受了各种美食，很开心(很感谢我儿子一路上的规划，简直完美）。&emsp;&emsp;国庆节后，开始阅读技术书籍，同时参与一些分享活动。期间，身边人也都找陆续结束，各种玩耍，各种皮。关于女朋友这事也被提及的越来越多，自己也想了想，的确是在很多难过或者困难的时候，有个人在一起陪伴或者安慰都是极棒的，这也导致我曾经一度想找个就这样将就了。不过对自己生活的不满意，对自己要求的提升，让我觉得这算是对生活的一种妥协，我还年轻，还有机会去尝试，所以不能轻易妥协。&emsp;&emsp;现在，努力提升自己，让自己过得精致一点，多多投资自己，保持一种态度：对生活，不将就！","categories":[{"name":"生活","slug":"生活","permalink":"http://roux.top/categories/生活/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://roux.top/tags/随笔/"}]},{"title":"实习总结","slug":"实习总结","date":"2018-08-30T16:00:00.000Z","updated":"2018-10-24T13:44:55.920Z","comments":true,"path":"2018/08/31/实习总结/","link":"","permalink":"http://roux.top/2018/08/31/实习总结/","excerpt":"&emsp;&emsp;work hard， work smart！","text":"&emsp;&emsp;work hard， work smart！ &emsp;&emsp;不知不觉三个月的实习就结束了，也许只有到最后要走的时候才会真正的感受到一些别样的情绪充斥在心间。感谢这段时间师兄师姐们的指导与帮助，也很开心能够遇见这么多的小伙伴！&emsp;&emsp;最终得知转正的结果还是很开心的，后面呢，也准备留在阿里了。以这段时间的感受来说：阿里是一家很有责任感的公司、公司内部的腐败程度个人感觉还是较其他公司好的、阿里的价值观我表示认同、最主要的是身边的小伙伴们都很nice。感觉这里面的环境很适合我，个人也比较懒，也就不想再换公司了（换公司的话，这种环境很难说）&emsp;&emsp;实习期间学到的东西还是很多的，主要是开了眼界，思想上有了相应的提升，对大公司的流程什么的都有了了解，而且对自己后面的方向也能够做出一些选择。","categories":[{"name":"生活","slug":"生活","permalink":"http://roux.top/categories/生活/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://roux.top/tags/随笔/"}]},{"title":"Vmware的一些问题","slug":"Vmware的一些问题","date":"2018-05-09T16:00:00.000Z","updated":"2018-05-18T08:40:15.531Z","comments":true,"path":"2018/05/10/Vmware的一些问题/","link":"","permalink":"http://roux.top/2018/05/10/Vmware的一些问题/","excerpt":"前言 前几天换了个电脑，于是所有的东西都需要拷贝和重装，在装vmware的时候遇到了一些问题，所以记录在这里。","text":"前言 前几天换了个电脑，于是所有的东西都需要拷贝和重装，在装vmware的时候遇到了一些问题，所以记录在这里。 操作系统 windows7 可以安装任何的版本，而且安装所有的系统都是没问题的。要注意的就是对vmware的服务要保持开启，给centos7安装vmtools的时候有点麻烦。这里注意的没有什么太多。 windows10 这里的话在安装vmware的时候需要安装vmware12及以上的版本，官方给的说明是11的时候就开始支持windows10了，但是我在装ubuntu16.04的时候直接报错导致安装失败，之后我使用12版本的直接成功。在这里需要注意的是在装系统的时候需要把硬件定制里面的显示的3D图形加速关闭，否则会出现黑屏的现象。如果ubuntu出现屏幕分辨率的问题导致无法点击安装过程中的确认或者下一步按钮的情况，可以先试用，然后选择设置修改分辨率，让其适合当前的分辨率，然后再次进入就可以看到和选择了。 由于中间有一次直接用杀毒软件结束掉了VMware，导致我在下一次打开ubuntu的时候显示正在使用中，用了其他的一些方法也都没解决，最终找到一个方法简单粗暴：找到安装操作系统的目录，进去后会看到两个后缀为.lck的文件夹，把这两个文件夹剪切出来（删除掉也可以，你打开以后会重建），然后再打开虚拟机就没问题了。具体的原因还没去了解。","categories":[{"name":"Tools","slug":"Tools","permalink":"http://roux.top/categories/Tools/"}],"tags":[{"name":"VMware","slug":"VMware","permalink":"http://roux.top/tags/VMware/"}]},{"title":"HTTP1.0与HTTP1.1","slug":"HTTP1.0与HTTP1.1","date":"2018-04-21T16:00:00.000Z","updated":"2018-04-22T12:26:10.026Z","comments":true,"path":"2018/04/22/HTTP1.0与HTTP1.1/","link":"","permalink":"http://roux.top/2018/04/22/HTTP1.0与HTTP1.1/","excerpt":"前言 前面的系列文章最终感觉有点零散，所以在这里将HTTP1.0和HTTP1.1的一些区别进行说明。","text":"前言 前面的系列文章最终感觉有点零散，所以在这里将HTTP1.0和HTTP1.1的一些区别进行说明。 区别 可扩展性 为了与未来的协议规范兼容，HTTP1.1在请求消息中包含了Upgrade头域，客户端可以让服务器知道它能够支持的其他备用通信协议，服务器以此进行协议的切换 HTTP1.1增加了options方法，允许客户端获取服务器支持的方法列表 在消息中增加版本号，用来进行兼容判断。此版本号只可以判断逐段的兼容性，不能判断端到端的兼容性 eg：一台HTTP/1.1的源服务器从使用HTTP/1.1的Proxy那儿接收到一条转发的消息，实际上源服务器并不知道终端客户使用的是HTTP/1.0还是HTTP/1.1。因此，HTTP/1.1定义Via头域，用来记录消息转发的路径，它记录了整个路径上所有发送方使用的版本号 缓存 HTTP1.1在1.0的特性上加了一些cache的特性：当缓存的对象的age超过expire（最大时限）时变为stale（旧的）对象，cache不需要直接抛弃此对象，而是与服务器进行重新激活 HTTP1.1增加了Cache-Control头域（请求消息和响应消息都可用），它支持一个可扩展的指令子集：例如max-age指令支持相对时间戳；private和no-store指令禁止对象被缓存；no-transform阻止Proxy进行任何改变响应的行为 带宽优化 请求对象的部分 HTTP/1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了。例如，客户端只需要显示一个文档的部分内容，又比如下载大文件时需要支持断点续传功能，而不是在发生断连后不得不重新下载完整的包。 HTTP/1.1中在请求消息中引入了range头域，它允许只请求资源的某个部分。在响应消息中Content-Range头域声明了返回的这部分对象的偏移值和长度。如果服务器相应地返回了对象所请求范围的内容，则响应码为206（Partial Content），它可以防止Cache将响应误以为是完整的一个对象 请求消息中如果包含比较大的实体内容，但不确定服务器是否能够接收该请求（如是否有权限），此时若贸然发出带实体的请求，如果被拒绝也会浪费带宽 HTTP/1.1加入了一个新的状态码100（Continue）。客户端事先发送一个只带头域的请求，如果服务器因为权限拒绝了请求，就回送响应码401（Unauthorized）；如果服务器接收此请求就回送响应码100，客户端就可以继续发送带实体的完整请求了。注意，HTTP/1.0的客户端不支持100响应码。但可以让客户端在请求消息中加入Expect头域，并将它的值设置为100-continue 节省带宽资源的一个非常有效的做法就是压缩要传送的数据。Content-Encoding是对消息进行端到端（end-to-end）的编码，它可能是资源在服务器上保存的固有格式（如jpeg图片格式）；在请求消息中加入Accept-Encoding头域，它可以告诉服务器客户端能够解码的编码方式 长连接 HTTP 1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，服务器不跟踪每个客户也不记录过去的请求。此外，由于大多数网页的流量都比较小，一次TCP连接很少能通过slow-start区，不利于提高带宽利用率。 在HTTP/1.0中，要建立长连接，可以在请求消息中包含Connection: Keep-Alive头域，如果服务器愿意维持这条连接，在响应消息中也会包含一个Connection: Keep-Alive的头域。同时，可以加入一些指令描述该长连接的属性，如max，timeout等 通常，HTTP/1.0的Proxy不支持Connection头域，为了不让它们转发可能误导接收者的头域，协议规定所有出现在Connection头域中的头域名都将被忽略 HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。例如：一个包含有许多图像的网页文件的多个请求和应答可以在一个连接中传输，但每个单独的网页文件的请求和应答仍然需要使用各自的连接。 HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间 消息传递 HTTP消息中可以包含任意长度的实体，通常它们使用Content-Length来给出消息结束标志。但是，对于很多动态产生的响应，只能通过缓冲完整的消息来判断消息的大小，但这样做会加大延迟。如果不使用长连接，还可以通过连接关闭的信号来判定一个消息的结束。 HTTP/1.1中引入了Chunkedtransfer-coding来解决上面这个问题，发送方将消息分割成若干个任意大小的数据块，每个数据块在发送时都会附上块的长度，最后用一个零长度的块作为消息结束的标志。这种方法允许发送方只缓冲消息的一个片段，避免缓冲整个消息带来的过载。 在HTTP/1.0中，有一个Content-MD5的头域，要计算这个头域需要发送方缓冲完整个消息后才能进行。而HTTP/1.1中，采用chunked分块传递的消息在最后一个块（零长度）结束之后会再传递一个拖尾（trailer），它包含一个或多个头域，这些头域是发送方在传递完所有块之后再计算出值的。发送方会在消息中包含一个Trailer头域告诉接收方这个拖尾的存在。 Host头域 在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。 HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。此外，服务器应该接受以绝对路径标记的资源请求。 内容协商 为了满足互联网使用不同母语和字符集的用户，一些网络资源有不同的语言版本（如中文版、英文版）。HTTP/1.0定义了内容协商（contentnegotiation）的概念，也就是说客户端可以告诉服务器自己可以接收以何种语言（或字符集）表示的资源。 例如如果服务器不能明确客户端需要何种类型的资源，会返回300（Multiple Choices），并包含一个列表，用来声明该资源的不同可用版本，然后客户端在请求消息中包含Accept-Language和Accept-Charset头域指定需要的版本。 Reference 详解HTTP1.1：http://imweb.io/topic/554c5879718ba1240cc1dd8a https://blog.csdn.net/forgotaboutgirl/article/details/6936982","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://roux.top/tags/HTTP/"}]},{"title":"HTTP2.0","slug":"HTTP2.0","date":"2018-04-21T16:00:00.000Z","updated":"2018-10-21T13:47:33.398Z","comments":true,"path":"2018/04/22/HTTP2.0/","link":"","permalink":"http://roux.top/2018/04/22/HTTP2.0/","excerpt":"前言 这篇文章主要是对HTTP2.0进行一个总结，把零散的知识点进行连接。 HTTP2.0 的目的是通过支持请求与响应的多路复用来较少延迟，通过压缩 HTTPS 首部字段将协议开销降低，同时增加请求优先级和服务器端推送的支持.","text":"前言 这篇文章主要是对HTTP2.0进行一个总结，把零散的知识点进行连接。 HTTP2.0 的目的是通过支持请求与响应的多路复用来较少延迟，通过压缩 HTTPS 首部字段将协议开销降低，同时增加请求优先级和服务器端推送的支持. 二进制分帧层 二进制分帧层，是HTTP 2.0性能增强的核心。 HTTP 1.x在应用层以纯文本的形式进行通信，而HTTP 2.0将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。这样，客户端和服务端都需要引入新的二进制编码和解码的机制。 帧 帧的分类 DATA：用于传输 HTTP 消息体； HEADERS：用于传输首部字段； SETTINGS：用于约定客户端和服务端的配置数据。比如设置初识的双向流量控制窗口大小； WINDOW_UPDATE：用于调整个别流或个别连接的流量 PRIORITY： 用于指定或重新指定引用资源的优先级。 RST_STREAM： 用于通知流的非正常终止。 PUSH_ PROMISE： 服务端推送许可。 PING： 用于计算往返时间，执行 “活性” 检活。 GOAWAY： 用于通知对端停止在当前连接中创建流 标志位用于不同的帧类型定义特定的消息标志。比如 DATA 帧就可以使用End Stream: true表示该条消息通信完毕。流标识位表示帧所属的流 ID。优先值用于 HEADERS 帧，表示请求优先级。R 表示保留位。 消息 消息是指逻辑上的HTTP消息（请求/响应）。一系列数据帧组成了一个完整的消息。比如一系列DATA帧和一个HEADERS帧组成了请求消息。 流 流是连接中的一个虚拟信道，可以承载双向消息传输。每个流有唯一整数标识符。为了防止两端流 ID 冲突，客户端发起的流具有奇数 ID，服务器端发起的流具有偶数 ID。 所有 HTTP2.0通信都在一个 TCP 连接上完成，慢启动时间减少,拥塞和丢包恢复速度更快，这个连接可以承载任意数量的双向数据流 Stream。相应地，每个数据流以 消息的形式发送，而消息由一 或多个帧组成，这些帧可以乱序发送，然后根据每个帧首部的流标识符重新组装。 多路复用 HTTP1.X如果不用pipeling的话会实现串行传输（一个得到应答才继续下一个），如果使用pipeling的话会建立多条TCP连接，这会导致开销增大 HTTP2.0建立一条TCP连接后，会并行传输数据。HTTP 2.0成功解决了HTTP 1.x的队首阻塞问题（TCP层的阻塞仍无法解决），同时，也不需要通过pipeline机制多条TCP连接来实现并行请求与响应。减少了TCP连接数对服务器性能也有很大的提升。 HTTP1.X虽然可以采用keep alive来解决复用TCP的问题，但是还是无法解决请求阻塞问题。 所谓请求阻塞意思就是一条TCP的connection在同一时间只能允许一个请求经过，这样假如后续请求想要复用这个链接就必须等到前一个完成才行，正如上图左边表示的。 之所以有这个问题就是因为HTTP1.x需要每条请求都是可是识别，按顺序发送，否则server就无法判断该相应哪个具体的请求。 HTTP2采用多路复用是指，在同一个域名下，开启一个TCP的connection，每个请求以stream的方式传输，每个stream有唯一标识，connection一旦建立，后续的请求都可以复用这个connection并且可以同时发送，server端可以根据stream的唯一标识来相应对应的请求。 请求优先级 流可以带有一个31bit的优先级： 0：表示最高优先级 2^31-1：表示最低优先级 客户端明确指定优先级，服务端可以根据这个优先级作为依据交互数据，比如客户端优先级设置为.css&gt;.js&gt;.jpg（具体可参见《高性能网站建设指南》）， 服务端按优先级返回结果有利于高效利用底层连接，提高用户体验。 然而，也不能过分迷信请求优先级，仍然要注意以下问题： 服务端是否支持请求优先级 会否引起队首阻塞问题，比如高优先级的慢响应请求会阻塞其他资源的交互。 服务端推送 HTTP 2.0增加了服务端推送功能，服务端可以根据客户端的请求，提前返回多个响应，推送额外的资源给客户端。 比如：客户端请求stream 1，/page.html。服务端在返回stream 1消息的同时推送了stream 2（/script.js）和stream 4（/style.css）。 首部压缩 HTTP1.x在每一次通信都会携带首部信息描述资源属性 HTTP2.0会在双方之间使用“首部表”来跟踪之前发送和存储的键值对，首部表在链接过程中始终存在，新增的键值对会更新到表尾，因此不需要每次通信都携带首部 HTTP2.0用到了首部压缩技术，压缩算法为HPACK HTTP 2.0关注的是首部压缩，而我们常用的gzip等是报文内容（body）的压缩。二者不仅不冲突，且能够一起达到更好的压缩效果。 Reference https://blog.csdn.net/zhuyiquan/article/details/69257126 https://segmentfault.com/a/1190000013028798 https://www.nihaoshijie.com.cn/index.php/archives/698/","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://roux.top/tags/HTTP/"}]},{"title":"DNS解析的过程","slug":"DNS解析","date":"2018-04-21T16:00:00.000Z","updated":"2018-04-22T06:26:43.626Z","comments":true,"path":"2018/04/22/DNS解析/","link":"","permalink":"http://roux.top/2018/04/22/DNS解析/","excerpt":"前言 对于网络这一块，有太多的学问，而且这个也是后面重点需要优化的方向，所以最近会写一些这方面的文章。","text":"前言 对于网络这一块，有太多的学问，而且这个也是后面重点需要优化的方向，所以最近会写一些这方面的文章。 过程 在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。 注意 人们在 DNS 中发现了一些漏洞，攻击者可以利用这些漏洞劫持这一使用名称在 互联网 上搜寻某个人或某个站点的过程。这种攻击的目的是取得对会话的控制以实施某种操作，例如使用户进入劫持者自己设立的欺骗性网站，以便收集用户的帐户和密码。 安全的DNS—DNSSEC Reference https://www.nowcoder.com/profile/2286733/myFollowings/detail/4794271","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"http://roux.top/tags/DNS/"}]},{"title":"HTTP学习（六）——HTTP2性能优化实践","slug":"HTTP学习（六）","date":"2018-04-21T16:00:00.000Z","updated":"2018-04-22T06:06:02.928Z","comments":true,"path":"2018/04/22/HTTP学习（六）/","link":"","permalink":"http://roux.top/2018/04/22/HTTP学习（六）/","excerpt":"前言 为了让我们的网站访问速度快变，我们不断增加带宽，做针对HTTP协议的特点对应用做各种优化。希望能通常高带宽，低延迟来提高网站到访问速度。带宽与延迟两者间，延迟才是性能的真正瓶颈。","text":"前言 为了让我们的网站访问速度快变，我们不断增加带宽，做针对HTTP协议的特点对应用做各种优化。希望能通常高带宽，低延迟来提高网站到访问速度。带宽与延迟两者间，延迟才是性能的真正瓶颈。 客观原因 当我们针对HTTP协议进行性能优化时，我们不得不注意到这样的一些客观原因。通常当我们改变不了底层协议特性时，我们只能在更高层处做文章。 带宽受物理层介质的影响，最快快不过光速，但是即便在今天越来越高的带宽，我们依然没有感觉到网站访问速度有多快。 延迟包括传输延迟，传播延迟，处理延迟和排队延迟。 每次连接都需要经过3次握手才能建立，增加整整一个RTT。 TCP拥塞控制策略：慢启动，拥塞避免[注1]。其中慢启动会被应用到每一个连接中。TCP流量和拥塞控制会影响整个网络到吞吐量。 解析DNS必然会产生一些延迟。 最快获得资源的方式，莫过于还没传，就已拿到。充分利用缓存。 最少的延迟就是什么都不传。而没有延迟。 针对HTTP1.X做过的优化 由于TCP层的特性，在提高web性能时，我们不得不做一些优化， Best Practices for Speeding Up Your Web Site，这些优化中针对HTTP协议特点的，我们做了哪些呢，从总体来说有以下几大点。 连接和拼接 连接或拼接JS和CSS文件，雪碧图，以减少HTTP请求，同时浏览器可缓存这些静态资源，为下次访问节约时间。但是这样带来的副作用是，维护成本高，其中某一个小改动都会使得整个拼接后的文件发生改变，重新缓存。 域名分区 由于浏览器的限制，同一个域下最多只能建立6个连接。我们通常使用子域名来减少所有资源在只有一个连接时的产生的排队延迟。这个显然不适用在HTTP2中，因为不同的域需要建立不同的连接。 资源内嵌 对于不常用的，较小大资源内嵌在文档中，比如base64的图片，以减少HTTP请求，但是这样的资源不能在浏览器中缓存，也不可能被其他页面共享，同时还有可能编码之后的资源变等更大了。在HTTP2中，这样的资源就可以使用SERVER PUSH来推送。 HTTP管道（额外的） 在HTTP1.x中已经实现了持久连接，但是却依然需要排队来发送和接收请求，这样不能充分利用网络资源。因此提出了HTTP管道的概念。客户端可以将所有请求都一起发给服务器端，服务器端或者按顺序处理，或者并行处理这些请求。但是返回响应的顺序是按照其自己内部的优先级来的。 但是，其缺点也很多，以至于现在的浏览器对它还是默认关闭的： 队首阻塞 并行处理时，需要占用缓存资源，服务器容易受到攻击 响应失败后，会断开tcp连接，并要求重发之后的所有请求，造成资源浪费 中间代理对其兼容性不是很好，有可能还会串行所有请求 针对HTTP2需要做的优化 坚决去掉在HTTP1.X中的域名分区，连接和拼接和资源内嵌的优化方式。 尽量让所有资源在同一域名下 利用服务器推送 继续保留CDN 脚注 TCP慢开始与拥塞避免示意图 Reference https://imjiaolong.cn/post/http2vshttp1.1.html","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://roux.top/tags/HTTP/"}]},{"title":"HTTP与HTTPS","slug":"HTTP与HTTPS","date":"2018-04-21T16:00:00.000Z","updated":"2018-04-22T06:28:42.803Z","comments":true,"path":"2018/04/22/HTTP与HTTPS/","link":"","permalink":"http://roux.top/2018/04/22/HTTP与HTTPS/","excerpt":"前言 HTTPS是对HTTP在安全方面上做的一个改进，HTTPS = HTTP + SSL/TLS","text":"前言 HTTPS是对HTTP在安全方面上做的一个改进，HTTPS = HTTP + SSL/TLS 区别 https需要申请CA证书，需要一定的费用 http是明文传输，https是有安全性的ssl加密传输 http的端口是80，https是443 http是简单的，无状态的，https是由http+sslL组成的进行加密传输、身份认证的协议，更加安全 HTTPS过程 客户端发起请求，将自己支持的加密算法，打个包告诉服务器端 服务器端从客户端发来的加密算法中，选出一组加密算法和HASH算法（注，HASH也属于加密），并将自己的身份信息以证书的形式发回给客户端。而证书中包含了网站的地址，加密用的公钥，以及证书的颁发机构等；这里，服务器就将自己用来加密用的公钥一同发还给客户端，而私钥则服务器保存着，用户解密客户端加密过后的内容。 客户端收到内容 验证一下证书是否合法。一般来说，证书是用来标示一个站点是否合法的标志。如果说该证书由权威的第三方颁发和签名的，则说明证书合法。 如果证书合法，或者客户端接受和信任了不合法的证书，则客户端就会随机产生一串序列号，使用服务器发来的公钥进行加密。这时候，一条返回的消息就基本就绪。 最后使用服务器挑选的HASH算法，将刚才的消息使用刚才的随机数进行加密，生成相应的消息校验值，与刚才的消息一同发还给服务器。 服务器接受到客户端发来的消息后 使用私钥解密上面客户端公钥加密的消息，得到客户端产生的随机序列号 使用该随机序列号，对该消息进行加密，验证的到的校验值是否与客户端发来的一致。如果一致则说明消息未被篡改，可以信任 最后，使用该随机序列号，加上之前第2步中选择的加密算法，加密一段握手消息，发还给客户端。同时HASH值也带上 客户端收到服务器端的消息后 计算HASH值是否与发回的消息一致 检查消息是否为握手消息 握手结束后，客户端和服务器端使用握手阶段产生的随机数以及挑选出来的算法进行对称加解密的传输 为什么不直接全程使用非对称加密算法进行数据传输 因为非对称算法的效率对比起对称算法来说，要低得多得多；因此往往只用在HTTPS的握手阶段。 http建立连接114ms，https为436ms（ssl为322ms），针对computer science house（计算机科学院CSH）的测试 经常使用的加密算法 非对称加密算法：RSA, DSA/DSS 对称加密算法： AES, 3DES HASH算法：MD5, SHA1, SHA256","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://roux.top/tags/HTTP/"}]},{"title":"HTTP学习（四）——HTTP2.0的新特性","slug":"HTTP学习（四）","date":"2018-04-20T16:00:00.000Z","updated":"2018-04-22T05:46:02.851Z","comments":true,"path":"2018/04/21/HTTP学习（四）/","link":"","permalink":"http://roux.top/2018/04/21/HTTP学习（四）/","excerpt":"前言 HTTP2.0可以让我们的应用变得更快、更简单、更健壮，让我们在HTTP/1.1时针对TCP协议特性而做的用来提高性能的HACK一笔勾销 为了提高应用的性能，降低延迟，我们能做的无外乎2点，要么传输的东西越小越好，要么距离能获得资源的地方越近越好。 HTTP2的目的：通过支持多路复用来提高并行能力，减少因为3次握手等而产生的延迟；通过压缩HTTP首部将协议开销降到最低，同时支持请求优先级和服务器推送。 HTTP2最大的改变：引入二进制分帧层。HTTP2.0不会改动HTTP1.x的语义，提供的功能也不变，但是HTTP2对内修改了格式化数据的方式，以及传输这些数据的方式。对外，也就是面向应用，不用做任何改变，感知不到这一层的变化的。 其实HTTP2.0是对HTTP1.x的一个扩展，而非替代，之所以称之为2是因为它引入的二进制分帧层之前的HTTP1.x的服务端和客户端并不兼容。","text":"前言 HTTP2.0可以让我们的应用变得更快、更简单、更健壮，让我们在HTTP/1.1时针对TCP协议特性而做的用来提高性能的HACK一笔勾销 为了提高应用的性能，降低延迟，我们能做的无外乎2点，要么传输的东西越小越好，要么距离能获得资源的地方越近越好。 HTTP2的目的：通过支持多路复用来提高并行能力，减少因为3次握手等而产生的延迟；通过压缩HTTP首部将协议开销降到最低，同时支持请求优先级和服务器推送。 HTTP2最大的改变：引入二进制分帧层。HTTP2.0不会改动HTTP1.x的语义，提供的功能也不变，但是HTTP2对内修改了格式化数据的方式，以及传输这些数据的方式。对外，也就是面向应用，不用做任何改变，感知不到这一层的变化的。 其实HTTP2.0是对HTTP1.x的一个扩展，而非替代，之所以称之为2是因为它引入的二进制分帧层之前的HTTP1.x的服务端和客户端并不兼容。 特性浅析分帧 这是HTTP2.0中最大的改变。HTTP2.0之所以性能会比HTTP1.x有那么大的提高，很大程度上正是由于这一层的引入。 这里所谓的“层” ，指的是位于套接字接口[1]与应用可见的高层HTTP API之间的一个新机制:HTTP的语义，包括各种动词、方法、首部，都不受影响，不同的是传输期间对它们的编码方式变了。 HTTP1.x用回车换行符作为纯文本的分隔符，在进行解析和差错检测时不方便。HTTP1.x中用ASCII码，是16进制的，来表示报文中的每一个字符，如下图中,47代表字母G，45代表字符E，54代表字符T。 然而，HTTP2.0引入分帧层后，将报文分隔成一个个更小的帧，并采用二进制编码的方式。通常会将一个消息（首部和数据在一起的）分成一个HEADER帧和若干个DATA帧。如下图所示 另外需要明确的几个定义： **流**：已建立的连接上的双向字节流。具有唯一的流ID，客户端发起的为奇数ID，服务端发起的为偶数ID。很多个流可以并行的在同一个tcp连接上交换消息。 **消息**：与逻辑消息对应，比如一个请求或一个响应。由一个或多个帧组成。 **帧**：HTTP2中最小的通信单位，每个帧都会有帧首部，每个帧或者用来承载HTTP首部或负荷数据，或其他特定类型的帧。帧是遵循二进制编码的。 总得来说，就是这样的，在HTTP2中，相同域名下的所有通信都在一个连接上完成，这个连接中可以承载任意数量的双向流。这些流都是以消息的形式被发送的，同时消息又由一个或多个帧组成。多个帧之间可以乱序发送，最后根据帧首部的流标识重新组装。 解释 :这个双向是指，服务器可以给浏览器发消息（server push），浏览器也可以给服务器发东西（这就不用说啦） 对于一个帧来说，有固定固定帧格式，其中帧首部规定了帧最多只能带64KB的数据，还包括了帧类型和流标识符等。另外，帧中还可以填充一些额外的数据，最多255字节，保证数据安全性，拿HEADER帧举例。 从这点上看，HTTP2.0中的帧与tcp报文段有些相似的。 在客户端或服务端发起建立新流时，帧携带HTTP的首部块，其中服务端发起流时，发送的HEADER帧没有优先级这一字段；当新流建立之后，就可发送HTTP消息的应用数据，也就是帧的负荷数据。 将消息拆成多个数据帧之后，会大大缓解HTTP队首阻塞[2]的情况。但是与tcp层的队首阻塞[3]并无直接关系。同时，改以帧为传输单位后，使得对报文无论是解析和差错检测方面都变得更加容易，因为对纯文本的解析还需要考虑到空格，空行，换行等问题。另外，也还消除了并行处理和发送请求及响应时对多个连接的依赖。 解释 ：多路复用：用一个tcp连接，并行发好多。【…keep_alive 很像啊】 —分组数？？表示是底层的，都没有概念…按道理说是分帧了后，分组数会变多啊？？？ 和keep_alive 不像，是和管道化很像哈。 实际上是这样的，首先肯定的是多使用同一个tcp连接，比起以前的多个tcp连接，会至少每次少了3个建立连接的tcp报文段，还不包括重传的。同时因为分帧之后出错的概率变小，间接的需要重传的包变少。从这两方面来说整个网络中的包中的总数是变少的。 另外呢，tcp报文段的长度其实还是保持不变的，不同流中的帧其实是混在一个tcp报文段中一起被发送，而在接收方那边接受到这个报文段后再进行拆分重新组装成新的http报文。 首部压缩 由于HTTP协议是一种无状态的协议，服务器自身不会保存太多的信息和先前请求过的元数据信息，这就需要客户端每次都使用多个首部字段来描述所传输的资源及其属性，又由于HTTP1.1是以文本形式传输的，每次都会给HTTP报文增加500-800字节的负荷，如果算上cookie，这个负荷甚至会增加到上千。如果可以有办法减少这些开销，那么对性能又有很大的提升。 HTTP2采用HPACK压缩方法，一边用index mapping table压缩，一边编码。这个table由静态表和动态表组成。 先用预定义的index mapping table将头部中常用的字符串用index来代替 对一定要使用文本表示的字符串，采用预定义的哈夫曼编码表进行编码 (具体的压缩和解压缩的方法请看此文的解释) 客户端和服务器端使用首部表来跟踪和存储之前发送的每一个键值对。第一次请求时发送过的键值对，第二次在再请求时就不在发送了。（这一现象还一直没观察到） 在tcp连接期间，客户端和服务端共同维护这个首部表，并且是共同渐进更新的 每个新的键值对，要么直接添加到首部表尾部，要么替换原有表中的值 另外，HTTP2的前身SPDY采用的头部压缩算法是delate算法，这个算法的压缩效率也不错，但是由于存在CRIME攻击，而HTTP2不得不重新设计了HPACK算法。 解释 使用了HPACK算法，一方面如果下一次请求头部和上一次请求头部中有相同的字段，那么相同的字段不会被发送，只会被发送差异性的字段。另一方面，会有一张首部表，里面会有常用的首部字段极其对应的序号，会有序号来代替这个具体的字段字符串。同时，整个首部帧还会用哈夫曼编码来进行压缩。 多路复用 引入二进制分帧层之后，HTTP2.0可以很容易的去实现多流并行而不用依赖建立多个tcp连接。 实验表明，客户端使用更少的连接肯定可以降低延迟时间。HTTP 2.0 发送的总分组数量比 HTTP 差不多要少 40%。而服务器处理大量并发连接的情况也变成了可伸缩性问题，因为 HTTP 2.0 减轻了这个负担。 —-HTTP2.0 每个来源使用一个连接，优势如下： 从服务器和客户端来说，占用的资源和内存都少了。 从tcp连接和网络来说，使得网络拥塞得到改善，慢启动时间减少，拥塞和丢包恢复速度变快。 解释 keep-alive，也是可以不进行3次握手就可以发送多个在同一个域下的请求。但是必须发送下一个请求B，等待前一个请求A的响应收到后才可以发送。多路复用和管道优化差不多，只是管道优化由于兼容性的问题，而没有被普遍使用。 但是什么时候断？如果太多的保持连接，会不会反而不好呢 和一般TCP连接释放一样，如果客户端没有数据要请求，或服务端数据发送完毕后，会主动发送关闭连接的报文。或者是服务端连续发送10个探测报文，客户端无响应，服务端就关闭了这个连接。 请求优先级 当同一条连接上可以同时发送很多请求时，并不等于说这些请求对于服务器来说都应该一视同仁，因为客户端对资源的需求程度不同。比如说一个html文档，显然客户端对CSS和JS的需求，远大于对文档内图片的需求。 因此在建立新流时，HEADER帧可以带有一个优先级(31位，0为优先级最高)的值。这样，服务端就可以因此而适当分配资源，优先发送这些优先级高的帧。 HTTP2.0协议并没有规定这样的处理优先级的算法该如何实现，仅仅只是提供了这样一种机制。 为了合理充分利用网络资源，服务器也应该交错处理不同优先级的帧。而不是严格按照优先级来处理，否则又会造成队首堵塞的情况。 解释 ：请求优先级….感觉需要服务器也要支持的节奏（那确实变复杂了） 是的。也就是说服务器和客户端对这个优先级的理解是一样的，或是达成一致的。 服务器推送 说到服务器推送，其实在HTTP1.1时，我们就用到过类似的，比如将图片使用base64编码嵌入在文档中。 之所以要提供这个服务，是因为一个文档被请求回来时，往往还需要再次请求很多文档内的其他资源，如果这些资源的请求不用客户端发起，而是服务端提前预判发给客户端，那么就会减少一半的RTT。 HTTP2.0这个协议也没有规定服务器端到底该怎样推送这个资源。服务端可以自己制定不同的策略，可以是根据客户端明确写出的推送请求；或者是服务端通过学习得来；再或者是通过额外的HTTP首部想服务端表明意向。 这个服务的特点是： 只有建立连接后，服务器才可以推送资源(发送PUSH_PROMISE帧，这个帧中只有要约的HTTP首部)，也就是说服务器不能无缘无故的主动向客户端推送资源 客户端可以发送RST_STREAM拒绝服务器推送来的资源。但是这可能存在一个时间差，而导致客户端明明已经拒绝了，但服务端却还是把资源推送了过来。 推送的资源可以有不同页面共享 服务器可以按照优先级来推送资源 解释 服务器主动推送一个资源，客户端有权来选择是接收还是不接收，不能‘来者不拒’嘛，是吧。 流量控制 我们知道在HTTP2协议中，我们可以在同一个连接中，建立多个流，那么实际上这些流之间是相互竞争的，会相互争夺这个连接中资源的分配。此时与tcp流量控制相似，我们也需要对流中的帧进行流量控制。但只有DATA帧受流量控制，而其他类型的帧不受流量控制。同样，HTTP2也只提供了这样一种机制，而非具体实现。 这个流量控制在没一跳之间进行，而非端到端 流量控制基于窗口更新帧。连接建立之初，通过交换settings帧，来设定双向的流量控制窗口大小。 发送端每发送一个DATA帧，就将window的值减去这次data帧的大小，直到window=0。 接收方可通过发送window_update 帧。如果接收方不想接受数据了，就不发送window _update帧。 在接受关键资源时，可将非关键资源的window设置的非常小，等网络空闲了，再改回大一些。 工具使用 可以使用chrome的工具chrome://net-internals/#http2来查看具体发送的帧的内容 打开chrome-network中的protocol一栏，查看当前站点使用的HTTP版本 安装chrome扩展HTTP/2 and SPDY indicator,在地址栏右侧会标示出是否使用了HTTP2或SPDY协议。 在firefox浏览器的网络中，也可直接查看使用的HTTP协议的版本 帮助我们检测某个网站是否使用了HTTP2协议的网站HTTP/2 Checker;检测是否使用了SPDY协议的网站SPDYCheck.org 分析页面性能的网站WebPagetest 实验验证为了能够亲自证实HTTP2确实对web性能有了很大的改进，使用nodejs作为服务端，分别验证在使用HTTP2, HTTPS, HTTP和SPDY作为HTTP协议时，同时加载10张图片时web性能的表现，代码下载。结果比较出乎意外： 可以比较直观的观察到多路复用的表现 Server Push的验证 屈屈的博客中有专门的介绍，这里我们也看一下。打开博客首页后可看到响应头中有link:&lt;...&gt;这样一个键值对，这是告诉服务器这个资源需要被推送。 然后使用之前提到过的chrome://net-internals/#http2工具来查看具体的Push过程 至于头部压缩字节变少，页面加载速度变慢并无明显结果。与HTTPS、SPDY和HTTP/2的性能比较的实验结果差的也比较多。 猜测原因：由于是访问的本地资源，不能模拟网络拥塞的情况，故不能完全体现出http2的优势。 脚注 套接字：是支持TCP/IP网络通信的基本操作单元，可以看成是不同主机之间的进程进行双向通信的端点。是应用进程与tcp连接之间的门，通过套接字口来发送或获得报文。 HTTP队首阻塞：一个慢请求阻塞后面的所有请求。具体来说就是，假设客户端同时发送2个请求，一个高优先级，一个低优先级，即便低优先级的资源先准备好了，也不会先发送，而是先等着，等高优先级的响应发送完了再发送低优先级的。这样会导致网络资源浪费，服务器缓冲开销浪费，最终导致客户端等待时间无限期延迟。 tcp队首阻塞：tcp要求分组严格按照顺序交付，一个分组未收到，就会阻塞后续的所有高序号分组。直到重传那个丢失的分组。","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://roux.top/tags/HTTP/"}]},{"title":"HTTP学习（五）——HTTP2 VS SPDY","slug":"HTTP学习（五）","date":"2018-04-20T16:00:00.000Z","updated":"2018-04-22T05:45:56.796Z","comments":true,"path":"2018/04/21/HTTP学习（五）/","link":"","permalink":"http://roux.top/2018/04/21/HTTP学习（五）/","excerpt":"前言 SPDY是HTTP2的催化剂，但SPDY不是HTTP2。 本文主要针对SPDY与HTTP2之间的区别，而不太多的涉及它俩之间与HTTP1.X的区别。 SPDY的出现 SPDY是谷歌在09年年中时发布的，它的主要目标时通过解决HTTP1.1中一些显著的性能限制，来减少网页额的加载时间。目前为止，Chrome,Firefox和Opera都支持了这一协议。 SPDY引入了新的二进制分帧层，以实现多路复用、优先次序、最小化的消除网络延迟，同时对HTTP首部进行压缩，减少HTTP报文的冗余数据。 目前为止，我们只在实验室条件下测试过 SPDY。最初的成果很激动人心：通过模拟的家庭上网线路下载了 25 个最流行的网站之后，我们发现性能的改进特别明显，页面加载速度最多快了 55%。 ——A 2x Faster Web Chromium Blog","text":"前言 SPDY是HTTP2的催化剂，但SPDY不是HTTP2。 本文主要针对SPDY与HTTP2之间的区别，而不太多的涉及它俩之间与HTTP1.X的区别。 SPDY的出现 SPDY是谷歌在09年年中时发布的，它的主要目标时通过解决HTTP1.1中一些显著的性能限制，来减少网页额的加载时间。目前为止，Chrome,Firefox和Opera都支持了这一协议。 SPDY引入了新的二进制分帧层，以实现多路复用、优先次序、最小化的消除网络延迟，同时对HTTP首部进行压缩，减少HTTP报文的冗余数据。 目前为止，我们只在实验室条件下测试过 SPDY。最初的成果很激动人心：通过模拟的家庭上网线路下载了 25 个最流行的网站之后，我们发现性能的改进特别明显，页面加载速度最多快了 55%。 ——A 2x Faster Web Chromium Blog 一方面由于随着web应用的发展，HTTP1.1协议的局限性突显的越来越严重，另一方面由于SPDY的优秀表现，12年初，W3C向全社会征集HTTP2的建议，最终决定将SPDY规范作为制定标准的基础。随后的时间内，SPDY与HTTP2共同进化，HTTP2提出新规范或新功能，SPDY为它进行测试和验证。当HTTP2一切就绪之日，就是SPDY退出舞台之时。事实上，在今年2月谷歌公司已经宣布将在16年年初放弃对SPDY的支持。 目前各浏览器对SPDY和HTTP2的支持情况分别如下: SPDY与HTTP2的区别 头部压缩算法，SPDY，通用的deflate算法[注1]；HTTP2，专门为压缩头部设计的HPACK算法 SPDY必须在TLS上运行，HTTP2可在TCP上直接使用，因为增加了HTTP1.1的Upgrade机制 更加完善的协议商讨和确认流程 更加完善的Server Push流程 增加控制帧的种类，并对帧的格式考虑的更细致 脚注 deflate算法 这个算法是由2个算法组合而成，哈夫曼编码和LZ77编码。 哈夫曼编码 一种无前缀编码，简单来说就是长字符串用短编码表示，以最终达到减少总大小的目的。具体编码过程可参考Huffman 编码压缩算法 例如，在一篇英语文章中，字母“E”出现的频率最高，“Z”最低，如果我们采用字符编码，那么每一个字母都是8bit表示；但是如果，我们使用不定长的bit编码，频率高的字母用比较短的编码表示，频率低的字母用长的编码表示，就会大大缩小文件的空间。 12345678910字符编码A00101001B00101010C00101011……哈夫曼编码A 0B 10C 110D 1110E 11110 大致思路：每次总是选取频率最小两个节点，将其频率相加，最终构成一个最优二叉树。 例如：有A,B,C,D,E五个字符，出现的频率（即权值）分别为5,4,3,2,1,那么我们第一步先取两个最小权值作为左右子树构造一个新树，即取1，2构成新树，其结点为1+2=3 虚线为新生成的结点，第二步再把新生成的权值为3的结点放到剩下的集合中，所以集合变成{5,4,3,3}，再根据第二步，取最小的两个权值构成新树，如图： 再依次建立哈夫曼树: 其中各个权值替换对应的字符即为下图: 所以各字符对应的编码为：A-&gt;11,B-&gt;10,C-&gt;00,D-&gt;011,E-&gt;010 LZ77编码 字典压缩算法,用到的场景比如gzip。 这个算法的主要思想是：文件中有两块内容相同的话，那么只要知道前一块的位置和大小，我们就可以确定后一块的内容。所以我们可以用（两者之间的距离，相同内容的长度）这样一对信息，来替换后一块内容。由于（两者之间的距离，相同内容的长度）这一对信息的大小，小于被替换内容的大小，所以文件得到了压缩。 大致流程如下： 可构想出2个窗口，一个作为搜索缓存区（已完成搜索的字符），一个作为待搜索窗口。如下图: 编码过程： 如果待搜索字符c没在搜索缓存区中找到，则输出(0,0,c),同时，整个窗口向前移动1位 如果待搜索字符c在搜索缓存区中找到，起始位置在搜索缓存区中x，连续长度是offset，待搜索窗口中offset之后的一个字符是d，则输出(x, offset, d)。之后，整个窗口向前移动offset位。 最终输出的三元组就是压缩码 Reference https://imjiaolong.cn/post/http2%26spdy.html","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[]},{"title":"HTTP学习（三）——关于HTTP/1.1的管道化","slug":"HTTP学习（三）","date":"2018-04-19T16:00:00.000Z","updated":"2018-04-22T05:45:50.220Z","comments":true,"path":"2018/04/20/HTTP学习（三）/","link":"","permalink":"http://roux.top/2018/04/20/HTTP学习（三）/","excerpt":"什么是http管道化 通常，http请求总是顺序发送的，下一个请求只有在当前请求的响应被完全接受的时候才会被发送。由于网络延迟和带宽的限制，这样会导致在服务器发送下一个响应的时候中间有很大的延迟。 HTTP/1.1允许多个http请求通过一个套接字同时被输出 ，而不用等待相应的响应。然后请求者就会等待各自的响应，这些响应是按照之前请求的顺序依次到达。（me：所有请求保持一个FIFO的队列，一个请求发送完之后，不必等待这个请求的响应被接受到，下一个请求就可以被再次发出；同时，服务器端返回这些请求的响应时也是按照FIFO的顺序）。 管道化的表现可以大大提高页面加载的速度，尤其是在高延迟连接中。 管道化同样也可以减少tcp/ip的数据包。通常MSS的大小是在536-1460字节，所以将许多个http请求放在一个tcp/ip包 里也是有可能的。减少加载一个网页所需数据包的数量可以在整体上对网络有益处，因为数据包越少，路由器和网络带来的负担就越少。 HTTP/1.1需要服务器也支持管道化。但这并不意味着服务器需要管道化响应，而是当客户端发出管道化请求时，服务器不会响应失败。这显然有可能引入一种新的福音主义错误（原文：This obviously has the potential to introduce a new category of evangelism bugs），因为仅有现代浏览器支持管道化。","text":"什么是http管道化 通常，http请求总是顺序发送的，下一个请求只有在当前请求的响应被完全接受的时候才会被发送。由于网络延迟和带宽的限制，这样会导致在服务器发送下一个响应的时候中间有很大的延迟。 HTTP/1.1允许多个http请求通过一个套接字同时被输出 ，而不用等待相应的响应。然后请求者就会等待各自的响应，这些响应是按照之前请求的顺序依次到达。（me：所有请求保持一个FIFO的队列，一个请求发送完之后，不必等待这个请求的响应被接受到，下一个请求就可以被再次发出；同时，服务器端返回这些请求的响应时也是按照FIFO的顺序）。 管道化的表现可以大大提高页面加载的速度，尤其是在高延迟连接中。 管道化同样也可以减少tcp/ip的数据包。通常MSS的大小是在536-1460字节，所以将许多个http请求放在一个tcp/ip包 里也是有可能的。减少加载一个网页所需数据包的数量可以在整体上对网络有益处，因为数据包越少，路由器和网络带来的负担就越少。 HTTP/1.1需要服务器也支持管道化。但这并不意味着服务器需要管道化响应，而是当客户端发出管道化请求时，服务器不会响应失败。这显然有可能引入一种新的福音主义错误（原文：This obviously has the potential to introduce a new category of evangelism bugs），因为仅有现代浏览器支持管道化。 什么时候我们应该管道化请求 只有幂等的请求[1] 才可以被管道化，比如GET和HEAD。POST和PUT不应该被管道化。我们同样也不应该在建立新连接的时候发出管道化的请求 ，因为不能确源服务或代理是否支持HTTP/1.1。因此，管道化只能利用已存在的 keep-alive 连接。 多少个请求应该被管道化 如果连接过早的关闭，管道化许多请求是划不来的，因为我们会花费很多时间用来向网络里写请求，然后还不得不在新连接中重写一遍。而且，如果较早到达的请求需要花费很长的时间完成，一个过长的管道实际上会让用户感知到更长的延迟。 HTTP/1.1标准也没有提供关于管道化请求理想数目的任何指导。实际上，我们建议每个服务器不超过2个keep-alive连接。显然，这个还得依赖于应用本身。鉴于上述的原因，浏览器可能不需要一个持续时间特别长的管道。2个可能是比较合适的值，但是还有待测试。 如果一个请求被取消了，会发生什么？ 如果一请求被取消了，是不是意味着整个管道都被取消了呢？或者，是不是意味着这个被取消请求的响应应该被简单的丢弃，以便这个管道中的其他请求不会被强制重发？ 这个答案依赖于很多因素，包括，这个被取消请求的响应还有多少没有被收到。最原始的办法可能是简单的取消管道，然后重发所有的请求。仅仅当请求是幂等的时候才可以。这样原始的方法也可以产生好的影响，因为正在管道中被发送的请求可能属于同一个正在被取消的页面载入组。 如果连接失败会发生什么？ 如果连接失败了或服务器在下载一个管道中的响应时中断了，浏览器必须有能力重新开始发送被丢失的请求。这种情况可以等同于上面讨论的被取消的例子。 解释 其实HTTP管道化就是将客户端的FIFO队列移到了服务端。在客户端可以依次发送所有要发送的请求（当然这些请求是在同一个域下的），一个请求发送完之后，不必等待这个请求的响应被接受到，下一个请求就可以被再次发出。在服务器端维持的FIFO队列，这个队列是按照资源的重要程度排列的。比如HTML比CSS要先返回，JS,CSS比图片先返回。 在服务器端会有一个缓冲区，来存放那些已经被处理好了但是还没轮到被发送的响应。比如服务器先后收到了A,B两个请求，A资源比B资源优先级要高，处理A需要10ms，处理B需要1ms，假设服务器可以并行处理请求，那么B的响应肯定是最先处理好了的，但是B响应不能先发出去，必须待在缓冲区里，等待A响应处理好了之后，先把A的响应发出去，B的响应才能够被发出去。因为服务端必须要遵循FIFO这个原则。 HTTP管道化不是HTTP2的内容，是对HTTP1.1协议下，服务器不能很好处理并行请求的一个改进。 管道化的有序和TCP的有序是本质上的不同，管道化的有序，是消息与消息之间的有序。TCP中的有序，组成一个消息的多个报文段之间的有序。 管道做了哪些事，我的理解是创造了一个可以不用等待前一个请求的响应即可发送下一个请求的场所。至于注意些什么，除了知道有些设备不支持，其他的我也没实际经验（毕竟没用过，囧）。 脚注 HTTP/方法的幂等性：是指一次和多次请求某一个资源应该具有同样的副作用。 幂等性的请求，实际上就是多次操作都不会改变结果的请求，比如GET，我可以多次从同一个地方获取资源，但是对于资源本身来说并不会发生什么变化，我GET10次和GET100次，资源都没有发生任何变化。而post则不同了，我提交表单10次，和100次，造成的结果是不同的，至少数据库里新增的数据有不同。 详情见此文 Reference https://imjiaolong.cn/post/http-pipelining.html","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://roux.top/tags/HTTP/"}]},{"title":"HTTP学习（二）——一条消息的历程","slug":"HTTP学习（二）","date":"2018-04-19T16:00:00.000Z","updated":"2018-04-22T05:45:53.227Z","comments":true,"path":"2018/04/20/HTTP学习（二）/","link":"","permalink":"http://roux.top/2018/04/20/HTTP学习（二）/","excerpt":"前言 我们都知道HTTP底层还是调用TCP协议进行传输的，那么具体怎样调用的呢（如下图）？在这个过程中一条消息都经历了什么过程呢？","text":"前言 我们都知道HTTP底层还是调用TCP协议进行传输的，那么具体怎样调用的呢（如下图）？在这个过程中一条消息都经历了什么过程呢？ 历程 应用层（HTTP, HTTP报文） HTTP报文是基于文本的，是没有长度限制的。也就是说资源有多大，就会一次性都会发过去。HTTP报文的首部行之间是用换行回车来分隔。另外，发送过去的报文实际内容就是将一个个的字符用ASCII码来表示。 运输层(TCP，报文段) 如果TCP需要发送一个很大的数据，TCP通常会把文件化成长度为MSS[1]的若干块再发送。也就是将长报文划分成短报文，并提供拥塞控制机制。TCP报文的首部一般是20字节，包括端口号，序号[3]和确认号[4]，以及做验证的一些字段。 网络层(IP, 数据报) 增加了源IP地址和目的IP地址；同时规定了数据报长度（包括首部长），理论上是65535字节。 有可能从发送方到接受方这一路径中每段链路使用的链路层协议不同，且这些协议具有不同的MTU[2],因此就需要对ip数据报进行分片。 只有完全重构为初始ip的数据报才会被交付到上层，否则会被直接丢弃。如果运输层是TCP，那么TCP会要求源重传。 链路层(帧) 传输的数据量有固定大小，不同的链路层协议能传送的最大数据量不同。可见此文 会增加源mac地址和目的mac地址。 脚注 MSS: 最大报文段长度，不包括TCP报文的头部。受最大链路层帧长度MTU的限制。 MTU: 最大传输单元，链路层协议不同，议具的MTU也有可能不同，其中以太网和PPP链路层的MTU是1500字节。 序号：这个分组的第一字节排在整个消息的第几位。 确认号：期望下次从主机那儿获得字节的序号。 Reference https://imjiaolong.cn/post/message-road.html","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://roux.top/tags/HTTP/"}]},{"title":"HTTP学习（一）——HTTP的历史","slug":"HTTP学习（一）","date":"2018-04-19T16:00:00.000Z","updated":"2018-04-22T05:44:00.950Z","comments":true,"path":"2018/04/20/HTTP学习（一）/","link":"","permalink":"http://roux.top/2018/04/20/HTTP学习（一）/","excerpt":"前言 本系列文章均转自小路口的系列博文，因为没有找到博主的联系方式，故如有侵权烦请联系我进行处理。 背景 在上世纪60年代，世界上占统治地位的通信网络是电话网络，它是基于电路交换[1]的。与此同时，随着分时计算机的出现和计算机重要性的提高，如何充分利用分散在世界各地的数字计算机为人们所共享就变的越发重要了。其中需要注意的是，这些用户所产生的流量是具有突发性的，也就是说具有活动的间断性。 于是世界上的科学家们就发明了更能很好解决突发性的分组交换来替代电路交换。最开始是美国的阿帕网，ARPAnet，是世界上第一个分组交换机网络，也就是今天因特网的直接祖先。 HTTP协议是现代web的基础。其实HTTP协议的出现主要是为了推动万维网的应用，它们的发明者是同一个人。HTTP协议设计之初是非常简洁的，就是为了传输超文本文档，也就是HTTP0.9版本。","text":"前言 本系列文章均转自小路口的系列博文，因为没有找到博主的联系方式，故如有侵权烦请联系我进行处理。 背景 在上世纪60年代，世界上占统治地位的通信网络是电话网络，它是基于电路交换[1]的。与此同时，随着分时计算机的出现和计算机重要性的提高，如何充分利用分散在世界各地的数字计算机为人们所共享就变的越发重要了。其中需要注意的是，这些用户所产生的流量是具有突发性的，也就是说具有活动的间断性。 于是世界上的科学家们就发明了更能很好解决突发性的分组交换来替代电路交换。最开始是美国的阿帕网，ARPAnet，是世界上第一个分组交换机网络，也就是今天因特网的直接祖先。 HTTP协议是现代web的基础。其实HTTP协议的出现主要是为了推动万维网的应用，它们的发明者是同一个人。HTTP协议设计之初是非常简洁的，就是为了传输超文本文档，也就是HTTP0.9版本。 HTTP的版本 HTTP0.9 请求：ASCII字符串＋CRLF结尾 响应：ASCII字符流/HTML+CRLF结尾 只能GET获取资源，不能发送携带数据的POST请求 文档传完之后，断开连接 HTTP1.0（并不是真正的规范） 随着页面上的内容逐渐丰富，除了文字，超链接，还有图片资源。 人们对web应用的需求也不断增加，要求不仅能够访问HTML同时还需要能够提供有关请求和响应的元数据（首部字段），在页面上进行交互操作，比如表单提交，并且支持内容协商。 请求/响应的首部可有多行首部字段构成 响应对象前增加了一个响应状态行 可以支持长连接，还是每次请求结束后默认都断开连接 HTTP1.1 持久连接 分块传输 字节范围请求 协商机制更健全，协商内容更多：内容编码，传输编码，缓存指令，客户端cookie等 HTTP pipling(实际使用受限，浏览器默认不开启，很多中间代理不提供该服务) HTTP2 在web应用中资源越来越丰富的趋势中，由于tcp自身的特点以至于HTTP1.1的性能上受到了很大的限制，虽然我们有做一些针对性能提高的hack。HTTP2的出现主要是为了提高传输性能，降低延迟，提高吞吐量。 从总体来说，HTTP0.9用了一行命令就启动了万维网，HTTP1.0是对0.9扩展的正式说明，而HTTP1.1则是一份官方标准。总之，HTTP1.x的设计的初衷是实现要简单。但是这也是以牺牲性能为代价的。所以，这也是现在HTTP2所要解决的问题。 解释 “HTTP1.x的设计的初衷是实现要简单。但是这也是以牺牲性能为代价的” 比如没有处理并行连接和请求的快捷方法，没有为了减少不必要的请求开销而做优化（首部压缩）等等，这些以至于在页面资源极其丰富的今天，即便我们针对HTTP1.1做了很多HACK优化，然而性能还是没有得到很大的提升。而这些点在HTTP2中都得到了改进。 HTTP与tcp的关系 HTTP是应用层的协议，tcp是传输层的协议。HTTP协议并没有规定必须要使用tcp协议当作是传输层的协议，现在默认使用tcp当做是传输层协议，采用80端口（因为HTTP是无状态协议，要是使用未经改良的不可靠传输协议，很容易造成数据丢失）；另外，谷歌还研发了一种基于udp的多路传输协议QUIC(Quick UDP Internet Connections)[2]，用来解决SPDY在TCP遇到的瓶颈而在UDP上做出的探索。 HTTP是一种无状态的协议，当前的请求与上一次的请求并无关系，也就是说这次HTTP请求做什么和上一次请求做什么是没有关系的，哪怕请求的是相同的资源。这样做的好处是，服务器不用为了保存状态而消耗过多的资源，坏处是重复发相同的状态，会浪费网络资源，造成网络拥塞，延迟增大。 tcp提供了可靠传输的性能，为精确传输做了优化，比如3次握手，差错检测，快速重传。同时还进行了拥塞预防与控制，慢启动等来减轻整个网络的拥塞程度。一个数据包从请求到收到，需要经过传播延迟，传输延迟，处理延迟和排队延迟。因此，tcp比较适合大块数据的精确传输，性价比高；若常有突发的连接请求，实际上是其负作用的。原因很简单，在拿到完整数据之前，tcp做了太多事，造成了太多延迟，至少1个RTT。 脚注 电路交换：在端系统会话过程中，预留了端系统间所经路径所需要的资源，包括缓存，链路传输速率。 QUIC能够处理传输可靠性、丢包或无序数据包等一系列UDP默认未处理的问题。它的高层类似SPDY，低层是在UDP上模仿实现TCP的面向连接特性和可靠性并加入类似TLS的加密过程 Reference https://imjiaolong.cn/post/http-history.html","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://roux.top/tags/HTTP/"}]},{"title":"TCP流量控制","slug":"TCP流量控制","date":"2018-04-07T16:00:00.000Z","updated":"2018-04-22T13:00:30.351Z","comments":true,"path":"2018/04/08/TCP流量控制/","link":"","permalink":"http://roux.top/2018/04/08/TCP流量控制/","excerpt":"滑动窗口 问题：如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。 所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。 滑动窗口理解起来的话可以想象要发送的数据在一个首尾连接的数组上，而滑动窗口则是这个上面的一部分（大小由收发双方进行协商（协商的过程也就是对数据的发送和确认的过程）动态变化）。","text":"滑动窗口 问题：如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。 所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。 滑动窗口理解起来的话可以想象要发送的数据在一个首尾连接的数组上，而滑动窗口则是这个上面的一部分（大小由收发双方进行协商（协商的过程也就是对数据的发送和确认的过程）动态变化）。 示例 设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口是 rwnd = 400 ”(这里的 rwnd 表示 receiver window) 。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。 请注意，TCP的窗口单位是字节，不是报文段。TCP连接建立时的窗口协商过程在图中没有显示出来。 设每一个报文段为100字节长，而数据报文段序号的初始值设为1。大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值ack 从图中可以看出，B进行了三次流量控制。第一次把窗口减少到 rwnd = 300 ，第二次又减到了 rwnd = 100 ，最后减到 rwnd = 0 ，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。B向A发送的三个报文段都设置了 ACK = 1 ，只有在ACK=1时确认号字段才有意义。 TCP为每一个连接设有一个持续计时器(persistence timer)。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口控测报文段（携1字节的数据），那么收到这个报文段的一方就重新设置持续计时器。 糊涂窗口综合症（Silly Window Syndrome） 解释 当发送端应用进程产生数据很慢、或接收端应用进程处理接收缓冲区数据很慢，或二者兼而有之；就会使应用进程间传送的报文段很小，特别是有效载荷很小。极端情况下，有效载荷可能只有1个字节；而传输开销有40字节(20字节的IP头+20字节的TCP头) 这种现象就叫糊涂窗口综合症。 发送端引起的SWS 如果发送端为产生数据很慢的应用程序服务(典型的有telnet应用)，例如，一次产生一个字节。这个应用程序一次将一个字节的数据写入发送端的TCP的缓存。如果发送端的TCP没有特定的指令，它就产生只包括一个字节数据的报文段。结果有很多41字节的IP数据报就在互连网中传来传去。 解决方法 为了防止发送端的TCP逐个字节地发送数据。必须强迫发送端的TCP收集数据，然后用一个更大的数据块来发送。发送端的TCP要等待多长时间呢？如果它等待过长，它就会使整个的过程产生较长的时延。如果它的等待时间不够长，它就可能发送较小的报文段，于是，Nagle找到了一个很好的解决方法，发明了Nagle算法。而他选择的等待时间是一个RTT,即下个ACK来到时。 接收端引起的SWS 接收端的TCP可能产生糊涂窗口综合症，如果它为消耗数据很慢的应用程序服务，例如，一次消耗一个字节。假定发送应用程序产生了1000字节的数据块，但接收应用程序每次只吸收1字节的数据。再假定接收端的TCP的输入缓存为4000字节。发送端先发送第一个4000字节的数据。接收端将它存储在其缓存中。现在缓存满了。它通知窗口大小为零，这表示发送端必须停止发送数据。接收应用程序从接收端的TCP的输入缓存中读取第一个字节的数据。在入缓存中现在有了1字节的空间。接收端的TCP宣布其窗口大小为1字节，这表示正渴望等待发送数据的发送端的TCP会把这个宣布当作一个好消息，并发送只包括一个字节数据的报文段。这样的过程一直继续下去。一个字节的数据被消耗掉，然后发送只包含一个字节数据的报文段。 解决方法 第一个解决方法是只要有数据到达就发送确认，但宣布的窗口大小为零，直到或者缓存空间已能放入具有最大长度的报文段，或者缓存空间的一半已经空了。 延迟确认。第二个解决方法是延迟一段时间后再发送确认。这表示当一个报文段到达时并不立即发送确认。接收端在确认收到的报文段之前一直等待，直到入缓存有足够的空间为止。延迟的确认防止了发送端的TCP滑动其窗口。当发送端的TCP发送完其数据后，它就停下来了。这样就防止了这种症状。 优点：它减少了通信量。接收端不需要确认每一个报文段。 缺点，就是迟延的确认有可能迫使发送端重传其未被确认的报文段。可以用协议来平衡这个优点和缺点，例如现在定义了确认的延迟不能超过500毫秒。 Reference https://blog.csdn.net/hzhsan/article/details/46429749","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://roux.top/tags/TCP/"}]},{"title":"TCP问答","slug":"TCP问答","date":"2018-02-07T16:00:00.000Z","updated":"2018-04-23T14:31:28.717Z","comments":true,"path":"2018/02/08/TCP问答/","link":"","permalink":"http://roux.top/2018/02/08/TCP问答/","excerpt":"","text":"问答 A进程通过TCP向另一台机器上的B进程发送了一个字符串“hello”，TCP返回对方成功接收的确认信息，请问，现在进程A是否可以肯定地说进程B收到了它发送的字符串？ 不能！举反例，进程B所在机器的TCP收到进程A发送的“hello”信息后，告诉进程A发送成功，但有可能没有立即将数据交给进程B，而是放在自己的缓冲区中，等待进程B读取，如果机器此时突然掉电，缓冲区中的信息将丢失，进程B将不可能收到“hello”字符串。 有什么办法来尽量避免上述情况的发生呢？ 将TCP报文段首部中的PSH标志置1，这样会让B端的TCP协议收到数据后尽快交给进程B，能不缓存尽量不要缓存。 我们知道通常TCP连接的建立需要3次握手，关闭需要4次握手，为什么关闭会多一次呢？ 简单说，就是TCP允许半关闭状态的存在。当进程A向进程B发送FIN，B也向A发送确认后。此时此刻的状态就是半关闭状态，A发送的FIN就是告诉B：“我要发送的数据都发送完了”但B没有发送FIN给A，有可能代表B还有没发送完的数据，如果B也发送完数据了，B就发送FIN给进程A，进程A确认B发送的FIN，这时，双方都已经发送完了数据，连接就断开了，TCP回收相关资源。 假如服务器突然断电重启，但客户端并不知情，请问此时二者之间的TCP连接处于什么状态？ 处于半打开状态。就是客户端还觉得连接是正常的，服务器这边已经没有连接的任何信息了。 那么，假如此时客户端通过这个连接向服务器请求数据，服务器会怎么应对呢？ 服务器收到客户端的请求会进行一次ARP查询，获得客户端MAC地址，然而由于已经丢失了所有连接信息，此时的服务器是一脸懵逼（就像喝了孟婆汤！），于是乎，它会发一个RST给客户端，表示：“哥们，我不认识你，想跟我说话请先发送SYN！” 假如客户端按照服务器的要求重新建立连接，却搞错了服务器的端口号，会发生什么情况呢？ 有两种可能，一种是服务器端的TCP收到客户端请求，查看本机上是否有进程在监听相应的端口，如果有，就把请求交给这个进程，一般而言，这个进程不会接受这个连接的，于是它会发一个RST给客户端。还有一种可能是TCP没有找到哪个进程在监听相应的端口，于是TCP就会直接发一个RST给客户端，一般而言都会是这种情况。 假如现在有一个多进程服务器，服务器进程为A,接受一个连接后新建一个进程B来处理连接，再接受一个连接后又建一个进程C来处理这个连接，请问，进程ABC是否监听同样的端口？ 是！因为一条连接由唯一的四元组组成。 那TCP接收到发送给这个端口的报文段，怎么决定发给哪个进程呢？ 首先，所有的SYN报文段都会发送给服务器进程A，其他的报文段依据\\&lt;sourceIP:port, targetIP:port&gt;这个四元组来决定发送给进程B还是进程C。 假如上面的服务器进程A收到一个连接请求，正在为这个请求创建处理进程的时候，又有新的连接请求进来了，TCP会怎么处理呢？ 一般情况下，服务器进程A会给TCP一个指示，让TCP维护一个适当长度的连接队列，TCP与新连接请求完成三次握手后，就会把这个连接放入连接队列中，服务器进程A会在合适的时候来从这个队列中取连接。 这个连接对列是否会对服务器的并发处理能力产生影响呢？如果会，会有什么影响？ 不会！二者没有必然关系。 MSS和MTU各是什么，二者是什么关系？ MSS是TCP最大报文段长度，就是TCP发送数据需要对数据分段时，最大的段的字节数。MTU是最大传输单元，通常由网卡的硬件特性规定，表示通过该网卡传输的数据单元最大的字节数。MSS要受同一台机器上的MTU限制。比如MTU为1500字节，那么MSS就只能是1460字节，这是因为1460字节的数据在通过网卡向外传输时，会加上20字节的ip头和20字节的tcp头。 假设机器A和B的MSS分别是1400和1600，请问，A通过TCP向B发送数据时，是否可以发送长度为1600字节的数据段？ 不可以，虽然发送1600字节的数据段没有突破B的MSS，但是突破了A自己的MSS。这样一来，当这1600字节的数据段通过A的网卡向B发送时，会被切分为2个IP片，每个为840字节，以保证不突破A的MTU，这显然降低了传输的效率，因为两个840字节中有着相同的IP头和TCP头。 机器A和B有一条TCP连接，假如A想尽快断开连接，应当怎么办？ A可以直接给B发送一个RST，就可以了，相当于告诉B，我关闭连接了，你看着办吧。这叫做异常关闭。 B的TCP收到A发来的RST，会怎么办？ B的TCP会告诉上层的进程，连接已经断开了，然后就会回收这条连接的资源，并不会发送任何确认信息给A。所谓你无情休怪我不义。 假设A正常断开与B的TCP连接，当收到B的FIN时，A发送ACK给B，是否就算完成了4次握手，连接已经成功断开？ 不是，A的TCP会启动一个定时器，等待2MSL的时间，这主要是为了防止A的ACK没有成功传到B，让B以为自己的FIN没有送到A处，反复重传FIN的问题。2MSL的时间到时，如果A没有再次收到B的FIN，说明B成功收到A的ACK，A就可以安全地断开这个连接，若期间再次收到B的FIN，则A会重传ACK。 Reference https://mp.weixin.qq.com/s/z0eALQt40Wl2xFGyAqY_Uw","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://roux.top/tags/TCP/"}]},{"title":"TIME_WAIT状态","slug":"TIME_WAIT","date":"2018-01-07T16:00:00.000Z","updated":"2018-04-22T05:43:43.299Z","comments":true,"path":"2018/01/08/TIME_WAIT/","link":"","permalink":"http://roux.top/2018/01/08/TIME_WAIT/","excerpt":"前言 关于TCP的TIME_WAIT，一直停留在明白有什么作用的层次。想着《计算机网络》都学完了，也应该把TCP的问题给实实在在的弄明白。","text":"前言 关于TCP的TIME_WAIT，一直停留在明白有什么作用的层次。想着《计算机网络》都学完了，也应该把TCP的问题给实实在在的弄明白。 分析 产生的原因见TCP四次挥手 一些问题及解决 TIME_WAIT快速回收与重用 记一次TIME_WAIT网络故障 也说说TIME_WAIT状态 深入剖析 再叙TIME_WAIT 你所不知道的TIME_WAIT和CLOSE_WAIT—-强烈推荐 以前也和前面文章里说的一样，只是知道出现大量的TIME_WAIT就应该调整那么三个参数就行了，但是没想到还有问题的存在，并且调整参数还会分情况与场景。以后学习要注意！ 总结 关于TCP的学习就基本上结束了，也学了近一年时间了，大大小小的问题在自己的搜索和老师的解答下也基本上弄明白了，部分细节后面慢慢的再深入探索。","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://roux.top/tags/TCP/"}]},{"title":"TCP拥塞控制","slug":"TCP拥塞控制","date":"2018-01-07T16:00:00.000Z","updated":"2018-04-22T12:27:20.775Z","comments":true,"path":"2018/01/08/TCP拥塞控制/","link":"","permalink":"http://roux.top/2018/01/08/TCP拥塞控制/","excerpt":"拥塞控制与流量控制 拥塞控制：防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提：网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的所有因素 流量控制：指点对点通信量的控制，是端到端正的问题。流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收 拥塞控制代价：需要获得网络内部流量分布的信息。在实施拥塞控制之前，还需要在结点之间交换信息和各种命令，以便选择控制的策略和实施控制。这样就产生了额外的开销。拥塞控制还需要将一些资源分配给各个用户单独使用，使得网络资源不能更好地实现共享。","text":"拥塞控制与流量控制 拥塞控制：防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提：网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的所有因素 流量控制：指点对点通信量的控制，是端到端正的问题。流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收 拥塞控制代价：需要获得网络内部流量分布的信息。在实施拥塞控制之前，还需要在结点之间交换信息和各种命令，以便选择控制的策略和实施控制。这样就产生了额外的开销。拥塞控制还需要将一些资源分配给各个用户单独使用，使得网络资源不能更好地实现共享。 几种拥塞控制方法 慢开始( slow-start )、拥塞避免( congestion avoidance )、快重传( fast retransmit )和快恢复( fast recovery )。 慢开始和拥塞避免 发送方维持一个拥塞窗口 cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口大小 发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数 慢开始 慢开始算法：当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理 每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认 注意：慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd 为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量（如何设置ssthresh）。慢开始门限ssthresh的用法如下： 当 cwnd &lt; ssthresh 时，使用上述的慢开始算法 当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法 拥塞避免算法 让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕 如下图，用具体数值说明了上述拥塞控制的过程。现在发送窗口的大小和拥塞窗口一样大 当TCP连接进行初始化时，把拥塞窗口cwnd置为1。前面已说过，为了便于理解，图中的窗口单位不使用字节而使用报文段的个数。慢开始门限的初始值设置为16个报文段，即 cwnd = 16 在执行慢开始算法时，拥塞窗口 cwnd 的初始值为1。以后发送方每收到一个对新报文段的确认ACK，就把拥塞窗口值另1，然后开始下一轮的传输（图中横坐标为传输轮次）。因此拥塞窗口cwnd随着传输轮次按指数规律增长。当拥塞窗口cwnd增长到慢开始门限值ssthresh时（即当cwnd=16时），就改为执行拥塞控制算法，拥塞窗口按线性规律增长 假定拥塞窗口的数值增长到24时，网络出现超时（这很可能就是网络发生拥塞了）。更新后的ssthresh值变为12（即变为出现超时时的拥塞窗口数值24的一半），拥塞窗口再重新设置为1，并执行慢开始算法。当cwnd=ssthresh=12时改为执行拥塞避免算法，拥塞窗口按线性规律增长，每经过一个往返时间增加一个MSS的大小 强调：“拥塞避免”并非指完全能够避免了拥塞。利用以上的措施要完全避免网络拥塞还是不可能的。“拥塞避免”是说在拥塞避免阶段将拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞 快重传和快恢复 不使用快重传的情况：如果发送方设置的超时计时器时限已到但还没有收到确认，那么很可能是网络出现了拥塞，致使报文段在网络中的某处被丢弃。这时，TCP马上把拥塞窗口 cwnd 减小到1，并执行慢开始算法，同时把慢开始门限值ssthresh减半。 快重传算法 快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认 接收方收到了M1和M2后都分别发出了确认。现在假定接收方没有收到M3但接着收到了M4。显然，接收方不能确认M4，因为M4是收到的失序报文段。根据可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。 但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让发送方及早知道报文段M3没有到达接收方。发送方接着发送了M5和M6。接收方收到这两个报文后，也还要再次发出对M2的重复确认。这样，发送方共收到了接收方的四个对M2的确认，其中后三个都是重复确认。 快重传算法还规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必继续等待M3设置的重传计时器到期。 快恢复算法 当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。这是为了预防网络发生拥塞。注意：接下去不执行慢开始算法。 由于发送方现在认为网络很可能没有发生拥塞，因此与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。 下图给出了快重传和快恢复的示意图，并标明了“TCP Reno版本”。 区别：新的 TCP Reno 版本在快重传之后采用快恢复算法而不是采用慢开始算法。 也有的快重传实现是把开始时的拥塞窗口cwnd值再增大一点，即等于 ssthresh + 3 X MSS 。这样做的理由是：既然发送方收到三个重复的确认，就表明有三个分组已经离开了网络。这三个分组不再消耗网络 的资源而是停留在接收方的缓存中。可见现在网络中并不是堆积了分组而是减少了三个分组。因此可以适当把拥塞窗口扩大了些 在采用快恢复算法时，慢开始算法只是在TCP连接建立时和网络出现超时时才使用 接收方根据自己的接收能力设定了接收窗口rwnd，并把这个窗口值写入TCP首部中的窗口字段，传送给发送方。因此，接收窗口又称为通知窗口。因此，从接收方对发送方的流量控制的角度考虑，发送方的发送窗口一定不能超过对方给出的接收窗口rwnd 发送方窗口的上限值 = Min [ rwnd, cwnd ] 当rwnd &lt; cwnd 时，是接收方的接收能力限制发送方窗口的最大值。当cwnd &lt; rwnd 时，则是网络的拥塞限制发送方窗口的最大值。","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://roux.top/tags/TCP/"}]},{"title":"信号量与自旋锁的区别","slug":"信号量和自旋锁的区别","date":"2018-01-07T16:00:00.000Z","updated":"2018-04-22T05:54:24.671Z","comments":true,"path":"2018/01/08/信号量和自旋锁的区别/","link":"","permalink":"http://roux.top/2018/01/08/信号量和自旋锁的区别/","excerpt":"区别 区别一：实现方式 自旋锁是自旋等待，进程状态始终处于TASK_RUNNING。 信号量是睡眠等待，进程在等待时处于TASK_INTERRUPTIBLE。","text":"区别 区别一：实现方式 自旋锁是自旋等待，进程状态始终处于TASK_RUNNING。 信号量是睡眠等待，进程在等待时处于TASK_INTERRUPTIBLE。 区别二：睡眠死锁陷阱： 在自旋锁的临界区中，进程是不能陷入睡眠的。 信号量可以睡眠。 同时，基于上面的原因，中断上下文中只能使用自旋锁（中断里不能休眠），在有睡眠代码的临界区只能使用信号量。 区别三：CPU的使用情况： 信号量对系统的负载小，因为它睡眠等待。 区别四：执行的效率方面： 自旋锁的效率比较高，因为它少了进程状态切换的消耗。 信号量的效率比较低，因为进程的等待需要切换进程状态。 区别五：上锁的时间长短： 因为自旋锁是忙等待，所以临界区的代码不能太长。 信号量可以使用在运行时间较长的临界区代码。 区别六：是否关抢占： 自旋锁是关抢占的，所以在单处理器非抢占的内核下，自旋锁是没用的，是空操作。 信号量并没有关抢占，所以，只有需要获得锁的进程才会睡眠，其他进程还可以继续运行。","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"锁","slug":"锁","permalink":"http://roux.top/tags/锁/"}]},{"title":"进程与线程","slug":"进程与线程","date":"2017-12-12T16:00:00.000Z","updated":"2018-04-22T05:56:45.870Z","comments":true,"path":"2017/12/13/进程与线程/","link":"","permalink":"http://roux.top/2017/12/13/进程与线程/","excerpt":"前言 网络编程也学了挺长时间了，想着把最基本的进程和线程捋一捋，为后面的进阶把基础弄扎实点。本文是我们学习交流发的，也不知道出处，在此感谢！文末有两篇文章讲解的很棒，结合起来细细品读，进线程基本就ok了！","text":"前言 网络编程也学了挺长时间了，想着把最基本的进程和线程捋一捋，为后面的进阶把基础弄扎实点。本文是我们学习交流发的，也不知道出处，在此感谢！文末有两篇文章讲解的很棒，结合起来细细品读，进线程基本就ok了！ 进程与线程的区别和联系 进程： 进程是并发执行的程序在执行过程中分配和管理资源的基本单位,是一个动态的概念,操作系统分配资源的基本单位。 每一个进程都有自己的空间，在内存中有其完备的数据空间和代码空间，即进程空间或(虚空间).一个进程所拥有的数据和变量只属于它自己。 线程： 在网络或多用户环境下，一个服务器通常需要接收大量且不确定数量用户的并发请求，为每一个请求都创建一个进程显然是行不通的，——无论是从系统资源开销方面或是响应用户请求的效率方面来看。因此，操作系统中线程的概念便被引进了。线程，是进程的一部分，一个没有线程的进程可以被看作是单线程的。 线程有时又被称为轻权进程或轻量级进程，也是 CPU 调度的一个基本单位。（最简单的比喻多线程就像火车的每一节车厢，而进程则是火车。车厢离开火车是无法跑动的，同理火车也不可能只有一节车厢。多线程的出现就是为了提高效率。） 区别： 进程和线程的主要差别在于它们是操作系统不同的资源管理方式. 进程有独立的地址空间,一个进程崩溃后,在保护模式下不会对其他进程产生影响,而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。 进程拥有一个完整的虚拟地址空间，不依赖于线程而独立存在；反之，线程是进程的一部分，没有自己的地址空间，与进程内的其他线程一起共享分配给该进程的所有资源。 简而言之： 一个程序至少有一个进程,一个进程至少有一个线程. 线程的划分尺度小于进程,使得多线程的程序并发性高 另外,进程在执行过程中拥有独立的内存单元,而多线程共享内存,从而极大地提高了程序的运行效率 线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。 从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。 优缺点： 线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反。同时，线程适合于在SMP(多核处理机)机器上运行，而进程则可以跨机器迁移。 进程池线程池的概念 进程池和线程池很相似，所以只介绍进程池。 进程池是由服务器预先创建的一组进程，这些子进程的数目在3-10个之间.http守护进程就是使用了包含7个子进程的进程池来实现并发的。线程池中的线程数量和CPU的数量差不多。 进程池中的所有子进程都运行着相同的代码，并具有相同的属性，比如优先级，PGID等。因为进程池在服务器启动之初就创建好了，所以他们不用打开不必要的文件描述符（从父进程继承下来的），也不会错误的使用大块的堆内存（复制父进程的） 当有新的任务到来时，主进程将通过某种方式选择进程池中的某一个进程来为之服务。相对于动态创建子进程，选择一个已经存在的子进程的代价明显要小的多。 关于创建池的数量 CPU密集型任务主要消耗大量CPU资源，大量地进行计算。由于依靠CPU性能，一直占用CPU进行计算，也就说一般情况下能够采用多任务的数量等于CPU核心数。 IO密集型任务（磁盘读取，web服务）主要需要IO的读取，利用CPU的效率较低，大量时间花费在IO上。由于现在有异步IO技术，也就是说一个任务在IO等待时间时可以暂停运行，让CPU的空闲时间用来运行其他任务，等到IO读取完毕后在继续执行。从而实现单核CPU上运行单进程却能实现多任务的并发，此时线程数量应大于CPU的数量 具体: 12345C: CPU核心数 N：进程或线程数C &lt;= N &lt;= M*C+n （1 &lt;= M &lt;= 7) n&lt;CM 进程：约3～4，线程：7～8 进程池与线程池的区别 进程池 优点：健壮性高，操作系统以进程为单位去分配资源 缺点： 占用资源高 进程间通讯代价大 进程切换需要保护上下文，开销大 线程池 优点：轻量级，通信代价小,线程间切换开销小。 缺点：健壮性不高，共享资源使用不当会导致错误。 子进程选择算法 主进程通过某种算法主动选择子进程。最简单、最常用的算法是轮流选取算法。 主进程和所有的子进程都在同一个共享的队列中，刚开始都处于睡眠状态，当有新的任务到来时，主进程将任务添加到消息队列中。将会通过算法来使其中一个子进程唤醒，这个子进程将任务取出并执行，而其他进程还处于睡眠状态。 当选择了一个子进程之后，主进程还要告诉子进程执行任务所需要的数据，而传递这些数据就要在子进程和主进程之间创建一个管道。可以将这些数据全都定义为全局变量，而这些数据将会被所有的线程共享。 为什么要用进程池（线程池） 一个子进程是通过进程动态内存分配的方式创建的，这种创建子进程的方式虽然能够获得资源，但是是有很多缺点： 动态创建进程是比较耗时间的，这将导致较慢的客户响应。 动态创建的子进程（或子线程）通常只用来为一个客户服务。这将导致系统上产生大量的进程（线程），这将使进程间（线程）间切换消耗大量的CPU资源。 动态创建出来的子进程（线程）是父进程（线程）的完整映射。当前进程（线程）必须谨慎的管理其分配的文件描述符和堆内存等系统资源，从而使系统的可用资源急剧下降，进而影响服务器性能。 由于系统的资源有限，这将是动态创建的进程（线程）数量有限，从而会使响应客户端请求的数量有上线。 为了有效的解决在大量连接下的客户请求，就要采用一种方式来避开动态创建带来的缺点。进程（线程）池是通过事先划分一块系统资源区，这块区域在系统启动时 就已经创建并初始化了。用户可以直接取得资源，从而避免动态分配资源。 运用池的优点： 可以执行大量相对短暂的任务 当任务增加的时候能够动态的增加进程池（线程池)中的进程（线程）的数量直到达到一定的阈值。 当任务执行完毕时，能够动态的销毁线程（进程）池中的线程（进程）。 系统开销少，能够统一管理。 SOURCE 进线程区别详解 线程的实质","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"进程","slug":"进程","permalink":"http://roux.top/tags/进程/"}]},{"title":"前缀、中缀、后缀表达式转换详解","slug":"前缀-后缀-中缀","date":"2017-12-11T16:00:00.000Z","updated":"2017-12-12T06:02:16.905Z","comments":true,"path":"2017/12/12/前缀-后缀-中缀/","link":"","permalink":"http://roux.top/2017/12/12/前缀-后缀-中缀/","excerpt":"前言 前面学过树的遍历及转换，感触不是很深，今天回头来看，另有感悟。这种感悟也是得益于大神的博文，记录于此。","text":"前言 前面学过树的遍历及转换，感触不是很深，今天回头来看，另有感悟。这种感悟也是得益于大神的博文，记录于此。 中缀表达式转后缀表达式 假定有中缀表达式 1 + (( 2 + 3) * 4 ) – 5，请将它转化为后缀表达式。 方法一：利用表达式树 首先将中缀表达式转换为表达式树，然后后序遍历表达式树，所得结果就是后缀表达式。 将中缀表达式转化为表达式树方法：表达式树的树叶是操作数，而其他的节点为操作符，根节点为优先级最低且靠右的操作符（如上述表达式优先级最低的是 - 和 +，但 + 更靠右，所以根为 + ），圆括号不包括(后面左右孩子可以类似的递归处理)。如上述中缀表达式转换后的表达式树如下： 经过后序遍历表达式树后得到的后缀表达式为：12 3 + 4 * + 5 – 方法二：利用辅助栈 从左到右遍历中缀表达式的每个操作数和操作符。当读到操作数时，立即把它输出，即成为后缀表达式的一部分；若读到操作符，判断该符号与栈顶符号的优先级，若该符号优先级高于栈顶元素，则将该操作符入栈，否则就一次把栈中运算符弹出并加到后缀表达式尾端，直到遇到优先级低于该操作符的栈元素，然后把该操作符压入栈中。如果遇到 (，直接压入栈中，如果遇到一个 )，那么就将栈元素弹出并加到后缀表达式尾端，但左右括号并不输出。最后，如果读到中缀表达式的尾端，将栈元素依次完全弹出并加到后缀表达式尾端。 仍然以上面的表达式为例，其转换过程如下： 利用辅助栈后缀表达式与用表达式树的结果一样，都为：1 2 3 + 4 * + 5 – 后缀表达式转换为中缀表达式 假定有后缀表达式1 2 3 + 4 * +5 –，请将它转化为中缀表达式。 方法一：利用表达式树 从左到右扫面后缀表达式，一次一个符号读入表达式。如果符号是操作数，那么就建立一个单节点树并将它推入栈中。如果符号是操作符，那么就从栈中弹出两个树T1和T2（T1先弹出）并形成一颗新的树，该树的根就是操作符，它的左、右儿子分别是T2和T1。然后将指向这棵新树的指针压入栈中。 前三个符号是操作数，因此创建三颗单节点树并将指向它们的指针压入栈中。 +被读入，因此指向最后两颗树的指针被弹出，形成一颗新树，并将指向新树的指针压入栈中。以下的流程图以相同原理执行。 最后再中序遍历所得的表达式树即得到我们所需的中缀表达式：1+（（2 + 3）* 4）-5 中缀表达式转换为前缀表达式 假定有中缀表达式1 + (( 2 + 3) * 4 ) – 5，请将它转化为前缀表达式。 方法一：利用表达式树 先将表达式用表达式树来表示，然后再前序遍历表达式树即得到我们所需的前缀表大式。(表达式树前面已经介绍过，这里不再累赘)。 此处，经过前序遍历所得前缀表达式为：- + 1 * + 2 3 4 5 方法二：利用辅助栈 首先构造一个运算符栈，然后从右至左扫描中缀表达式。如果是操作数，则直接输出，作为前缀表达式的一个直接转换表达式Temp（最后，前缀表达式由该表达式翻转得到）；如果是运算符，则比较优先级：若该运算符优先级大于等于栈顶元素，则将该运算符入栈，否则栈内元素出栈并加到Temp表达式尾端，直到该运算符大于等于栈顶元素的优先级时，再将该运算符压入栈中。遇到右括号直接压入栈中，如果遇到一个左括号，那么就将栈元素弹出并加到Temp表达式尾端，但左右括号并不输出。最后，若运算符栈中还有元素，则将元素一次弹出并加到Temp表达式尾端，最后一步是将Temp表达式翻转。其过程如下图所示： 从右到左开始扫描，5为数字放入Temp中，-为操作符入栈。 遇到左括号，元素弹出直到遇到右括号为止。 所得前缀表达式为：- + 1 * + 2 3 4 5 前缀表达式转换为中缀表达式： 假定有前缀表达式 - + 1 * + 2 3 4 5，请将它转化为中缀表达式。 方法一：辅助栈 首先创建一个数字栈。从右到左扫描前缀表达式，如果遇到操作数，则入栈。如果遇到操作符，则将栈顶元素弹出（后扫面的数字位于表达式前面），并和操作符结合写成表达式，作为中缀表达式。如果遇到的操作符优先级大于已存在表达式的最后执行操作符的优先级，则将已存在的表达式加上()。如下是前缀表达式转为中缀表达式的示意图： 扫描到操作数直接入栈。 扫描到操作符，将两个栈顶元素弹出，并和操作符结合写成表达式。 表达式不是（2+3）*4 + 1，因为 1 比 2、3、4 后扫描到。(如果不好理解，可以这样思考：遇到操作符出栈结合成为一个表达式，然后将这个表达式入栈，然后继续下一步(将整个表达式当做一个整体操作数)) 表达式不是5-（1+（2+3）*4），因为 5 是最早扫面到的数字。 所以中缀表达式为(1 +（2 + 3）* 4） - 5。 SOURCE http://blog.csdn.net/walkerkalr/article/details/22798365","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://roux.top/categories/数据结构/"}],"tags":[{"name":"树","slug":"树","permalink":"http://roux.top/tags/树/"}]},{"title":"线程池浅析","slug":"线程池","date":"2017-12-11T16:00:00.000Z","updated":"2017-12-12T13:59:26.774Z","comments":true,"path":"2017/12/12/线程池/","link":"","permalink":"http://roux.top/2017/12/12/线程池/","excerpt":"池 由于服务器的硬件资源“充裕”，那么提高服务器性能的一个很直接的方法就是以空间换时间，即“浪费”服务器的硬件资源，以换取其运行效率。这就是池的概念。池是一组资源的集合，这组资源在服务器启动之初就完全被创建并初始化，这称为静态资源分配。当服务器进入正是运行阶段，即开始处理客户请求的时候，如果它需要相关的资源，就可以直接从池中获取，无需动态分配。很显然，直接从池中取得所需资源比动态分配资源的速度要快得多，因为分配系统资源的系统调用都是很耗时的。当服务器处理完一个客户连接后，可以把相关的资源放回池中，无需执行系统调用来释放资源。从最终效果来看，池相当于服务器管理系统资源的应用设施，它避免了服务器对内核的频繁访问。 池可以分为多种，常见的有内存池、进程池、线程池和连接池。","text":"池 由于服务器的硬件资源“充裕”，那么提高服务器性能的一个很直接的方法就是以空间换时间，即“浪费”服务器的硬件资源，以换取其运行效率。这就是池的概念。池是一组资源的集合，这组资源在服务器启动之初就完全被创建并初始化，这称为静态资源分配。当服务器进入正是运行阶段，即开始处理客户请求的时候，如果它需要相关的资源，就可以直接从池中获取，无需动态分配。很显然，直接从池中取得所需资源比动态分配资源的速度要快得多，因为分配系统资源的系统调用都是很耗时的。当服务器处理完一个客户连接后，可以把相关的资源放回池中，无需执行系统调用来释放资源。从最终效果来看，池相当于服务器管理系统资源的应用设施，它避免了服务器对内核的频繁访问。 池可以分为多种，常见的有内存池、进程池、线程池和连接池。 线程池 线程池 线程池是一种多线程处理形式，处理过程中将任务添加到队列，然后在创建线程后自动启动这些任务。线程池线程都是后台线程。每个线程都使用默认的堆栈大小，以默认的优先级运行，并处于多线程单元中。如果某个线程在托管代码中空闲（如正在等待某个事件）,则线程池将插入另一个辅助线程来使所有处理器保持繁忙。如果所有线程池线程都始终保持繁忙，但队列中包含挂起的工作，则线程池将在一段时间后创建另一个辅助线程但线程的数目永远不会超过最大值。超过最大值的线程可以排队，但他们要等到其他线程完成后才启动。 使用线程的问题 在服务器应用程序中，串行处理机制通常都无法提供高吞吐率或快速响应性。也有一些例外，如当任务数量很少且执行时间很长时，或当服务器只为单个用户提供服务，并且该客户每次只发出一个请求时，但大多数应用程序并不是按照这种方式来工作的。 一般可以通过为每个请求创建一个新的线程来提供服务，从而实现更高的响应性，如果每个线程调用的是同一个业务处理方法，那这个方法必须设计为线程安全的。在正常负载情况下，为每个任务分配一个线程的方法能提升串行执行的性能。只要请求的到达速率不超出服务器的请求处理能力，那么这种方法可以同时带来更快的响应性和更高的吞吐率。 在生产环境中，为每个任务分配一个线程 这种方法存在一些缺陷，尤其是当需要创建大量的线程时： 线程生命周期的开销非常高。 资源消耗。活跃的线程会消耗系统资源，尤其是内存；大量空闲的线程也会占用许多内存，给垃圾回收器带来压力。而且大量线程在竞争cpu资源时还将产生其他的性能开销。 稳定性。在可创建线程的数量上存在一个限制，这个限制值随平台的不同而不同。 在一定范围内，增加线程可以提高系统的吞吐率，但如果超出了这个范围，再创建更多的线程只会降低程序的执行速度，并且如果过多创建线程整个程序可能崩溃。 为什么用线程池 创建/销毁线程伴随着系统开销，过于频繁的创建/销毁线程，会很大程度上影响处理效率 例如： 记创建线程消耗时间T1，执行任务消耗时间T2，销毁线程消耗时间T3 如果T1+T3&gt;T2，那么是不是说开启一个线程来执行这个任务太不划算了！ 正好，线程池缓存线程，可用已有的闲置线程来执行新任务，避免了T1+T3带来的系统开销 线程并发数量过多，抢占系统资源从而导致阻塞(同时避免创建过多的线程) 我们知道线程能共享系统资源，如果同时执行的线程过多，就有可能导致系统资源不足而产生阻塞的情况 运用线程池能有效的控制线程最大并发数，避免以上的问题 对线程进行一些简单的管理 比如：延时执行、定时循环执行的策略等运用线程池都能进行很好的实现 线程池的构成 线程池管理器:用于创建并经管线程池 工作线程: 线程池中实际履行的线程 任务接口: 尽管线程池大多半场景下是用来支撑收集办事器，然则我们将线程履行的任务抽象出来，形成任务接口，从而达到线程池与具体的任务无关。 任务队列:线程池的概念具体到实现则可能是队列，链表之类的数据布局，此中保存履行线程。 线程池处理流程 线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的核心工作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。 线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。 线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的非核心工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。 线程池的使用 只有当任务都是同类型的并且相互独立时，线程池的性能才能达到最佳。 如果将运行时间较长的与运行时间较短的任务混合在一起，那么除非线程池很大，否则可能造成拥塞，因为很有可能在线程池中运行的都是运行时间较长的任务，其他任务得不到响应； 如果提交的任务依赖于其他任务，那么除非线程池无限大，否则可能造成死锁。 将可以并行进行的方法（任务）放入线程的run（或call）方法里执行，然后把线程放入线程池就可以实现线程池调度任务了。 线程池的应用范围 需要大量的线程来完成任务，且完成任务的时间比较短。 像WEB服务器完成网页请求这样的任务，使用线程池技术是非常合适的。因为单个任务小，而任务数量巨大，你可以想象一个热门网站的点击次数。 但对于长时间的任务，比如一个Telnet连接请求，线程池的优点就不明显了。因为Telnet会话时间比线程的创建时间大多了。 对性能要求苛刻的应用，比如要求服务器迅速响应客户请求。 接受突发性的大量请求，但不至于使服务器因此产生大量线程的应用。突发性大量客户请求，在没有线程池情况下，将产生大量线程，虽然理论上大部分操作系统线程数目最大值不是问题，短时间内产生大量线程可能使内存到达极限，并出现OutOfMemory的错误。 线程池的合理配置 要想合理地配置线程池，就必须首先分析任务特性，可以从以下几个角度来分析： 任务的性质：CPU密集型任务、IO密集型任务和混合型任务。 任务的优先级：高、中和低。 任务的执行时间：长、中和短。 任务的依赖性：是否依赖其他系统资源，如数据库连接。 分析 性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务应配置尽可能小的线程，如配置 Ncpu + 1 个线程的线程池。由于IO密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程，如2 * Ncpu。混合型的任务，如果可以拆分，将其拆分成一个CPU密集型任务和一个IO密集型任务，只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量将高于串行执行的吞吐量。如果这两个任务执行时间相差太大，则没必要进行分解。 优先级不同的任务可以使用优先级队列来处理。它可以让优先级高的任务先执行。 注意：如果一直有优先级高的任务提交到队列里，那么优先级低的任务可能永远不能执行。 执行时间不同的任务可以交给不同规模的线程池来处理，或者可以使用优先级队列，让执行时间短的任务先执行。 依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，等待的时间越长，则CPU空闲时间就越长，那么线程数应该设置得越大，这样才能更好地利用CPU。 SOURCE C++实现的线程池收集 简单的C线程池的实现 JAVA版本的详细解释","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"线程","slug":"线程","permalink":"http://roux.top/tags/线程/"}]},{"title":"Git操作命令","slug":"Git命令","date":"2017-12-11T16:00:00.000Z","updated":"2018-04-22T05:58:16.139Z","comments":true,"path":"2017/12/12/Git命令/","link":"","permalink":"http://roux.top/2017/12/12/Git命令/","excerpt":"前言 学习中经常用到GitHub，但是一直只会一些简单的操作，偶尔碰到复杂的需求(或者一些细小的但是很重要的问题)的时候，又要去Google，往往会花费一定的时间(时间累积起来也很害怕哟)，所以对一些常用的命令做一些总结，顺便把找到的一些好的教程保存下来，节省查找一些时间。 在线练习—强烈推荐","text":"前言 学习中经常用到GitHub，但是一直只会一些简单的操作，偶尔碰到复杂的需求(或者一些细小的但是很重要的问题)的时候，又要去Google，往往会花费一定的时间(时间累积起来也很害怕哟)，所以对一些常用的命令做一些总结，顺便把找到的一些好的教程保存下来，节省查找一些时间。 在线练习—强烈推荐 命令啊命令 查看、添加、提交、删除、找回，重置修改文件 1234567891011121314151617181920212223242526272829git help &lt;command&gt; # 显示command的helpgit show # 显示某次提交的内容 git show $idgit co -- &lt;file&gt; # 抛弃工作区修改git co . # 抛弃工作区修改git add &lt;file&gt; # 将工作文件修改提交到本地暂存区git add . # 将所有修改过的工作文件提交暂存区git rm &lt;file&gt; # 从版本库中删除文件git rm &lt;file&gt; --cached # 从版本库中删除文件，但不删除文件git reset &lt;file&gt; # 从暂存区恢复到工作文件git reset -- . # 从暂存区恢复到工作文件git reset --hard # 恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改git ci &lt;file&gt; git ci . git ci -a # 将git add, git rm和git ci等操作都合并在一起做 git ci -am &quot;some comments&quot;git ci --amend # 修改最后一次提交记录git revert &lt;$id&gt; # 恢复某次提交的状态，恢复动作本身也创建次提交对象git revert HEAD # 恢复最后一次提交的状态 查看文件diff 1234567891011git diff &lt;file&gt; # 比较当前文件和暂存区文件差异 git diffgit diff &lt;id1&gt;&lt;id2&gt; # 比较两次提交之间的差异git diff &lt;branch1&gt;..&lt;branch2&gt; # 在两个分支之间比较git diff --staged # 比较暂存区和版本库差异git diff --cached # 比较暂存区和版本库差异git diff --stat # 仅仅比较统计信息 查看提交记录 1234567git log git log &lt;file&gt; # 查看该文件每次提交记录git log -p &lt;file&gt; # 查看每次详细修改内容的diffgit log -p -2 # 查看最近两次详细修改内容的diffgit log --stat #查看提交统计信息 Mac上可以使用tig代替diff和log，brew install tig Git 本地分支管理 查看、切换、创建和删除分支 1234567891011121314151617181920212223git br -r # 查看远程分支git br &lt;new_branch&gt; # 创建新的分支git br -v # 查看各个分支最后提交信息git br --merged # 查看已经被合并到当前分支的分支git br --no-merged # 查看尚未被合并到当前分支的分支git co &lt;branch&gt; # 切换到某个分支git co -b &lt;new_branch&gt; # 创建新的分支，并且切换过去git co -b &lt;new_branch&gt; &lt;branch&gt; # 基于branch创建新的new_branchgit co $id # 把某次历史提交记录checkout出来，但无分支信息，切换到其他分支会自动删除git co $id -b &lt;new_branch&gt; # 把某次历史提交记录checkout出来，创建成一个分支git br -d &lt;branch&gt; # 删除某个分支git br -D &lt;branch&gt; # 强制删除某个分支 (未被合并的分支被删除的时候需要强制) 分支合并和rebase 12345git merge &lt;branch&gt; # 将branch分支合并到当前分支git merge origin/master --no-ff # 不要Fast-Foward合并，这样可以生成merge提交git rebase master &lt;branch&gt; # 将master rebase到branch，相当于： git co &lt;branch&gt; &amp;&amp; git rebase master &amp;&amp; git co master &amp;&amp; git merge &lt;branch&gt; Git补丁管理(方便在多台机器上开发同步时用) 12345git diff &gt; ../sync.patch # 生成补丁git apply ../sync.patch # 打补丁git apply --check ../sync.patch #测试补丁能否成功 Git暂存管理 1234567git stash # 暂存git stash list # 列所有stashgit stash apply # 恢复暂存的内容git stash drop # 删除暂存区 Git远程分支管理 1234567891011git pull # 抓取远程仓库所有分支更新并合并到本地git pull --no-ff # 抓取远程仓库所有分支更新并合并到本地，不要快进合并git fetch origin # 抓取远程仓库更新git merge origin/master # 将远程主分支合并到本地当前分支git co --track origin/branch # 跟踪某个远程分支创建相应的本地分支git co -b &lt;local_branch&gt; origin/&lt;remote_branch&gt; # 基于远程分支创建本地分支，功能同上 git push # push所有分支 123456789git push origin master # 将本地主分支推到远程主分支git push -u origin master # 将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库)git push origin &lt;local_branch&gt; # 创建远程分支， origin是远程仓库名git push origin &lt;local_branch&gt;:&lt;remote_branch&gt; # 创建远程分支git push origin :&lt;remote_branch&gt; #先删除本地分支(git br -d &lt;branch&gt;)，然后再push删除远程分支 Git远程仓库管理 1234567git remote -v # 查看远程服务器地址和仓库名称git remote show origin # 查看远程服务器仓库状态git remote add origin git@ github:robbin/robbin_site.git # 添加远程仓库地址git remote set-url origin git@ github.com:robbin/robbin_site.git # 设置远程仓库地址(用于修改远程仓库地址) git remote rm &lt;repository&gt; # 删除远程仓库 创建远程仓库 12345678910111213git clone --bare robbin_site robbin_site.git # 用带版本的项目创建纯版本仓库scp -r my_project.git git@ git.csdn.net:~ # 将纯仓库上传到服务器上mkdir robbin_site.git &amp;&amp; cd robbin_site.git &amp;&amp; git --bare init # 在服务器创建纯仓库git remote add origin git@ github.com:robbin/robbin_site.git # 设置远程仓库地址git push -u origin master # 客户端首次提交git push -u origin develop # 首次将本地develop分支提交到远程develop分支，并且trackgit remote set-head origin master # 设置远程仓库的HEAD指向master分支 也可以命令设置跟踪远程库和本地库 123git branch --set-upstream master origin/mastergit branch --set-upstream develop origin/develop SOURCE 资料：https://www.gitbook.com/book/tycn/git/details 资料：https://github.com/xirong/my-git/blob/master/ixirong.com.md 通俗易懂：http://blog.jobbole.com/78960/","categories":[{"name":"Tools","slug":"Tools","permalink":"http://roux.top/categories/Tools/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://roux.top/tags/Git/"}]},{"title":"关于袜子的一些问题","slug":"袜子","date":"2017-12-10T16:00:00.000Z","updated":"2018-04-22T05:56:35.102Z","comments":true,"path":"2017/12/11/袜子/","link":"","permalink":"http://roux.top/2017/12/11/袜子/","excerpt":"前言 明天就是双十二了，想起冬天刚好没棉袜穿了，上淘宝一搜，一大堆(我的天呀，各种类型和品牌，看得我一脸懵逼！)，也不知道怎么买(没有女朋友的我，麻木！)，想了想就上网搜了下，也没找到一些有用的参考(全部是淘宝的宣传。。。)，最终在微博上发现了一篇文章，看了下写的还是很详细很有用的，就转载留着以后用，哈哈。。。。。。","text":"前言 明天就是双十二了，想起冬天刚好没棉袜穿了，上淘宝一搜，一大堆(我的天呀，各种类型和品牌，看得我一脸懵逼！)，也不知道怎么买(没有女朋友的我，麻木！)，想了想就上网搜了下，也没找到一些有用的参考(全部是淘宝的宣传。。。)，最终在微博上发现了一篇文章，看了下写的还是很详细很有用的，就转载留着以后用，哈哈。。。。。。 袜子啊袜子 都说脚是人的第二心脏。对于双脚的健康来说，一双好袜子可能跟一双好鞋一样重要。美国《悦己》杂志最新载文指出，出现3种情况，说明你的袜子就该淘汰了。 出现三种情况袜子就该淘汰: 失去弹性。袜子失去弹性，就会加大与双脚的摩擦，走路或运动时不跟脚，如果出汗，还会有滑腻的感觉，很容易受伤。 脚后跟变薄，有破洞。袜子穿久了必然会变薄，这也会导致脚跟受伤或起泡。 穿上不舒服。双脚有紧绷、刺痒，明显勒痕等不适感时，说明袜子不合适。 如何买到合适的袜子？别看袜子小，但想要买一双合适的也不容易。对此，美国德利麦克斯袜子专家组提出了以下建议： 少选羊毛袜。这种材质的袜子吸汗效果不好，易使双脚处于潮湿状态，引起水泡。一般情况下，最好选择棉袜，但如果去运动，建议购买灯芯绒材质的袜子，吸汗效果较好。 合脚和尺码非常重要。袜子应该完全合脚，不应太紧或太松。袜子过大，额外的纤维会加重摩擦，并损伤脚部皮肤。 注意纤维密度。买袜子时，应该注意袜子纤维密度，太疏松的不建议买。 另外，脚趾分开袜、足弓束带袜等高品质的袜子，每个人也应该备几双。 选袜子的六字口诀。大家都知道，脚是人的”第二心脏”。所以，选对袜子比穿双好鞋更重要。有专家推荐了几条选择袜子的标准。 谨记”紧松大光齐清”6字口诀。即袜口和袜筒松紧合适，袜底要松，袜后跟大，袜表面光滑，罗口平齐无歪斜，针纹组织清晰，花纹、袜头、袜跟无露针。 颜色尽量和鞋里一致，购买儿童袜子优先选择浅色的，颜色越鲜艳的，里面添加化学成分就越多。 优先选择以棉纤维为主、加上适量弹性纤维的袜子。 考虑其用途和穿着对象，如日常穿着以舒适、透气为主，运动时穿着要以柔软、耐磨为主；汗脚者宜选购既透气又吸湿的棉线袜子，脚干裂者就选购吸湿性较差的涤纶袜和锦纶袜；儿童袜要尽量选择组织结构简单、浅颜色、表面平滑的袜子，不要选择有虚线露在外面的袜品。 在洗涤袜子时，切不可用力揉搓，以防止袜子在强烈摩擦后使袜丝滑出或断丝；洗涤袜子的水温不宜超过40℃，否则会使袜子受热后收缩、袜底变小，甚至还会使袜子硬化、变质。为了保持袜子的原有光泽，最好不要用含碱过多的肥皂，只要用手轻搓后，用清水冲净，放在阴凉通风处阴干。 大小规格篇 袜子的规格是用袜号表示的，而袜号又是以袜底的实际长度尺寸为标准的，所以知道自己的脚长后便可选购合脚的袜子。可是，由于袜子所使用的原料不同，其在袜号系列上也有所不同。其中弹力尼龙袜，以袜长相差2cm为1档；棉纱线袜、锦纶丝袜、混纺袜等的袜号系列，则以相差1cm为1档。 如何选择大小呢？首先，测量一下自己脚的长度。知道自己脚的长度后，可以挑选袜号。袜号以厘米为单位，袜号根据弹性的大小基本分成三个类型。 第一类，没有弹性的棉袜、锦纶丝袜。这类袜子的袜号一般一厘米一档，袜号有：10、11、12、13、14、15、16、17、18、19、20、21、22、23、24、25、26、27、28、29、30。例如袜号10，即对应10cm的脚长。 第二类，由有弹性的锦纶或涤纶和没有弹性的棉交织，使袜子具有一定的弹性。袜号有：15~16、17~18、19~20、21~22、23~24、25~26、27~28。例如袜号为15~16，即15~16cm的脚适合。 第三类，由高弹性的锦纶丝或氨纶包芯纱与棉交织，使袜子具有较大的伸展性。袜号有：12~14、14~16、16~18、18~20、20~22、22~24、24~26、26~28、28~30。例如袜号为12~14，即12~14cm的脚适合。 材质篇 袜子的材质主要有以下几种： 棉是传统的天然纤维，也是舒适度较高的纺织材料，直到今天仍然在大量的使用。不过，棉本身的性能就有很大的局限性。棉纤维的吸湿性很好，吸湿的速度很快，但是排湿就不行了，棉纤维湿了以后，干的会很慢的。 羊毛也是一种传统的天然纤维，它是以良好的保暖性而著称，但是，普通的羊毛是不太适合做袜子的，必须选用材质较高的羊毛，如：澳洲的MERINOWOOL（美丽奴羊毛）、NEWWOOL（新毛）等，都是很好的内衣和袜子的材料。不过，很多人会发现，用羊毛直接做贴身衣物的很少，即使有，价格也比较昂贵，这主要是由羊毛本身的结构特性决定的。在显微镜下，可以看到羊毛纤维有很多鳞片，排列有点象竹笋叶，而每一个鳞片的顶部都有一个角质化的尖，这个角质化的尖容易使羊毛纤维之间产生粘连现象，又叫赶粘，同时，这个角质化的尖又使羊毛在贴身时会有刺痒的感觉，所以，如果选用羊毛材料做袜子之类的贴身衣物时，必须将这个角质化的尖去掉，这道处理的费用相对较高，是造成产品昂贵的主要原因之一。羊毛本身的特性是保暖，同时它的吸湿性和排湿较差，在与其他纤维混纺或混织后，可制成很好的冬季保暖袜。 莱卡、氨纶和橡筋，全是弹性材料。莱卡是美国杜邦公司的注册商标，其实也是氨纶的一种，所以又叫莱卡氨伦，只不过是处理上要比普通氨纶要好得多，其延展和回复性都相当好，而且不易老化，现在，很多的户外品牌的袜子都选用莱卡来做弹性材料。橡筋实际就是橡皮筋，当然用来做袜子的要细得多，和纱一样细，是在制造过程中织进袜子里的，橡筋比较容易老化，在被汗水腐蚀或经过冬天的严寒以后会很容易失去原有的延展和会复性，象对于户外运动的专业运动袜这样比较昂贵的袜子来说，这一特性就使它不太经济核算了。不过，现在日本有一种橡筋，听说持久耐用性很好，还是在推广阶段。 NYLON（尼龙），有的成份标识上又叫锦纶，在户外运动袜里面是专门加强牢固度的，尼龙的加入何以延长袜子的使用寿命，不易损坏。 对于运动袜，特别是专业性很强的户外运动的专业运动袜，还必须有一些特殊的纤维的添加来突出它的专业功能性。这其中，COOLMAX是经常被用到的。COOLMAX是美国杜邦公司的专利纤维产品，纺织上又叫四管道异型聚酯纤维。普通的纤维横截面多是实心的圆形或椭圆型，而COOLMAX这种纤维是空心的，横截面程十子型，就象四根被并列在一起的管子。这种结构使纤维与空气的接触面积加大，在织物之间也同时保证了很多的空隙，这样一来，就保证了COOLMAX这种纤维具有很强的吸湿性和排湿性，掺有COOLMAX纤维的织物又有很好的透气性。要注意的是，COOLMAX是吸湿、导汗、透气的功能性纤维，并不是保暖纤维，它只不过是使湿气排出保持尽量干燥的保暖环境。 THERMOLITE是专门的保暖纤维，THERMOLITE也是美国杜邦公司的专利纤维产品，它和COOLMAX一样是聚酯纤维，同样结构也是中空的。据介绍，THERMOLITE是从北极熊的毛的结构受到启发而研制出来的，它的横截面是圆形的，中间是空的，象一根管子，这样一来可以提高纤维的蓬松度，从而达到保暖的效果，这个原理和羽绒的保暖原理有些类似。THERMOLITE的保暖效果很好，同时也有不错的排汗效果，是冬季保暖袜的比较理想的材料。 此外，还有竹纤维、兔毛等等的材质原料。在以后的发展中，也将会有更多的原料开发并运用到袜子里面。 结构篇 要知道什么样的袜子是合脚的，这就要了解袜子的结构。袜由袜口、袜统和袜脚3部分组成。其中袜脚包括袜跟、袜底和袜背、袜头。袜口的作用是使袜子边缘不致脱散并紧贴腿上。袜子的主要参数有5个：袜号、袜底长、总长、口长和跟高。在挑选的过程中我们没法一一测量，但是从以下几方面，我们可以大致判断哪些袜子才是合脚的。 首先，一定要有垫，就是在袜子的底部要有象毛巾一样的圈，所以又叫毛圈。毛圈的主要作用是增加鞋与脚之间的弹性，同时，也充分加大了袜子材料与空气接触的面积，使之有更好的吸湿排汗性，当然，吸湿排汗性的体现和材料也有很大的关系。针对不同强度的运动，毛圈的高度、密度和部位应该是有所不同的。在高海拔的登山中或极长途的行走，应该是在脚底、脚面部位都有毛圈的，而且毛圈的高度和密度都是最高的，这样才可以更好的全方位的对脚起到保护。在中长途的行走和中低海拔的登山中，一般袜子只要脚底部位加毛圈就够了，不过，毛圈的高度和密度还是要最高的要求。只有在短途行走和后勤补给比较充裕的行走中，如特种旅游和普通旅游，毛圈的高度和密度可以比较低，但是绝对不能没有，就是一般的体育锻炼，袜子也还是要有毛圈的。 其次，在袜子的脚弓部位一定要有一圈弹力的固定，使袜子能很好的贴服在脚上。过去经常有这样的事情发生：走了一段路以后，脚上的袜子全跑到前面去了，又或者袜子横着转开了，脚底的部位跑到脚侧面了，使脚很不舒服，这全是因为袜子与脚的贴附性差，所以，在脚弓部位加上弹性的固定，就可以尽可能的避免这类事情的发生。人的脚底在接触地面时，正常的话，脚弓部位接触地面最少，在行走时，脚弓所受到的摩擦最小，同时，这又是整个脚掌的中部，在这个部位加上固定是最合适的。弹性固定不能过紧，过紧一样会影响血液循环，也不能过松，否则起不到固定的作用，袜子在脚上一样会跑。 再有，袜子的脚尖、脚跟部位一定是要加厚，脚跟的受力是最大的，而脚尖又是相对比较薄弱的地方，特殊的保护是必要的。袜尖与袜子脚面部分的拼接一定要是平的，千万不能有棱，这个地方是脚面上的脚趾位置，如果接缝是棱的话，很容易把脚磨伤的。 袜身的主要部分就是这些，再有就是脚踝以上的部分，这部分基本上是露在鞋（靴）以外的，但是，也有一定的特殊要求。 先说脚踝。这部分一般是鞋帮的位置，加有毛圈的垫还是必要的，但是由于这一部分是脚最先与空气接触的位置，透气的功能在结构上就必须要体现出来，一般是在脚踝的正面，和鞋舌接触的地方采用结构比毛圈结构稍微稀疏的波纹结构，同时加入弹性材料。因为鞋舌的内层多采用泡沫弹性材料，比鞋其他地方的材料要软，摩擦力较小，所以波纹结构选在这一位置不会对脚产生伤害。脚踝又是脚本身活动最多的地方，加入弹性材料可以保证脚的正常活动不会有太多的束缚感。 季节搭配篇 在不同的季节，有不同的袜子供我们选择。 炎热的夏季，袜子以美观、舒适为主。这个季节女士选择最多的是含弹性纤维的丝袜。不是所有的弹性纤维都是莱卡，含莱卡的丝袜是比较高档的丝袜，它比一般丝袜具有更好的回弹性，更强的透气性，更柔和的色泽。现在又有了3D工艺，它使丝袜更光滑更轻软，穿着更舒适自由。一双好的丝袜能修饰腿部的不足，有美体的效果。 夏季容易出汗，纯化纤的丝袜排汗虽好，但容易有异味，天然纤维和化纤混纺的薄袜是男士的首选。一般人有个误区，觉得棉含量越高越好。其实，全棉的袜子，吸汗好，但不排汗，脚容易出现水泡。天然纤维含量在55%以上就可以了。含麻纤维的袜子是较好的选择，不仅具有天然的抗菌功能，还有良好的吸汗和排汗功能。 春秋二季是气温最舒适的季节，棉以它舒适的触觉作为这个季节袜子的首选。这个季节外出走动的频次较高，可以选择一些功能性的纤维和棉混纺的袜子。例如Lycra可以减低肌肉的疲劳，恢复体力；CoolMax具有强大的透气性，使运动时保持脚部的干爽；等等。 寒冷的冬季，袜子以保暖为主。一般含羊毛80%左右的混纺袜是较好的选择，它比纯毛的袜子更加结实，具有其他混纺功能性纤维的优良效果，又具有羊毛优良的保暖性能。 问答篇 有100%的棉袜吗？ 答：没有100%的棉袜。袜子本身是有弹性的，就说明袜子本身的成分里包含其他材料。如：氨纶、涤纶、锦纶等。氨纶主要的作用就是增加弹性，它具有高延性和高弹恢复率。因此掺有氨纶的袜子才会有弹性，不易缩水。而锦纶和涤纶具有强度高、耐磨性，掺有这些成分的袜子更加耐磨耐穿。含棉量在80%左右的袜子就可以称为全棉袜了。袜子不能说100%棉，因为袜子必须含有辅助成分，这样袜子才会具备良好的透气性，耐磨性，吸汗性！ 棉袜分多少种？ 答：通常含棉65%以上都是纯棉袜子，其实棉也分很多种类，如天然棉、精梳棉、丝光棉。 精梳棉是粗棉里提炼出来的比较好的棉，也因从不同等级棉里不同而价格不同，还有经过烧毛公艺出来的精梳棉一般都不会起球的，通常价格也比较贵的，总的来说精梳棉是属于中高档的运动袜、休闲袜。 丝光棉是在精梳棉的基础上加了蚕丝，处理工艺更精细一些。有光泽，最不像纯棉了。看上去像尼龙袜或丝袜（这也是大家最不认同它的地方：分不清楚），因为是含有蚕丝，穿上去比较舒适，耐磨损。是属于高档的皮鞋袜子的主要材质。 丝袜分多少种？ 答：丝袜有那么多品种，该如何选择呢？总的来说女丝袜有四类：天鹅绒，包芯丝，水晶丝，弹性丝袜。依价格排列，天鹅绒的价格是最贵的，弹性丝袜的价格是最便宜的。 天鹅绒袜的特点：采用进口材料设计编织，洗涤不变形；弹性佳，防勾丝处理，耐穿耐磨性增强三倍；具有承托力及按摩作用，穿着不易滑。缺点是价格较贵，透明度不如包芯丝。需要袜子透亮的MM请选择包芯丝。 包芯丝的特点：使用有多股超丝纤维合成一股的多孔原丝编织而成。具有更优良的柔软性和贴服性，多股纤维间的空气量多，透气性非常出色。但不如天鹅绒细腻，价格适中，由于轻薄透气的原因比天鹅绒更容易损坏，现在夏天一般都是使用包芯丝的比较多，穿着也比较舒服； 水晶丝的特点：水晶丝也有人叫它“玻璃丝”外表和包芯丝相似，有丝的感觉，比包芯丝更透亮，价格也比较便宜，但不如包芯丝贴脚，穿着的感觉不如包芯丝舒服； 最好讲讲弹性丝袜，弹性丝袜的透亮度不如包芯丝，质量方面也不如天鹅绒。属于老式工艺，编织的密度不如包芯丝等，不过手感也很柔软，穿着也比较服贴，价格便宜，适合对丝袜要求不高的MM穿着。 袜子里面多少“D”的含义？ 答：D：是指袜子纤维的纤度单位，每9000米纤维重多少克就称多少P。目前天鹅绒袜中，分6D“薄到底”，10D超薄，15D超薄，50D，80D，120D，150D，300D，到2000D不等。一般夏天可选用超薄的，春秋季节可选用50D，80D，120D，150D，在相同材料的情况下，D数越大则越厚！冬季可选用300D以上特厚保暖的天鹅绒袜。1600D的厚度基本上与普通棉毛裤差不多。包芯丝都是薄型的。 袜子里的四大健康问题 “虽说只是个配角，但如果每天都穿着不合格的袜子，就等于脚底下’踩着’一个隐形的健康杀手。”一般而言袜子隐藏四大健康问题。 不耐磨。”有些袜子穿一两次就有洞了，大家都会想这是由于自己穿着不当造成的，其实，这说明袜子的耐磨性不合格。”袜子需要在重要部位，比如脚趾处、脚跟处加入高强力的纤维，并采用更为科学的织制工艺才能保证耐磨性，耐磨性不好的袜子往往使用的是低档材料，不仅容易穿破，也有可能磨伤脚部。 掉色严重。袜子的染色牢度也是袜子是否合格的重要指标。按规定，袜子的染色牢度应该达到4级，即颜色基本不会掉。1级就是当拿一件白色的衣物和深色袜子放在一起洗的时候，最后两件物品的颜色会变得难以区分。 袜子掉色带来的问题不仅仅是污染其他衣物，更由于纺织产品在印染和后期整理等过程中要加入各种染料、助剂等整理剂，这些化学制剂或多或少都会含有或产生对人体有害的物质。 甲醛、芳香胺超标。按照流程，出厂前厂家要对袜子进行充分的水洗。因为在整个生产过程中会用到大量的含碱物质，没有充分清洗干净的袜子就会被检出很高的pH值。而甲醛和碱这两种物质都会对皮肤造成一定危害，比如容易引起过敏发炎等。 甲醛出现在袜子里，远比在衣物中更可怕。这是因为，人的脚掌上汗腺、血管、神经系统非常发达，当脚排出一些体液的时候，这些体液有可能会造成染料的分解。此外，袜子中的有害物质不易扩散，还会与脚部不停摩擦，加大对皮肤的影响。 袜口紧。近年来，袜厂生产的袜子多是紧口的，常把脚腕勒得紧紧的，甚至勒出了红痕。袜口对脚踝局部的压迫常常会导致血压增高，严重者甚至诱发心脏病。 不同的袜子怎么洗？ 有些人穿袜子其袜子很容易发臭，臭得甚至用洗洁剂也洗不掉。其实，在洗袜子时用些醋来洗，就可将袜子的臭味完全去除，而且还有杀菌作用。 专家说：”人们穿着袜子和鞋，非常容易出汗，也更容易感染细菌。” 袜子的除臭方法：有些人穿袜子其袜子很容易发臭，臭得甚至用洗洁剂也洗不掉。其实，在洗袜子时用些醋来洗，就可将袜子的臭味完全去除，而且还有杀菌作用。 不使袜子失去弹性：用洗衣机洗袜子时，先将橡皮筋扎起袜头的上面，用这方法就不会导致袜头失去弹性。除此之外，在晒晾时记得将袜头向上。 各种袜子清洗的科学方法： 普通棉线袜，要勤洗勤换，换下即放在清水中浸泡2小时左右，然后再擦上肥皂用热水揉洗，这样污垢容易脱落。 纯丝袜。人造丝袜、尼龙袜等，洗涤时要放在40℃以下的肥皂水或合成洗涤液中轻轻搓揉，切忌用力猛搓。袜子洗后要阴干，不可曝晒和火烤。 羊毛袜洗涤时，应先将含碱少的中性肥皂切成皂片，放入热水中溶化，等水降温后，再将袜子放入，稍浸片刻，然后用手轻轻搓洗。对污垢较多的袜头和袜后跟，可再擦些肥皂揉搓，至干净为止。袜子搓完后，用清水漂洗干净，略为捏干，平摊在桌面上用手抹平，阴晾在通风处，或用白布遮盖在阳光下晒干。 SOURCE http://blog.sina.com.cn/s/blog_631625de0102v7dv.html","categories":[{"name":"生活","slug":"生活","permalink":"http://roux.top/categories/生活/"}],"tags":[{"name":"琐事","slug":"琐事","permalink":"http://roux.top/tags/琐事/"}]},{"title":"memset函数分析---一次错误的总结","slug":"memset","date":"2017-12-09T16:00:00.000Z","updated":"2018-04-22T05:51:47.758Z","comments":true,"path":"2017/12/10/memset/","link":"","permalink":"http://roux.top/2017/12/10/memset/","excerpt":"前言 今天在写一个哈希表的程序的时候一直出现死循环的错误，经过调试后发现是 memset 函数的原因(没有清零数组中的元素(int类型的最后一个大小需要写 sizeof(array)))，具体情况下面分析。","text":"前言 今天在写一个哈希表的程序的时候一直出现死循环的错误，经过调试后发现是 memset 函数的原因(没有清零数组中的元素(int类型的最后一个大小需要写 sizeof(array)))，具体情况下面分析。 分析 原型：void *memset(void *s, int ch, size_t n); int ch的类型可以是char 或 int 将s所指向的某一块内存中的每个字节的内容全部设置为ch指定的ASCII值， 块的大小由第三个参数指定，这个函数通常为新申请的内存做初始化工作， 其返回值为指向S的指针。 memset按字节赋值。(今天代码出错的原因，还是自己理解的不深入) memset的作用是在一段内存块中填充某个给定的值，它是对较大的结构体或数组进行清零操作的一种最快方法。 常见错误 第一： 搞反了 ch 和 n 的位置. 一定要记住如果要把一个char a[20]清零，一定是 memset(a, 0, 20); 而不是 memset(a, 20, 0); 第二： 过度使用memset，我想这些程序员可能有某种心理阴影，他们惧怕未经初始化的内存，所以他们会写出这样的代码： 123char buffer[20];memset(buffer, 0, sizeof(char)*20);strcpy(buffer, \"123\"); 这里的memset是多余的. 因为这块内存马上就被覆盖了，清零没有意义. 第三： 其实这个错误严格来讲不能算用错memset，但是它经常在使用memset的场合出现 123456int some_func(struct something *a)&#123; … memset(a,0,sizeof(a)); …&#125; 这里错误的原因是函数传参过程中的指针降级，导致 sizeof(a)，返回的是一个 something * 指针类型大小的的字节数，如果是32位，就是4字节。 常见问题 问：为何要用 memset 置零? memset(&amp;Address, 0, sizeof(Address))；经常看到这样的用法，其实不用的话，分配数据的时候，剩余的空间也会置零的。 答：如果不清空，可能会在测试当中出现野值。 其实不然！特别是对于字符指针类型的，剩余的部分通常是不会为0的，不妨作一个试验，定义一个字符数组，并输入一串字符，如果不用 memset 实现清零，显示出来就会有乱码。 问：下面的代码1能把数组中的元素值都设置成字符1，但是，代码2想把数组中的元素值设置成1，却是不可行的。 12345678910111213//代码1#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int main()&#123; char a[5]; memset(a, '1', 5）; for(int i = 0; i &lt; 5; i++) cout&lt;&lt;a[i]&lt;&lt;\" \"; return 0;&#125; 12345678910111213//代码2#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;int main()&#123; int a[5]; memset(a, 1, 20）; //如果这里改成memset(a,1,5*sizeof(int))也不可以，因为memset按字节赋值。 for(int i = 0; i &lt; 5; i++) cout&lt;&lt;a[i]&lt;&lt;\" \"; return 0;&#125; 第一个程序为什么可以，而第二个不行？ 因为第一个程序的数组a 是字符型的，字符型占据内存大小是1Byte，而 memset 函数也是以字节为单位进行赋值的，所以你输出没有问题。而第二个程序a是整型的，使用 memset 还是按字节赋值，这样赋值完以后，每个数组元素的值实际上是 0x01010101 即十进制的16843009。 如果用 memset(a, 1, 20);(实际上与 memset(a, 1, 5*sizeof(int)) 结果是一样的)就是对a指向的内存的20个字节进行赋值，每个都用ASCⅡ为1的字符去填充，转为二进制后，1就是00000001，占一个字节。一个 int 元素是4字节，合一起就是0x01010101（十六进制），就等于16843009，就完成了对一个 int 元素的赋值了。所以用 memset 对非字符型数组赋初值是不可取的！ 怎么对bool型数组赋值： 123const int N = 11;bool arr[N];memset(&amp;arr, 1, sizeof(bool) * N); bool类型就是1或0. 一些示例： 1234567891011121314151617181920212223242526272829//有一个结构体Some x，可以这样清零：memset(&amp;x, 0, sizeof(Some));//如果是一个结构体的数组Some x[10]，可以这样：memset(x, 0, sizeof(Some)*10）；//memset可以方便的清空一个结构类型的变量或数组。如：struct sample_struct&#123; char csName[16]; int iSeq; int iType;&#125;;//对于变量struct sample_strcut stTest;//一般情况下，清空stTest的方法：stTest.csName[0]=&#123;'\\0'&#125;;stTest.iSeq=0;stTest.iType=0;//如果用memset的话非常方便：memset(&amp;stTest, 0, sizeof(struct sample_struct));//如果是数组：struct sample_struct TEST[10];memset(TEST, 0, sizeof(struct sample_struct)*10）；//另外：如果结构体中有数组的话还是需要对数组单独进行初始化处理的 source http://www.360doc.com/content/17/0322/09/33093582_639073036.shtml http://www.cnblogs.com/youxin/p/3226817.html","categories":[{"name":"C","slug":"C","permalink":"http://roux.top/categories/C/"}],"tags":[{"name":"Function","slug":"Function","permalink":"http://roux.top/tags/Function/"}]},{"title":"随笔2017-12-04","slug":"随笔2017-12-04","date":"2017-12-03T16:00:00.000Z","updated":"2018-10-24T13:46:15.231Z","comments":true,"path":"2017/12/04/随笔2017-12-04/","link":"","permalink":"http://roux.top/2017/12/04/随笔2017-12-04/","excerpt":"随笔2017-12-04&emsp;&emsp;最近学习了许多新知识(也忙于考试)，有吸收消化的也有吸收没消化的，还有部分没吸收的，慢慢来吧，这个急不来(知识需要积累，但是更需要沉淀)。","text":"随笔2017-12-04&emsp;&emsp;最近学习了许多新知识(也忙于考试)，有吸收消化的也有吸收没消化的，还有部分没吸收的，慢慢来吧，这个急不来(知识需要积累，但是更需要沉淀)。 &emsp;&emsp;有个话题很有意思：做应用层开发的人员应不应该要去了解和学习一些底层原理的知识？说下自己的理解吧，我认为相关的知识的底层实现的原理是一种思想与解决问题的思考过程，值得每个从事这一行业的相关人员去学习，从而让自己站在巨人的肩上去学习与思考，这样不仅仅会拓宽自己的视野，还能潜移默化的改变自己的思维习惯，提升自己的能力，最终决定你能够达到的高度。如果你只会用(尽管用的很好)，但是你不理解底层的原理，又怎么能在合适的场景应用，用到最佳效果(做出合理的优化与改变)，最后做出一些创新与发展。所以，我认为还是应该去学相关的知识的。我也庆幸自己的兴趣促使自己在这方面坚持了下来，庆幸自己意识到了这个问题从而更加坚定！ &emsp;&emsp;高三明悟的道理：知识在于积累，更在于思考与沉淀。 &emsp;&emsp;高一就记在心里的话(感谢班主任)：少说话，多观察，多思考！","categories":[{"name":"生活","slug":"生活","permalink":"http://roux.top/categories/生活/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://roux.top/tags/随笔/"}]},{"title":"自旋锁与互斥锁","slug":"自旋锁","date":"2017-12-01T16:00:00.000Z","updated":"2018-04-22T05:56:24.941Z","comments":true,"path":"2017/12/02/自旋锁/","link":"","permalink":"http://roux.top/2017/12/02/自旋锁/","excerpt":"前言 互斥锁 互斥锁是一种实现线程同步的机制：当一个线程尝试获取互斥锁，如果互斥锁已经被占用则该线程会被挂起进入睡眠状态，直到被唤醒。线程被挂起时，CPU会将该线程当前的处理状态保存到内存中，等到唤醒时从内存中读取上次的处理状态，这个CPU切换线程处理状态的过程被称为“上下文切换”。上下文切换是一个非常耗时的操作，它需要相当多的CPU指令才能完成。但在早期单核处理器中，只能通过这个方式来完成，毕竟一口锅不能同时炒两盘不一样的菜。","text":"前言 互斥锁 互斥锁是一种实现线程同步的机制：当一个线程尝试获取互斥锁，如果互斥锁已经被占用则该线程会被挂起进入睡眠状态，直到被唤醒。线程被挂起时，CPU会将该线程当前的处理状态保存到内存中，等到唤醒时从内存中读取上次的处理状态，这个CPU切换线程处理状态的过程被称为“上下文切换”。上下文切换是一个非常耗时的操作，它需要相当多的CPU指令才能完成。但在早期单核处理器中，只能通过这个方式来完成，毕竟一口锅不能同时炒两盘不一样的菜。 自旋锁 多核处理器开始普及之后，使用互斥锁经常会出现一种尴尬的情况：一个线程因为尝试获取互斥锁失败而进入睡眠状态，但上下文切换还没完成或者说刚切换上下文没多久，另一个线程就已经释放了那个互斥锁(所以出现了自旋锁)。 概念 自旋锁是为实现保护共享资源而提出一种锁机制。其实，自旋锁与互斥锁比较类似，它们都是为了解决对某项资源的互斥使用。无论是互斥锁，还是自旋锁，在任何时刻，最多只能有一个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁。但是两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，”自旋”一词就是因此而得名。(查看维基百科) 自旋锁和互斥锁一样也是实现线程同步的一种机制：当一个线程尝试获取自旋锁时，如果自旋锁已经被占用则该线程会一直循环等待并反复检查锁是否可用，直到锁可用时才会退出循环。如果持有锁的线程很快就释放了并且线程竞争不激烈，那自旋的效率就非常好，反之，自旋就会白白浪费CPU的处理时间，这反而会带来性能上的损失。 问题 如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。 不公平的锁(即无法满足等待时间最长的线程优先获取锁)就会存在”线程饥饿”问题。 在用自旋锁时有可能造成死锁，当递归调用时有可能造成死锁，调用有些其他函数也可能造成死锁，如 copy_to_user()、copy_from_user()、kmalloc()等 说明：我们要慎重使用自旋锁，自旋锁只有在内核可抢占式或SMP的情况下才真正需要，在单CPU且不可抢占式的内核下，自旋锁的操作为空操作。自旋锁适用于锁使用者保持锁时间比较短的情况下。 优点 自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快(非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换) 特点 单CPU非抢占内核下： 自旋锁会在编译时被忽略（因为单CPU且非抢占模式情况下，不可能发生进程切换，时钟只有一个进程处于临界区（自旋锁实际没什么用了） 单CPU抢占内核下： 自选锁仅仅当作一个设置抢占的开关（因为单CPU不可能有并发访问临界区的情况，禁止抢占就可以保证临街区唯一被拥有） 多CPU下： 此时才能完全发挥自旋锁的作用，自旋锁在内核中主要用来防止多处理器中并发访问临界区，防止内核抢占造成的竞争。 自旋锁与互斥锁 原理 互斥锁：线程会从sleep（加锁）——&gt;running（解锁），过程中有上下文的切换，cpu的抢占，信号的发送等开销。 自旋锁：线程一直是running(加锁——&gt;解锁)，死循环检测锁的标志位。 用一句话概括互斥锁和自旋锁：互斥锁是睡等，自旋锁是忙等。 区别 性能问题 互斥锁的起始原始开销要高于自旋锁，但是基本是一劳永逸，临界区持锁时间的大小并不会对互斥锁的开销造成影响，而自旋锁是死循环检测，加锁全程消耗cpu，起始开销虽然低于互斥锁，但是随着持锁时间，加锁的开销是线性增长。 释放问题 自旋锁你不需要操心锁持有进(线)程意外结束(加锁到解锁过程中进程被kill了)的时候，锁的释放问题(需要写点代码) 互斥锁最好用于那种生命周期特别长和特别稳定的代码段，例如中断处理例程内核代码。 其它(互斥锁看做二元信号量) 信号量和读写信号量适合于保持时间较长的情况，它们会导致调用者睡眠，因而自旋锁适合于保持时间非常短的情况。 自旋锁可以用于中断，不能用于进程上下文(会引起死锁)。而信号量不允许使用在中断中，而可以用于进程上下文。 自旋锁保持期间是抢占失效的，自旋锁被持有时，内核不能被抢占，而信号量和读写信号量保持期间是可以被抢占的。 应用 互斥锁(互斥锁用于临界区持锁时间比较长的操作，比如下面这些情况都可以考虑) 临界区有IO操作 临界区代码复杂或者循环量大 被保护的共享资源只在进程上下文访问 临界区竞争非常激烈 单核处理器 自旋锁 主要用在临界区持锁时间非常短且CPU资源不紧张的情况下，自旋锁一般用于多核的服务器。 被保护的共享资源需要在中断上下文访问(包括底半部(中断处理句柄)和顶半部(软中断)) 总结 自旋锁的初衷就是：在短期间内进行轻量级的锁定。一个被争用的自旋锁使得请求它的线程在等待锁重新可用的期间进行自旋(特别浪费处理器时间)，所以自旋锁不应该被持有时间过长。如果需要长时间锁定的话, 最好使用信号量。 既然互斥锁与自旋锁各有优劣，我们可以把它们结合到一起：当一个线程获取锁失败，先让它自旋一段时间，一段时间过后还未能获取锁，再让它进入睡眠状态。这个过程的重点在于自旋时间的长短，过长可能退化成单纯的自旋锁，过短可能退化成互斥锁。 推荐阅读 公平性 自旋锁的公平性 自旋锁公平性三种实现 自旋锁的优化 API及宏解释 解释的比较详细 自旋锁 详解 读写自旋锁 信号量与自旋锁 补充","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"锁","slug":"锁","permalink":"http://roux.top/tags/锁/"}]},{"title":"乐观锁与悲观锁","slug":"悲观锁与乐观锁","date":"2017-12-01T16:00:00.000Z","updated":"2018-04-22T05:54:56.724Z","comments":true,"path":"2017/12/02/悲观锁与乐观锁/","link":"","permalink":"http://roux.top/2017/12/02/悲观锁与乐观锁/","excerpt":"前言 最近学习遇到了”锁”这个有趣的知识，以前也只是听过各种”锁”，感觉很多而且杂乱，现在就将他们进行整理学习。 乐观锁和悲观锁本质上只是一种思想，在实现的时候悲观锁还是利用了数据库提供的”锁”机制(也只有数据库层提供的”锁”机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加”锁”机制，也无法保证外部系统不会修改数据)，乐观锁则会记录和检查数据版本。这两种”锁”多用于关系数据库的并发控制。","text":"前言 最近学习遇到了”锁”这个有趣的知识，以前也只是听过各种”锁”，感觉很多而且杂乱，现在就将他们进行整理学习。 乐观锁和悲观锁本质上只是一种思想，在实现的时候悲观锁还是利用了数据库提供的”锁”机制(也只有数据库层提供的”锁”机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加”锁”机制，也无法保证外部系统不会修改数据)，乐观锁则会记录和检查数据版本。这两种”锁”多用于关系数据库的并发控制。 基础 概念 在关系数据库管理系统里，悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作读某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。(就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会 block，直到它拿到锁) 悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。 在关系数据库管理系统里，乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。(就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做) 乐观并发控制多数用于数据争用不大、冲突较少的环境中，这种环境中，偶尔回滚事务的成本会低于读取数据时锁定数据的成本，因此可以获得比其他并发控制方法更高的吞吐量。 流程 悲观锁 在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。 如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。 具体响应方式由开发者根据实际需要决定。 如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。 其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。 乐观锁 数据版本,为数据增加的一个版本标识(实现数据版本有两种方式，第一种是使用版本号，第二种是使用时间戳)。 当读取数据时，将版本标识的值一同读出，数据每更新一次，同时对版本标识进行更新。 当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的版本标识进行比对，如果数据库表当前版本号与第一次取出来的版本标识值相等，则予以更新，否则认为是过期数据。 为什么需要”锁” 在多用户环境中，在同一时间可能会有多个用户更新相同的记录，这会产生冲突。 典型的冲突有： 丢失更新：一个事务的更新覆盖了其它事务的更新结果，就是所谓的更新丢失。例如：用户A把值从6改为2后，用户B又把值从2改为6，则用户A丢失了他的更新。 脏读：当一个事务读取其它完成一半事务的记录时，就会发生脏读取。例如：用户A,B看到的值都是6，用户B把值改为2的过程中，用户A读到的值仍为6。 失效情况 悲观锁 时间戳的精度如果不够，如毫秒级别，那么在高并发，或者非常凑巧情况下，有失效的可能。(如果使用高精度时间戳的话，成本又太高) 乐观锁 乐观锁存在失效的情况，属小概率事件，需要多个条件共同配合才会出现。如： 应用采用自己的策略管理主键ID。如，常见的取当前ID字段的最大值＋1作为新ID。 版本号字段 ver 默认值为 0 。 用户A读取了某个记录准备修改它。该记录正好是ID最大的记录，且之前没被修改过， ver 为默认值 0。 在用户A读取完成后，用户B恰好删除了该记录。之后，用户C又插入了一个新记录。 此时，阴差阳错的，新插入的记录的ID与用户A读取的记录的ID是一致的， 而版本号两者又都是默认值 0。 用户A在用户C操作完成后，修改完成记录并保存。由于ID、ver均可以匹配上， 因此用户A成功保存。但是，却把用户C插入的记录覆盖掉了。 乐观锁此时的失效，根本原因在于应用所使用的主键ID管理策略， 正好与乐观锁存在极小程度上的不兼容。 时间戳的精度如果不够，如毫秒级别，那么在高并发，或者非常凑巧情况下，有失效的可能。(如果使用高精度时间戳的话，成本又太高) 优缺点 悲观锁 悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。 悲观锁适用于可靠的持续性连接，诸如C/S应用。 对于Web应用的HTTP连接，先天不适用。 锁的使用意味着性能的损耗，在高并发、锁定持续时间长的情况下，尤其严重。 Web应用的性能瓶颈多在数据库处，使用悲观锁，进一步收紧了瓶颈。 非正常中止情况下的解锁机制，设计和实现起来很麻烦，成本还很高。 不够严谨的设计下，可能产生莫名其妙的，不易被发现的，让人头疼到想把键盘一巴掌碎的死锁问题。 乐观锁 乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。 但如果直接简单这么做，还是有可能会遇到不可预期的结果，例如两个事务都读取了数据库的某一行，经过修改以后写回数据库，这时就会出现”脏”数据的问题。 参考及推荐 参考 http://blog.csdn.net/YChenFeng/article/details/75003911 http://www.digpage.com/lock.html http://www.hollischuang.com/archives/934 https://zh.wikipedia.org/wiki/%E6%82%B2%E8%A7%82%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6 https://zh.wikipedia.org/wiki/%E4%B9%90%E8%A7%82%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6 推荐 https://www.zhihu.com/question/29420056 http://www.cnblogs.com/0201zcr/p/4782283.html http://www.digpage.com/lock.html","categories":[{"name":"Database","slug":"Database","permalink":"http://roux.top/categories/Database/"}],"tags":[{"name":"锁","slug":"锁","permalink":"http://roux.top/tags/锁/"}]},{"title":"线程安全解决方法---锁","slug":"线程安全解决方法","date":"2017-11-30T16:00:00.000Z","updated":"2017-12-01T07:35:54.874Z","comments":true,"path":"2017/12/01/线程安全解决方法/","link":"","permalink":"http://roux.top/2017/12/01/线程安全解决方法/","excerpt":"前言 前面文章说到的关于线程安全(并发)的问题，一般采取的解决的方法是 “加锁” 对于锁的使用一定要慎重与小心","text":"前言 前面文章说到的关于线程安全(并发)的问题，一般采取的解决的方法是 “加锁” 对于锁的使用一定要慎重与小心 线程安全解决方法—锁 同步与锁 为了避免一个变量被多个线程同时使用和修改，我们需要多个线程对该数据进行数据进行访问同步。同步就是一个线程在访问一个数据的时候，其他线程不能再对其进行访问。 同步最常见的方法是使用锁，锁是一种非强制机制，线程在访问数据时首先试图获取锁，在访问结束时释放锁。当锁还没释放时，其他的线程不能访问该数据，处于阻塞状态，直到锁释放，重新可用。 常见的锁有：二元信号量，多元信号量(简称信号量)，互斥量，临界区，读写锁，条件变量 二元信号量 这是最简单的一种锁，只有两种状态，即占用和未占用，它适合只能被唯一一个线程访问的资源, 他可以先被一个线程获得，但是可以被其他线程释放。 当二元信号量处于非占用状态时，第一个试图获取该二元信号量的线程会获得该锁，并将二元信号量置为占用状态，此后其他的所有试图获取该二元信号量的线程将会等待，直到该锁被释放。 信号量 信号量可以称为多元信号量，它允许多个线程并发访问一个资源，一个初值为 N 的信号量，可以允许 N 个线程并发访问。 线程访问资源时，首先获取信号量，具体步骤如下: 将信号量的值减1 如果信号量相减的值大于0，则继续运行，否则进入等待状态。 访问完资源后，进行下面操作 将信号量加1， 如果大于1，唤醒一个等待中的进程 推荐阅读 [信号量是什么怎么用] (https://www.zhihu.com/question/47411729) 秒杀多线程 互斥量 互斥量和二元信号量很相似，同时只允许一个线程访问，只是二元信号量它可以被一个线程获取，但可以被任意进程释放。互斥量与之不同，一个进程获取了互斥量，释放时只能由本线程释放，不能由其他线程释放。 推荐阅读 std::mutex 线程同步 秒杀多线程 临界区 临界区是比互斥量更为严格的一种锁，我们把临界区的锁的获取称为进入临界区，锁的释放离开临界区。不管是互斥量还是信号量，他们都是在整个系统中可见的，也就是说一个进程创建了一个互斥量和信号量，其他进程可以获取该锁。然而临界区的作用范围仅限于本进程可见，其他进程是无法获取该锁的，除此之外，临界区和互斥量相同。 临界区和互斥量与信号量的区别在于，互斥量和信号量在系统中任何进程里都是可见的，也就是说，一个进程创建了一个互斥量或信号量，另一个进程试图去获取该锁时合法的。然而，临界区的作用范围仅限于本进程中，其他的进程无法获取该锁（类似于静态全局变量对全局变量）。除此之外，临界区具有和互斥量相同的性质。 推荐阅读 实现临界区基本方法 读写锁 假想一个场景，如果一个进程中，对一个数据要进行大量的读写，更具体的来说是大量地读，少量地写，如果每次在读写之前都上锁，读写完成后都释放锁，那么加入我读写一共进行1000次，那就一共有1000次获得锁和释放锁的过程，如果使用读写锁，事情会变得相对简单(在读取的时候不加锁，在有线程需要写的时候进行加锁)。 首先读写锁有两种获取方式，一种是独占式，一种是共享式。 当锁处于自由状态时，以任何一种状态获得锁都能成功，如果锁处于共享状态，其他线程以共享方式获得也能成功(独占式不行)。如果一个锁处于独占式的状态，那么以任何一种方法都不能获得锁 1234读写锁状态 以共享方式获取 以独占方式获取自由 成功 成功共享 成功 等待独占 等待 等待 推荐阅读 读写锁1 读写锁2 条件变量 以上介绍的锁处于系统自动控制的状态，不能准确地控制各自线程的顺序，所以再次基础上，我们又加上了条件变量这个机制详细原因。官方点来说条件变量是一种同步手段，对于条件变量来说，线程有两种状态，一种是线程可以等待条件变量(类比接收一个信号)，其次是线程可以唤醒条件变量(类比发送一个信号)。一个条件变量可以被多个线程等待，通俗点来说当一个线程唤醒了一个条件变量(发送信号)后，多个线程等到了条件变量(接收到了信号)，那么多个线程就可以一起执行。 推荐阅读 条件变量 条件变量详解 条件变量陷阱与思考 总结 注意 在锁中间最好避免出现函数调用的现象，以防出现重入现象 123456789101112131415161718// 这是一个函数调用自身的例子，当打印出hello world之后就一直卡死，造成死锁#include &lt;iostream&gt;#include &lt;pthread.h&gt;pthread_mutex_t task_mutex;void hello()&#123; pthread_mutex_lock(&amp;task_mutex); std::cout &lt;&lt; \"hello world\" &lt;&lt; std::endl; hello(); pthread_mutex_unlock(&amp;task_mutex);&#125;int main(void)&#123; hello(); return 0;&#125; 互斥锁，同步锁，临界区，互斥量，信号量，自旋锁之间的联系","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"线程","slug":"线程","permalink":"http://roux.top/tags/线程/"}]},{"title":"线程安全","slug":"线程安全","date":"2017-11-28T16:00:00.000Z","updated":"2018-04-22T05:59:43.354Z","comments":true,"path":"2017/11/29/线程安全/","link":"","permalink":"http://roux.top/2017/11/29/线程安全/","excerpt":"前言 在单线程进程中，只存在一个控制流。因此，这些进程所执行的代码无需重入或是线程安全的。在多线程程序中，相同的功能和资源可以通过多个控制流并发访问。 要保护资源的完整性，编写的多线程程序代码必须能重入并是线程安全的。重入和线程安全都与函数处理资源的方式相关。","text":"前言 在单线程进程中，只存在一个控制流。因此，这些进程所执行的代码无需重入或是线程安全的。在多线程程序中，相同的功能和资源可以通过多个控制流并发访问。 要保护资源的完整性，编写的多线程程序代码必须能重入并是线程安全的。重入和线程安全都与函数处理资源的方式相关。 线程 概念 线程，有时也称轻量级进程(LWP)，它是程序执行流的最小单元。它由堆栈，寄存器集，线程ID，当前指令指针(PC)组成。 线程也可以理解为颗粒度更小的进程，对任务划分更为精细，线程可以像进程一样，进行并发，提高了程序的响应度，一个进程包含了多个线程。 线程之间可以共享进程中一部分的内存空间(包括代码段，数据段，堆)，还有一个进程中的资源(如打开的文件，socket，还有信号) 进程是可以作为一个程序独立运行的，但是线程并不可以，它必须依附于进程来工作，一个进程最少有一个线程。 线程的访问权限 栈：（尽管并不是完全不能被其他线程访问，但是一般情况下，还是被认为为私有数据） 线程局部存储(Thread Local Storge, TLS)：是某些操作系统为线程单独提供的私有空间，通常具有很有限的容量。 寄存器(包括pc寄存器)：寄存器是执行流的基本数据，为线程私有。 线程私有: 函数参数 TLS 栈 线程之间共享: 代码段 全局变量 函数中的静态变量 堆上的数据 一些进程中资源:打开的文件，socket，信号等 线程的调度和优先级 线程在运行时可以有三种状态：等待，就绪，运行 等待 -&gt; 就绪 -&gt; 运行 -&gt; 等待 运行 -&gt; 就绪 -&gt; 运行(对于CPU密集型程序常出现时间片用完还没完成任务，于是在运行) 概念 多线程的出现，导致了一个处理器上经常要运行多个线程，各个线程怎么运行？谁先谁后？这些问题都交给了线程调度，有了线程调度，一个线程在规定的时间片(处于运行中的程序拥有的一段可以执行的时间)内运行，超出了时间片的时间，调度机制将会安排下一个线程运行。 现在线程调度虽然各不相同，但是都有优先级调度和轮转法的痕迹。轮转法(让每一个程序都运行一段时间，时间一到就切换到下一个程序)，优先级调度(根据程序的优先级来运行，优先级高的先运行)。 线程提升优先级的方法 手动设置 根据等待的频繁程度，增加或减少优先级。 随着时间的累计，逐渐增减优先级 线程饿死 如果一个高优先级的CPU密集型任务，在每次时间片用尽后进入就绪状态，然后又进入运行状态，那么很低优先级的程序就会永远等不到运行，这就是线程饿死 抢占式线程和不可抢占式线程 每当一个线程在执行时间到达时间片后，都会被系统收回控制权，之后执行其他线程，这就是抢占式 当在不可抢占式线程中时，线程是不可抢占的，除非线程自己发出一个停止执行的命令，或者进入等待。在该线程模型下， 线程必须自己主动进入就绪状态，而不是靠时间片强行进入就绪状态。如果一个线程没有等待，也没有主动进入就绪，那么它将一直运行，其他线程被阻塞 现在非抢占式线程基本已经看不到了，基本上都是抢占式进程 线程安全 概念 线程安全的概念比较直观，一般来说，一个函数被称为线程安全的，当且仅当被多个并发线程反复调用时，它会一直产生正确的结果。 多线程编程中的三个核心概念 确保线程安全 要确保函数线程安全，主要需要考虑的是线程之间的共享变量。属于同一线程的不同进程会共享进程内存空间中的全局区和堆，而私有的线程空间则主要包括栈和寄存器。因此，对于同一进程的不同线程来说，每个线程的局部变量都是私有的，而全局变量、局部静态变量、分配于堆的变量都是共享的。而对于这些共享变量进行访问时，如果要保证线程安全，则必须通过加锁的方式。 线程不安全的后果 线程不安全可能导致的后果是显而易见的——共享变量的值由于不同线程的访问，可能发生不可预料的变化，进而导致程序的错误，甚至崩溃。 可重入函数 概念 可重入的概念基本没头比较正式的完整解释，这里有个大体的理解，所谓的“重入”，常见的情况是，程序执行到某个函数foo()，收到信号，于是暂停目前正在执行的函数，转到信号处理函数，而这个信号处理函数的执行过程中，又恰恰也会进到刚刚执行的函数foo()，这样便发生了所谓的重入。此时如果foo()能够正确的运行，而且处理完成后，之前暂停的foo()也能够正确运行，则说明它时可重入的。 Linux中可重入这个概念一般只有在signal的场景下有意义，叫async-signal-safe。很多线程安全的函数都是不可重入的，例如malloc。可重入函数一般也是线程安全的，当然据说时是有反例的。 确保可重入 要确保函数可重入，需要满足一下几个条件： 不在函数内部使用静态或全局数据 不返回静态或全局数据，所有数据都由函数的调用者提供 使用本地数据，或者通过制作全局数据的本地拷贝来保护全局数据 不掉用不可重入函数 不可重入的后果 不可重入的后果主要体现在像信号处理函数这样需要重入的情况中。如果信号处理函数中使用了不可重入的函数，则可能导致程序的错误甚至崩溃。 总结 可重入与线程安全并不等同。一般来说，可重入的函数一定时线程安全的，但反过来说就不一定成立了，也就是说，可重入是比线程安全要要求严格的 如果一个函数中用到了全局或静态变量，那么他不是线程安全的，也不是可重入的 如果我们对它加以改进，在访问全局或者静态变量时使用互斥量或信号量等方式加锁，则可以使它变成线程安全的，但此时它仍然是不可重入的，因为通常加锁方式是针对不同线程的访问，而对同一线程可能出现问题 如果将函数中的全局或静态变量去掉，改成函数参数等其他形式，则有可能使函数变成既线程安全，又可重入 编写重入和线程安全代码 示例：strtok strtok 函数是既不可重入的，也不是线程安全的；加锁的 strtok 不是可重入的，但线程安全；而 strok_r 既是可重入的，也是线程安全的。 参考及推荐 参考 https://www.ibm.com/support/knowledgecenter/zh/ssw_aix_71/com.ibm.aix.genprogc/writing_reentrant_thread_safe_code.htm https://www.gsxio.com/reentrant-function-and-thread-safety.html http://sindrilin.com/note/2017/09/09/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/ 推荐 http://www.bijishequ.com/detail/277766?p= http://www.cppblog.com/elva/archive/2011/01/21/139019.html","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"线程","slug":"线程","permalink":"http://roux.top/tags/线程/"}]},{"title":"惊群现象","slug":"惊群现象","date":"2017-11-28T16:00:00.000Z","updated":"2018-04-22T05:55:03.471Z","comments":true,"path":"2017/11/29/惊群现象/","link":"","permalink":"http://roux.top/2017/11/29/惊群现象/","excerpt":"前言 什么是“惊群”，会产生什么问题？ 惊群是当许多进(线)程等待一个事件，事件发生后这些进(线)程被唤醒，单只有一个进(线)程能获得CPU执行权，其他进(线)程又得被阻塞，这造成了严重的系统上下文切换代价。 系统对用户进程/线程频繁的无效调度，大幅度的降低系统效率 为了确保只有一个进程或线程得到资源，用户必须对资源加锁，这就进一步增加了系统开销","text":"前言 什么是“惊群”，会产生什么问题？ 惊群是当许多进(线)程等待一个事件，事件发生后这些进(线)程被唤醒，单只有一个进(线)程能获得CPU执行权，其他进(线)程又得被阻塞，这造成了严重的系统上下文切换代价。 系统对用户进程/线程频繁的无效调度，大幅度的降低系统效率 为了确保只有一个进程或线程得到资源，用户必须对资源加锁，这就进一步增加了系统开销 网络模型如下图所示： “惊群”的现象怎么用代码模拟出来？ 这个会在后面讲解 如何处理“惊群”问题，处理“惊群”后的现象又是怎么样呢？ 处理方法 不希望把所有进程都唤醒，就采用定点唤醒某一个进程的做法。(Linux内核的accept解决方法) 尽量避免进程上下文切换(Nginx解决epoll的方法(抢占锁)) 现象后面讲解 accept惊群 我们都知道常见的C/S模式的服务器一般都会在主进程执行 socket()+bind()+listen() 后，fork() 多个子进程，每个子进程都通过 accept() 循环处理这个 socket；此时，每个进程都阻塞在 accpet() 调用上，当一个新连接到来时，所有的进程都会被唤醒，但其中只有一个进程会 accept() 成功，其余皆失败，重新休眠。这就是 accept 惊群。 打个比方，街边有一家麦当劳餐厅，里面有4个服务小窗口，每个窗口各有一名服务员。当大门口进来一位新客人时，“欢迎光临！”餐厅大门的感应式门铃自动响了（相当于操作系统底层捕捉到了一个网络事件），于是4个服务员都抬起头（相当于操作系统唤醒了所有服务进程）希望将客人招呼过去自己所在的服务窗口。但结果可想而知，客人最终只会走向其中某一个窗口，而其他3个窗口的服务员只能“失望叹息”（这一声无奈的叹息就相当于accept()返回EAGAIN错误），然后埋头继续忙自己的事去。 如果只用一个进程去 accept 新连接，并通过消息队列等同步方式使其他子进程处理这些新建的连接，那么将会造成效率低下；因为这个进程只能用来 accept 连接，该进程可能会造成瓶颈。 我们已经知道了“惊群”是怎么回事，那么就按照上面的图编码实现看一下效果。我尝试使用多进程模型，创建一个父进程绑定一个端口监听socket，然后fork出多个子进程，子进程们开始循环处理（比如accept）这个socket。测试代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;assert.h&gt;#include &lt;sys/wait.h&gt;#include &lt;string.h&gt;#include &lt;errno.h&gt;#define IP \"127.0.0.1\"#define PORT 55555#define WORKER 4int worker(int listenfd, int i)&#123; while (1) &#123; printf(\"I am worker %d, begin to accept connection.\\n\", i); struct sockaddr_in client_addr; socklen_t client_addrlen = sizeof( client_addr ); int connfd = accept( listenfd, ( struct sockaddr* )&amp;client_addr, &amp;client_addrlen ); if (connfd != -1) &#123; printf(\"worker %d accept a connection success.\\t\", i); printf(\"ip :%s\\t\",inet_ntoa(client_addr.sin_addr)); printf(\"port: %d \\n\",client_addr.sin_port); &#125; else &#123; printf(\"worker %d accept a connection failed,error:%s\", i, strerror(errno)); close(connfd); &#125; &#125; return 0;&#125;int main()&#123; int i = 0; struct sockaddr_in address; bzero(&amp;address, sizeof(address)); address.sin_family = AF_INET; inet_pton( AF_INET, IP, &amp;address.sin_addr); address.sin_port = htons(PORT); int listenfd = socket(PF_INET, SOCK_STREAM, 0); assert(listenfd &gt;= 0); int ret = bind(listenfd, (struct sockaddr*)&amp;address, sizeof(address)); assert(ret != -1); ret = listen(listenfd, 5); assert(ret != -1); for (i = 0; i &lt; WORKER; i++) &#123; printf(\"Create worker %d\\n\", i+1); pid_t pid = fork(); /*child process */ if (pid == 0) &#123; worker(listenfd, i); &#125; if (pid &lt; 0) &#123; printf(\"fork error\"); &#125; &#125; /*wait child process*/ int status; wait(&amp;status); return 0;&#125; 编译执行，在本机上使用 telnet 127.0.0.1 55555 测试，结果如下所示： 按照“惊群”现象，期望结果应该是4个子进程都会accpet到请求，其中只有一个成功，另外三个失败的情况。而实际的结果显示，父进程开始创建4个子进程，每个子进程开始等待accept连接。当telnet连接来的时候，只有worker0 子进程accpet到请求，而其他的三个进程并没有接收到请求。 其实在Linux2.6版本以后，内核内核已经解决了accept()函数的“惊群”问题。处理方式就是，当内核接收到一个客户连接后，只会唤醒等待队列上的第一个进程。所以，如果服务器采用accept阻塞调用方式，在最新的Linux系统上，已经没有“惊群”的问题了。 但是很不幸，通常我们的程序没那么简单，不会愿意阻塞在accept调用上，我们还有许多其他网络读写事件要处理，linux下我们爱用epoll解决非阻塞socket。所以，即使accept调用没有惊群了，我们也还得处理惊群这事，因为epoll有这问题。上面说的测试程序，如果我们在子进程内不是阻塞调用accept，而是用epoll_wait，就会发现，新连接过来时，多个子进程都会在epoll_wait后被唤醒！ 相关文章/帖子 惊群(thundering herd)问题在linux上可能是莫须有的问题 Does the Thundering Herd Problem exist on Linux anymore? epoll惊群 如上所述，accept 已经不存在惊群问题，但 epoll 上还是存在惊群问题。即，如果多个进程/线程阻塞在监听同一个 listening socket fd 的 epoll_wait 上，当有一个新的连接到来时，所有的进程都会被唤醒。 主进程仍执行 socket()+bind()+listen() 后，将该 socket 加入到 epoll 中，然后 fork 出多个子进程，每个进程都阻塞在 epoll_wait() 上，如果有事件到来，则判断该事件是否是该 socket 上的事件，如果是，说明有新的连接到来了，则进行 accept 操作 那么，当新的连接到来时，是否每个阻塞在 epoll_wait 上的进程都会被唤醒呢？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/epoll.h&gt;#include &lt;netdb.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt;#define IP \"127.0.0.1\"#define PORT 55555#define PROCESS_NUM 4#define MAXEVENTS 64static int create_and_bind ()&#123; int fd = socket(PF_INET, SOCK_STREAM, 0); struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; inet_pton( AF_INET, IP, &amp;serveraddr.sin_addr); serveraddr.sin_port = htons(PORT); bind(fd, (struct sockaddr*)&amp;serveraddr, sizeof(serveraddr)); return fd;&#125;static int make_socket_non_blocking (int sfd)&#123; int flags, s; flags = fcntl (sfd, F_GETFL, 0); if (flags == -1) &#123; perror (\"fcntl\"); return -1; &#125; flags |= O_NONBLOCK; s = fcntl (sfd, F_SETFL, flags); if (s == -1) &#123; perror (\"fcntl\"); return -1; &#125; return 0;&#125;void worker(int sfd, int efd, struct epoll_event *events, int k) &#123; /* The event loop */ while (1) &#123; int n, i; n = epoll_wait(efd, events, MAXEVENTS, -1); printf(\"worker %d return from epoll_wait!\\n\", k); for (i = 0; i &lt; n; i++) &#123; if ((events[i].events &amp; EPOLLERR) || (events[i].events &amp; EPOLLHUP) || (!(events[i].events &amp;EPOLLIN))) &#123; /* An error has occured on this fd, or the socket is not ready for reading (why were we notified then?) */ fprintf (stderr, \"epoll error\\n\"); close (events[i].data.fd); continue; &#125; else if (sfd == events[i].data.fd) &#123; /* We have a notification on the listening socket, which means one or more incoming connections. */ struct sockaddr in_addr; socklen_t in_len; int infd; char hbuf[NI_MAXHOST], sbuf[NI_MAXSERV]; in_len = sizeof in_addr; infd = accept(sfd, &amp;in_addr, &amp;in_len); if (infd == -1) &#123; printf(\"worker %d accept failed!\\n\", k); break; &#125; printf(\"worker %d accept successed!\\n\", k); /* Make the incoming socket non-blocking and add it to the list of fds to monitor. */ close(infd); &#125; &#125; &#125;&#125;int main (int argc, char *argv[])&#123; int sfd, s; int efd; struct epoll_event event; struct epoll_event *events; sfd = create_and_bind(); if (sfd == -1) &#123; abort (); &#125; s = make_socket_non_blocking (sfd); if (s == -1) &#123; abort (); &#125; s = listen(sfd, SOMAXCONN); if (s == -1) &#123; perror (\"listen\"); abort (); &#125; efd = epoll_create(MAXEVENTS); if (efd == -1) &#123; perror(\"epoll_create\"); abort(); &#125; event.data.fd = sfd; event.events = EPOLLIN; s = epoll_ctl(efd, EPOLL_CTL_ADD, sfd, &amp;event); if (s == -1) &#123; perror(\"epoll_ctl\"); abort(); &#125; /* Buffer where events are returned */ events = calloc(MAXEVENTS, sizeof event); int k; for(k = 0; k &lt; PROCESS_NUM; k++) &#123; printf(\"Create worker %d\\n\", k+1); int pid = fork(); if(pid == 0) &#123; worker(sfd, efd, events, k); &#125; &#125; int status; wait(&amp;status); free (events); close (sfd); return EXIT_SUCCESS;&#125; 测试结果： 我们发现，当我模拟发起一个请求时，只有一个或少数几个进程被唤醒了(是不是linux内核也做了一些操作让epoll在某些情况下只唤醒部分进程呢？)。 代码改进如下(在epoll_wait后调用sleep)： 123456789101112131415161718192021222324252627282930313233void worker(int sfd, int efd, struct epoll_event *events, int k) &#123; /* The event loop */ while (1) &#123; int n, i; n = epoll_wait(efd, events, MAXEVENTS, -1); /*keep running*/ sleep(2); printf(\"worker %d return from epoll_wait!\\n\", k); for (i = 0; i &lt; n; i++) &#123; if ((events[i].events &amp; EPOLLERR) || (events[i].events &amp; EPOLLHUP) || (!(events[i].events &amp;EPOLLIN))) &#123; /* An error has occured on this fd, or the socket is not ready for reading (why were we notified then?) */ fprintf (stderr, \"epoll error\\n\"); close (events[i].data.fd); continue; &#125; else if (sfd == events[i].data.fd) &#123; /* We have a notification on the listening socket, which means one or more incoming connections. */ struct sockaddr in_addr; socklen_t in_len; int infd; char hbuf[NI_MAXHOST], sbuf[NI_MAXSERV]; in_len = sizeof in_addr; infd = accept(sfd, &amp;in_addr, &amp;in_len); if (infd == -1) &#123; printf(\"worker %d accept failed,error:%s\\n\", k, strerror(errno)); break; &#125; printf(\"worker %d accept successed!\\n\", k); /* Make the incoming socket non-blocking and add it to the list of fds to monitor. */ close(infd); &#125; &#125; &#125;&#125; 再次运行发现其实linux内核并没有做什么，上面出现的现象的原因是我们的进程在处理事件的速度太快，还没等到唤醒所有的进程就处理完毕了，所以造成只唤醒了部分进程的假象。 为什么只解决了 accept() 的惊群问题，而没有解决 epoll() 的？ accept 确实应该只能被一个进程调用成功，内核很清楚这一点。但 epoll 不一样，他监听的文件描述符，除了可能后续被 accept 调用外，还有可能是其他网络 IO 事件的，而其他 IO 事件是否只能由一个进程处理，是不一定的，内核不能保证这一点，这是一个由用户决定的事情，例如可能一个文件会由多个进程来读写。所以，对 epoll 的惊群，内核则不予处理。 解决问题 网上有好多优秀的文章已经阐述的很详细了，我就只解释下原理，想要查看细节的请自行查看(下面的链接)。 Linux 对于一些 linux 内核中已知的惊群问题，内核开发者增加了“互斥等待”选项： 当一个等待队列入口如果 WQ_FLAG_EXCLUSEVE 标志置位，它被添加到等待队列尾部，否则添加到队列尾部。 当 wake_up 被在一个队列上调用时，它在唤醒第一个有 WQ_FLAG_EXCLUSEVE 标志的进程后终止。 因此，对于互斥等待的行为，内核只会唤醒队列中的第一个进程 https://jin-yang.github.io/post/linux-details-of-thundering-herd.html (跳到最后看3.9以上的内核怎样处理的) https://groups.google.com/forum/#!msg/openresty/IY43D2qs3ok/MwV4F1eiAQAJ (配合上面的一起看，要看回答(回答有解释为什么能实现多个描述符监听同一个端口)) nginx nginx 使用 ngx_accept_mutex 作为互斥锁让所有 worker 进程竞争，最终只有一个进程可以获得锁，以保证只有一个进程执行 epoll_wait 操作，并 accept 它的负载均衡也很简单，当达到最大connection的7/8时，本worker不会去试图拿accept锁，也不会去处理新连接，这样其他nginx worker进程就更有机会去处理监听句柄，建立新连接了。而且，由于timeout的设定，使得没有拿到锁的worker进程，去拿锁的频率更高。 http://www.cnblogs.com/my_life/articles/5145050.html (从中间的部分开始看) https://groups.google.com/forum/#!msg/openresty/IY43D2qs3ok/MwV4F1eiAQAJ (配合后面的回答看，链接一定要点进去) https://pureage.info/2015/12/22/thundering-herd.html (直接跳到最后面看步骤和思想，建议配合下面的阅读) http://techlog.cn/article/list/10182833 (很详细的代码解释，建议阅读) 其它 http://blog.163.com/pandalove@126/blog/static/9800324520122633515612/ 参考 https://zh.wikipedia.org/wiki/%E6%83%8A%E7%BE%A4%E9%97%AE%E9%A2%98 https://www.zhihu.com/question/24169490 (第一个回答下面的评论) http://www.cnblogs.com/Anker/p/7071849.html 以及上面所提到的文章","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"Others","slug":"Others","permalink":"http://roux.top/tags/Others/"}]},{"title":"epoll源码分析","slug":"epoll源码","date":"2017-11-26T16:00:00.000Z","updated":"2018-04-22T05:49:06.480Z","comments":true,"path":"2017/11/27/epoll源码/","link":"","permalink":"http://roux.top/2017/11/27/epoll源码/","excerpt":"epoll的实现 执行 epoll_create 时，创建了红黑树和就绪 list 链表。 执行 epoll_ctl 时，如果增加fd（socket），则检查在红黑树中是否存在，存在立即返回，不存在则添加到红黑树上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪list链表中插入数据。 执行 epoll_wait 时立刻返回准备就绪链表里的数据即可。","text":"epoll的实现 执行 epoll_create 时，创建了红黑树和就绪 list 链表。 执行 epoll_ctl 时，如果增加fd（socket），则检查在红黑树中是否存在，存在立即返回，不存在则添加到红黑树上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪list链表中插入数据。 执行 epoll_wait 时立刻返回准备就绪链表里的数据即可。 源码分析 epoll用 kmem_cache_create（slab分配器）分配内存用来存放 struct epitem 和 struct eppoll_entry。 123456789101112131415static int __init eventpoll_init(void)&#123; mutex_init(&amp;pmutex); ep_poll_safewake_init(&amp;psw); epi_cache = kmem_cache_create(\"eventpoll_epi\", sizeof(struct epitem), 0, SLAB_HWCACHE_ALIGN|EPI_SLAB_DEBUG|SLAB_PANIC, NULL); pwq_cache = kmem_cache_create(\"eventpoll_pwq\", sizeof(struct eppoll_entry), 0, EPI_SLAB_DEBUG|SLAB_PANIC, NULL); return 0;&#125; 当向系统中添加一个 fd 时，就创建一个 epitem 结构体，这是内核管理 epoll 的基本数据结构： 12345678910111213struct epitem &#123; struct rb_node rbn; //用于主结构管理的红黑树 struct list_head rdllink; //事件就绪队列 struct epitem *next; //用于主结构体中的链表 struct epoll_filefd ffd; //这个结构体对应的被监听的文件描述符信息 int nwait; //poll操作中事件的个数 struct list_head pwqlist; //双向链表，保存着被监视文件的等待队列，功能类似于select/poll中的poll_table struct eventpoll *ep; //该项属于哪个主结构体（多个epitm从属于一个eventpoll） struct list_head fllink; //双向链表，用来链接被监视的文件描述符对应的struct file。因为file里有f_ep_link,用来保存所有监视这个文件的epoll节点 struct epoll_event event; //注册的感兴趣的事件,也就是用户空间的epoll_event&#125; 而每个epoll fd（epfd）对应的主要数据结构为： 123456789101112131415161718192021222324252627282930313233struct eventpoll &#123; spin_lock_t lock; //对本数据结构的访问 struct mutex mtx; //防止使用时被删除 wait_queue_head_t wq; //sys_epoll_wait() 使用的等待队列 wait_queue_head_t poll_wait; //file-&gt;poll()使用的等待队列 struct list_head rdllist; //事件满足条件的链表 struct rb_root rbr; //用于管理所有fd的红黑树（树根） struct epitem *ovflist; //将事件到达的fd进行链接起来发送至用户空间&#125;//struct eventpoll在epoll_create时创建。long sys_epoll_create(int size) &#123; struct eventpoll *ep; ... ep_alloc(&amp;ep); //为ep分配内存并进行初始化/* 调用anon_inode_getfd 新建一个file instance， 也就是epoll可以看成一个文件（匿名文件）。 因此我们可以看到epoll_create会返回一个fd。 epoll所管理的所有的fd都是放在一个大的结构eventpoll(红黑树)中， 将主结构体struct eventpoll *ep放入file-&gt;private项中进行保存（sys_epoll_ctl会取用）*/ fd = anon_inode_getfd(\"[eventpoll]\", &amp;eventpoll_fops, ep, O_RDWR | (flags &amp; O_CLOEXEC)); return fd;&#125;//其中，ep_alloc(struct eventpoll **pep)为pep分配内存，并初始化。//其中，上面注册的操作eventpoll_fops定义如下：static const struct file_operations eventpoll_fops = &#123; .release= ep_eventpoll_release, .poll = ep_eventpoll_poll,&#125;; 这样说来，内核中维护了一棵红黑树，大致的结构如下： 简单版 复杂版 接着是epoll_ctl函数（省略了出错检查等代码）： 12345678910111213141516171819202122232425262728293031323334353637383940asmlinkage long sys_epoll_ctl(int epfd,int op,int fd,struct epoll_event __user *event) &#123; int error; struct file *file,*tfile; struct eventpoll *ep; struct epoll_event epds; error = -FAULT; //判断参数的合法性，将 __user *event 复制给 epds。 if(ep_op_has_event(op) &amp;&amp; copy_from_user(&amp;epds,event,sizeof(struct epoll_event))) goto error_return; //省略跳转到的代码 file = fget (epfd); // epoll fd 对应的文件对象 tfile = fget(fd); // fd 对应的文件对象 //在create时存入进去的（anon_inode_getfd），现在取用。 ep = file-&gt;private-&gt;data; mutex_lock(&amp;ep-&gt;mtx); //防止重复添加（在ep的红黑树中查找是否已经存在这个fd） epi = epi_find(ep,tfile,fd); switch(op) &#123; ... case EPOLL_CTL_ADD: //增加监听一个fd if(!epi) &#123; epds.events |= EPOLLERR | POLLHUP; //默认包含POLLERR和POLLHUP事件 error = ep_insert(ep,&amp;epds,tfile,fd); //在ep的红黑树中插入这个fd对应的epitm结构体。 &#125; else //重复添加（在ep的红黑树中查找已经存在这个fd）。 error = -EEXIST; break; ... &#125; return error;&#125; ep_insert的实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283static int ep_insert(struct eventpoll *ep, struct epoll_event *event, struct file *tfile, int fd)&#123; int error ,revents,pwake = 0; unsigned long flags ; struct epitem *epi; /* struct ep_queue&#123; poll_table pt; struct epitem *epi; &#125;*/ struct ep_pqueue epq; //分配一个epitem结构体来保存每个加入的fd if(!(epi = kmem_cache_alloc(epi_cache,GFP_KERNEL))) goto error_return; //初始化该结构体 ep_rb_initnode(&amp;epi-&gt;rbn); INIT_LIST_HEAD(&amp;epi-&gt;rdllink); INIT_LIST_HEAD(&amp;epi-&gt;fllink); INIT_LIST_HEAD(&amp;epi-&gt;pwqlist); epi-&gt;ep = ep; ep_set_ffd(&amp;epi-&gt;ffd,tfile,fd); epi-&gt;event = *event; epi-&gt;nwait = 0; epi-&gt;next = EP_UNACTIVE_PTR; epq.epi = epi; //安装poll回调函数 init_poll_funcptr(&amp;epq.pt, ep_ptable_queue_proc ); /* 调用poll函数来获取当前事件位，其实是利用它来调用注册函数ep_ptable_queue_proc（poll_wait中调用）。 如果fd是套接字，f_op为socket_file_ops，poll函数是 sock_poll()。如果是TCP套接字的话，进而会调用 到tcp_poll()函数。此处调用poll函数查看当前 文件描述符的状态，存储在revents中。 在poll的处理函数(tcp_poll())中，会调用sock_poll_wait()， 在sock_poll_wait()中会调用到epq.pt.qproc指向的函数， 也就是ep_ptable_queue_proc()。 */ revents = tfile-&gt;f_op-&gt;poll(tfile, &amp;epq.pt); spin_lock(&amp;tfile-&gt;f_ep_lock); list_add_tail(&amp;epi-&gt;fllink,&amp;tfile-&gt;f_ep_lilnks); spin_unlock(&amp;tfile-&gt;f_ep_lock); ep_rbtree_insert(ep,epi); //将该epi插入到ep的红黑树中 spin_lock_irqsave(&amp;ep-&gt;lock,flags); // revents &amp; event-&gt;events：刚才fop-&gt;poll的返回值中标识的事件有用户event关心的事件发生。 // !ep_is_linked(&amp;epi-&gt;rdllink)：epi的ready队列中有数据。ep_is_linked用于判断队列是否为空。 /* 如果要监视的文件状态已经就绪并且还没有加入到就绪队列中,则将当前的 epitem加入到就绪队列中.如果有进程正在等待该文件的状态就绪,则唤醒一个等待的进程。 */ if((revents &amp; event-&gt;events) &amp;&amp; !ep_is_linked(&amp;epi-&gt;rdllink)) &#123; list_add_tail(&amp;epi-&gt;rdllink,&amp;ep-&gt;rdllist); //将当前epi插入到ep-&gt;ready队列中。 /* 如果有进程正在等待文件的状态就绪， 也就是调用epoll_wait睡眠的进程正在等待， 则唤醒一个等待进程。 waitqueue_active(q) 等待队列q中有等待的进程返回1，否则返回0。 */ if(waitqueue_active(&amp;ep-&gt;wq)) __wake_up_locked(&amp;ep-&gt;wq,TAKS_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE); /* 如果有进程等待eventpoll文件本身（???）的事件就绪， 则增加临时变量pwake的值，pwake的值不为0时， 在释放lock后，会唤醒等待进程。 */ if(waitqueue_active(&amp;ep-&gt;poll_wait)) pwake++; &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock,flags); if(pwake) ep_poll_safewake(&amp;psw,&amp;ep-&gt;poll_wait); //唤醒等待eventpoll文件状态就绪的进程 return 0;&#125; 12345678910init_poll_funcptr(&amp;epq.pt, ep_ptable_queue_proc);revents = tfile-&gt;f_op-&gt;poll(tfile, &amp;epq.pt);//这两个函数将ep_ptable_queue_proc注册到epq.pt中的qproc。typedef struct poll_table_struct &#123; poll_queue_proc qproc; unsigned long key;&#125;poll_table;//执行f_op-&gt;poll(tfile, &amp;epq.pt)时，XXX_poll(tfile, &amp;epq.pt)函数会执行poll_wait()，poll_wait()会调用epq.pt.qproc函数，即ep_ptable_queue_proc。 ep_ptable_queue_proc函数如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* 在文件操作中的poll函数中调用，将epoll的回调函数加入到目标文件的唤醒队列中。 如果监视的文件是套接字，参数whead则是sock结构的sk_sleep成员的地址。 */static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead, poll_table *pt) &#123; /* struct ep_queue&#123; poll_table pt; struct epitem *epi; &#125; */ struct epitem *epi = ep_item_from_epqueue(pt); //pt获取struct ep_queue的epi字段。 struct eppoll_entry *pwq; if (epi-&gt;nwait &gt;= 0 &amp;&amp; (pwq = kmem_cache_alloc(pwq_cache, GFP_KERNEL))) &#123; init_waitqueue_func_entry(&amp;pwq-&gt;wait, ep_poll_callback); pwq-&gt;whead = whead; pwq-&gt;base = epi; add_wait_queue(whead, &amp;pwq-&gt;wait); list_add_tail(&amp;pwq-&gt;llink, &amp;epi-&gt;pwqlist); epi-&gt;nwait++; &#125; else &#123; /* We have to signal that an error occurred */ /* * 如果分配内存失败，则将nwait置为-1，表示 * 发生错误，即内存分配失败，或者已发生错误 */ epi-&gt;nwait = -1; &#125;&#125;//其中struct eppoll_entry定义如下：struct eppoll_entry &#123; struct list_head llink; struct epitem *base; wait_queue_t wait; wait_queue_head_t *whead;&#125;;//ep_ptable_queue_proc 函数完成 epitem 加入到特定文件的wait队列任务。/*ep_ptable_queue_proc有三个参数：struct file *file; 该fd对应的文件对象wait_queue_head_t *whead; 该fd对应的设备等待队列（同select中的mydev-&gt;wait_address）poll_table *pt; f_op-&gt;poll(tfile, &amp;epq.pt)中的epq.pt*//*在ep_ptable_queue_proc函数中，引入了另外一个非常重要的数据结构eppoll_entry。eppoll_entry主要完成epitem和epitem事件发生时的callback（ep_poll_callback）函数之间的关联。首先将eppoll_entry的whead指向fd的设备等待队列（同select中的wait_address），然后初始化eppoll_entry的base变量指向epitem，最后通过add_wait_queue将epoll_entry挂载到fd的设备等待队列上。完成这个动作后，epoll_entry已经被挂载到fd的设备等待队列。*/ ep_poll_callback函数如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/*由于ep_ptable_queue_proc函数设置了等待队列的ep_poll_callback回调函数。所以在设备硬件数据到来时，硬件中断处理函数中会唤醒该等待队列上等待的进程时，会调用唤醒函数ep_poll_callback*/static int ep_poll_callback(wait_queue_t *wait, unsigned mode, int sync, void *key) &#123; int pwake = 0; unsigned long flags; struct epitem *epi = ep_item_from_wait(wait); struct eventpoll *ep = epi-&gt;ep; spin_lock_irqsave(&amp;ep-&gt;lock, flags); //判断注册的感兴趣事件 //#define EP_PRIVATE_BITS (EPOLLONESHOT | EPOLLET) //有非EPOLLONESHONT或EPOLLET事件 if (!(epi-&gt;event.events &amp; ~EP_PRIVATE_BITS)) goto out_unlock; if (unlikely(ep-&gt;ovflist != EP_UNACTIVE_PTR)) &#123; if (epi-&gt;next == EP_UNACTIVE_PTR) &#123; epi-&gt;next = ep-&gt;ovflist; ep-&gt;ovflist = epi; &#125; goto out_unlock; &#125; if (ep_is_linked(&amp;epi-&gt;rdllink)) goto is_linked; //***关键***，将该fd加入到epoll监听的就绪链表中 list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); //唤醒调用epoll_wait()函数时睡眠的进程。用户层epoll_wait(...) 超时前返回。 if (waitqueue_active(&amp;ep-&gt;wq)) __wake_up_locked(&amp;ep-&gt;wq, TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE); if (waitqueue_active(&amp;ep-&gt;poll_wait)) pwake++; out_unlock: spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); if (pwake) ep_poll_safewake(&amp;psw, &amp;ep-&gt;poll_wait); return 1;&#125;/*所以ep_poll_callback函数主要的功能是将被监视文件的等待事件就绪时，将文件对应的epitem实例添加到就绪队列中，当用户调用epoll_wait()时，内核会将就绪队列中的事件报告给用户。*/ epoll_wait实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041SYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) &#123; int error; struct file *file; struct eventpoll *ep; /* 检查maxevents参数。 */ if (maxevents &lt;= 0 || maxevents &gt; EP_MAX_EVENTS) return -EINVAL; /* 检查用户空间传入的events指向的内存是否可写。参见__range_not_ok()。 */ if (!access_ok(VERIFY_WRITE, events, maxevents * sizeof(struct epoll_event))) &#123; error = -EFAULT; goto error_return; &#125; /* 获取epfd对应的eventpoll文件的file实例，file结构是在epoll_create中创建。 */ error = -EBADF; file = fget(epfd); if (!file) goto error_return; /* 通过检查epfd对应的文件操作是不是eventpoll_fops 来判断epfd是否是一个eventpoll文件。如果不是则返回EINVAL错误。 */ error = -EINVAL; if (!is_file_epoll(file)) goto error_fput; /* At this point it is safe to assume that the \"private_data\" contains */ ep = file-&gt;private_data; /* Time to fish for events ... */ error = ep_poll(ep, events, maxevents, timeout); error_fput: fput(file);error_return: return error;&#125; epoll_wait调用ep_poll，ep_poll实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, long timeout) &#123; int res, eavail; unsigned long flags; long jtimeout; wait_queue_t wait; /* timeout是以毫秒为单位，这里是要转换为jiffies时间。这里加上999(即1000-1)，是为了向上取整。 */ jtimeout = (timeout &lt; 0 || timeout &gt;= EP_MAX_MSTIMEO) ?MAX_SCHEDULE_TIMEOUT : (timeout * HZ + 999) / 1000;retry: spin_lock_irqsave(&amp;ep-&gt;lock, flags); res = 0; if (list_empty(&amp;ep-&gt;rdllist)) &#123; /* 没有事件，所以需要睡眠。当有事件到来时，睡眠会被ep_poll_callback函数唤醒。*/ init_waitqueue_entry(&amp;wait, current); //将current进程放在wait这个等待队列中。 wait.flags |= WQ_FLAG_EXCLUSIVE; /* 将当前进程加入到eventpoll的等待队列中，等待文件状态就绪或直到超时，或被信号中断。 */ __add_wait_queue(&amp;ep-&gt;wq, &amp;wait); for (;;) &#123; /* 执行ep_poll_callback()唤醒时应当需要将当前进程唤醒，所以当前进程状态应该为“可唤醒”TASK_INTERRUPTIBLE */ set_current_state(TASK_INTERRUPTIBLE); /* 如果就绪队列不为空，也就是说已经有文件的状态就绪或者超时，则退出循环。*/ if (!list_empty(&amp;ep-&gt;rdllist) || !jtimeout) break; /* 如果当前进程接收到信号，则退出循环，返回EINTR错误 */ if (signal_pending(current)) &#123; res = -EINTR; break; &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); /* 主动让出处理器，等待ep_poll_callback()将当前进程唤醒或者超时,返回值是剩余的时间。 从这里开始当前进程会进入睡眠状态，直到某些文件的状态就绪或者超时。 当文件状态就绪时，eventpoll的回调函数ep_poll_callback()会唤醒在ep-&gt;wq指向的等待队列中的进程。*/ jtimeout = schedule_timeout(jtimeout); spin_lock_irqsave(&amp;ep-&gt;lock, flags); &#125; __remove_wait_queue(&amp;ep-&gt;wq, &amp;wait); set_current_state(TASK_RUNNING); &#125; /* ep-&gt;ovflist链表存储的向用户传递事件时暂存就绪的文件。 * 所以不管是就绪队列ep-&gt;rdllist不为空，或者ep-&gt;ovflist不等于 * EP_UNACTIVE_PTR，都有可能现在已经有文件的状态就绪。 * ep-&gt;ovflist不等于EP_UNACTIVE_PTR有两种情况，一种是NULL，此时 * 可能正在向用户传递事件，不一定就有文件状态就绪， * 一种情况时不为NULL，此时可以肯定有文件状态就绪， * 参见ep_send_events()。 */ eavail = !list_empty(&amp;ep-&gt;rdllist) || ep-&gt;ovflist != EP_UNACTIVE_PTR; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); /* Try to transfer events to user space. In case we get 0 events and there's still timeout left over, we go trying again in search of more luck. */ /* 如果没有被信号中断，并且有事件就绪，但是没有获取到事件(有可能被其他进程获取到了)，并且没有超时，则跳转到retry标签处，重新等待文件状态就绪。 */ if (!res &amp;&amp; eavail &amp;&amp; !(res = ep_send_events(ep, events, maxevents)) &amp;&amp; jtimeout) goto retry; /* 返回获取到的事件的个数或者错误码 */ return res;&#125;/*ep_send_events函数向用户空间发送就绪事件。ep_send_events()函数将用户传入的内存简单封装到ep_send_events_data结构中，然后调用ep_scan_ready_list() 将就绪队列中的事件传入用户空间的内存。用户空间访问这个结果，进行处理。*/ 结构如下 总结 详细分析请点击此处 精简流程请点击此处 原文查看请点击此处","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"I/O复用","slug":"I-O复用","permalink":"http://roux.top/tags/I-O复用/"}]},{"title":"glibc内存分配与回收","slug":"ptmalloc","date":"2017-11-21T16:00:00.000Z","updated":"2018-04-22T05:53:20.502Z","comments":true,"path":"2017/11/22/ptmalloc/","link":"","permalink":"http://roux.top/2017/11/22/ptmalloc/","excerpt":"前言 部分基础请先看此文 先解释一下本文中会提到的三个重要概念：arena，bin，chunk。三者在逻辑上的蕴含关系一般如下图所示（图中的chunk严格来说应该是Free Chunk）。","text":"前言 部分基础请先看此文 先解释一下本文中会提到的三个重要概念：arena，bin，chunk。三者在逻辑上的蕴含关系一般如下图所示（图中的chunk严格来说应该是Free Chunk）。 arena：通过 sbrk 或 mmap 系统调用为线程分配的堆区，按线程的类型可以分为2类： main arena：主线程建立的arena； thread arena：子线程建立的arena； chunk：逻辑上划分的一小块内存，根据作用不同分为4类： Allocated chunk：即分配给用户且未释放的内存块； Free chunk：即用户已经释放的内存块； Top chunk Last Remainder chunk bin：一个用以保存 Free chunk 链表的表头信息的指针数组，按所悬挂链表的类型可以分为4类: Fast bin Unsorted bin Small bin Large bin 实际内存中，main arena 和 thread arena 的图示如下（单堆段）: 其中 malloc_state 的数据结构描述在源代码中的位置请点这里，可以发现该数据结构中保存着 fastbinsY、top、last_remainder、bins 这四个分别表示 Fast bin、Top chunk、Last Remainder chunk、bins（Unsorted bin、 Small bin、Large bin） 的数据。 Arena级分析 部分内容请参考此文 main arena中的内存申请 main arena中的内存申请的流程如下图所示： 第一次申请 根据申请内存空间大小是否达到 mmap 这一系统调用的分配阈值，决定是使用 sbrk 系统调用 还是 mmap 系统调用申请堆区。一般分配的空间比申请的要大（详见此处），这样可以减少后续申请中向操作系统申请内存的次数。 举例而言，用户申请1000字节的内存，实际会通过sbrk系统调用产生 132KB 的连续堆内存区域。 然后将用户申请大小的内存返回。（本例中将返回1000字节的内存。） 后续申请 根据 arena 中剩余空间的大小决定是继续分配还是扩容，其中包含扩容部分的为 top chunk。 然后将用户申请大小的内存返回。 注意： top chunk 不属于任何bin！只有 free chunk 依附于bin！ 分配阈值具有默认值，但会动态调整； 扩容具体过程见库函数 sYSMALLOc 。 thread arena中的申请 thread arena中的内存申请的流程如下图所示： 其流程类似于main arena的，区别在于thread arena的堆内存是使用mmap系统调用产生的，而非同主线程一样可能会使用sbrk系统调用。 注意：Arena的数量与线程之间并不一定是一一映射的关系 内存回收 线程释放的内存不会直接返还给操作系统，而是返还给 glibc malloc bin级分析 内存分配 内存分配的流程如下图所示： 我们知道，内存分配的最终目的在于分配出合适大小的内存块返回给用户。在实现中即为在 bin 或 top chunk 中找到（并分割出）所需内存块，其检索的优先级从高到低分别是： 123456789- fastbinY- small bins- unsorted bins- large bins- top bins 注意： Fast bin、Unsorted bin、Small bin 和 Large bin 中保存的都是用户曾经释放的内存块（可能经过合并） top chunk 包含 Arena 扩容的部分，不属于任何 bin 内存回收 内存回收的流程如下图所示： 我们提到了 bin 可以分为4类：Fast bin、Unsorted bin、Small bin 和 Large bin。保存这些 bin 的数据结构为fastbinsY 以及 bins： fastbinsY：用以保存 fast bins。（可索引大小16~64B的内存块） bins：用以保存 unsorted、small以及 large bins ，共计可容纳126个： Bin 1 – unsorted bin Bin 2 to Bin 63 – small bin(可索引大小小于512B的内存块) Bin 64 to Bin 126 – large bin（可索引大小≥512B的内存块） 在内存被释放的时候，被释放内存块会根据其大小而被添加入对应的bin中： 16~64B 的内存块会被添加入 fastbinY 中 samll 及 large 的会添加在 bins 中的 unsorted bins 中 注意：small bins 和 large bins 中索引的内存块是在内存分配的过程中被添加在相应的 bin 中的 chunk级分析 ptmalloc 在给用户分配的空间的前后加上了一些控制信息, 用这样的方法来记录分配的信息, 以便完成分配和释放工作. 一个使用中的chuck( 使用中, 就是指还没有被free掉 ) 在内存中的样子如图所示： 在图中, chunk 指针指向一个 chunk 的开始, 一个chunk 中包含了用户请求的内存区域和相关的控制信息. 图中的 mem 指针才是真正返回给用户的内存指针。 chunk 的第二个域的最低一位为 p, 它表示前一个块是否在使用中, p 为 0则表示前一个 chunk 为空闲, 这时 chunk 的第一个域 prev_size 才有效, prev_size 表示前一个 chunk 的 size, 程序可以使用这个值来找到前一个 chunk 的开始. 当 p 为 1 时, 表示前一个 chunk 正在使用中, prev_size 无效, 程序也就不可以得到前一个 chunk 的大小. 而不能对前一个 chunk 进行任何操作. ptmalloc 分配的第一个块总是将 p 设为 1 , 以防止程序引用到不存在的区域。空闲 chunk 在内存中的结构如图所示： 当 chunk 空闲时, 原本是用户数据区的地方存储了两个指针, 指针 fd 指向后一个空闲的 chunk, 而 bk 指向前一个空闲的 chunk, ptmalloc 通过这两个指针将大小相近的 chunk 连成一个双向链表. 而不同的 chunk 链表又是通过 bins 或者 fastbins 来组织的 为了使得 chunk 所占用的空间最小, ptmalloc 使用了空间复用, 一个 chunk 或者正在被使用, 或者已经被 free 掉, 所以 chunk 中的一些域可以在使用状态和空闲状态表示不同的意义, 来达到空间复用的效果。空闲时, 一个 chunk 中至少要4个 size_t 大小的空间, 用来存储 prev_size, size , fd 和 bk。 也就是 16 bytes. chuck 的大小要 align 到8 bytes. 当一个 chunk 处于使用状态时, 它的下一个 chunk 的 prev_size 域肯定是无效的。 所以实际上, 这个空间也可以被当前 chunk 使用. 这听起来有点不可思议, 但确实是合理空间复用的例子. 故而实际上, 一个使用中的 chunk 的大小的计算公式应该是: in_use_size = ( 用户请求大小 + 8 - 4 ) align to 8 bytes 这里加8是因为需要存储 prev_size 和 size, 但又因为向下一个 chunk 借 了4个bytes , 所以要减去4 . 最后, 因为空闲的 chunk 和使用中的 chunk 使用的是同一块空间。 所以肯定要取其中最大者作为实际的分配空间。 即最终的分配空间 chunk_size = max(in_use_size, 16)。 这就是当用户请求内存分配时, ptmalloc 实际需要分配的内存大小, 在后面的介绍中. 如果不是特别指明的地方, 指的都是这个经过转换的实际需要分配的内存大小, 而不是用户请求的内存分配大小. 空闲的chunk Bins 用户 free 掉的内存并不是都会马上归还给系统, 相反, ptmalloc 会统一管理 heap 中的空闲的 chunk ， 当用户进行下一次分配请求时, ptmalloc 会首先试图在 heap 中空闲的 chunk 中挑选一块给用户， 这样就避免了频繁的系统调用， 降低了内存分配的开销。 ptmalloc 将 heap 中相似大小的 chunk 用双向链表链接起来， 这样的一个链表被称为一个bin，ptmalloc 使用一个数组来存储这些 bin 如下图： 数组中的前64个 bin 称为 exact bins, exact bins 中的 chunk 具有相同的大小。 两个相邻的 bin 中的 chunk 大小相差8 bytes. exact bins 中的 chunk 按照最近使用顺序进行排列, 最后释放的 chunk 被链接到链表的头部, 而 allocation 是从尾部开始, 这样, 每一个 chunk 都有相同的机会被 ptmalloc 选中。 后面的 bin 被称作 ordered bins。 ordered bins 中的每一个 bin 分别包含了一个给定范围内的 chunk, 其中的 chunk 按大小序排列。 相同大小的 chunk 同样按照最近使用顺序排列. ptmalloc 使用 smallest-first, best-fit 的原则在空闲 ordered bins 中查找合适的 chunk. 当空闲的 chunk 被链接到bin中的时候, ptmalloc 会把表示该 chunk 是否处于使用中的标志 p 设为 0 (注意, 这个标志实际上处在下一个 chunk 中), 同时 ptmalloc 还会检查它前后的 chunk 是否也是空闲的, 如果是的话, ptmalloc 会首先把它们合并为一个大的 chunk, 然后将合并后的 chunk 放到 bin 中。 要注意的是, 并不是所有的 chunk 被释放后就立即被放到bin中。 ptmalloc 为了提高分配的速度, 会把一些小的的 chunk 先放到一个叫做 fastbin的容器内。 Fastbins 一般的情况是, 程序在运行时会经常需要分配和释放一些较小的内存空间. 当 allocator(分配器) 合并了相邻的几个小的 chunk 之后, 也许马上就会有另一个小块内存的请求, 这样 allocator 又需要从大的空闲内存中分出一块出来, 这样无疑是比较低效的, 故而, ptmalloc 中在分配过程中引入了 fastbins, 不大于 max_fast (72 bytes) 的 chunk 被 free 后, 首先会被放到 fastbins 中, fastbins 中的 chunk 并不改变它的使用标志 p。 这样也就无法将它们合并, 当需要给用户分配的 chunk 小于或等于 max_fast 时, ptmalloc 首先会在 fastbins 中查找相应的空闲块, 然后才会去查找 bins 中的空间 chunk. 在某个特定的时候, ptmalloc 会遍历 fastbins 中的 chunk, 将相邻的空闲 chunk 进行合并, 并将合并后的 chunk 放到 bins 中去。 Unsorted Bins 如果被用户释放的 chunk 大于 max_fast, 则按上面的叙述它应该会被放到 bins 中. 但实际上, ptmalloc 还引入了一个称为 unsorted bins 的队列. 这些大于 max_fast 的chunk 首先会被放到 unsorted bins 队列中, 在进行 malloc 操作的时候, 如果在 fastbins 中没有找到合适的 chunk, 则 ptmalloc 会先在 unsorted bins 中查找合适的空闲 chunk, 然后才查找 bins。 如果 unsorted bins 不能满足分配要求. malloc 便会将 unsorted bins 中的 chunk 放到 bins 中, 然后再在 bins 中继续进行查找和分配过程。 从这个过程可以看出来, unsorted bins 可以看做是 bins 的一个缓冲区, 增加它只是为了加快分配的速度, 忽略它对我们理解 ptmalloc 没有太大的影响。 例外的 chunk 并不是所有的 chunk 都按照上面的方式来组织, 实际上, 有两种例外情况. top chunk 在前面一直提到, ptmalloc 会预先分配一块较大的空闲内存(也就是所为的 heap), 而通过管理这块内存来响应用户的需求, 因为内存是按地址从低向高进行分配的, 在空闲内存的最高处, 必然存在着一块空闲 chunk, 叫做 top chunk。 当 bins 和 fastbins 都不能满足分配需要的时候, ptmalloc 会设法在 top chunk 中分出一块内存给用户, 如果 top chunk 本身不够大, 则 ptmalloc 会适当的增加它的大小(也就增加了 heap 的大小)。 以满足分配的需要, 实际上, top chunk 在分配时总是在 fastbins 和 bins 之后被考虑, 所以, 不论 top chunk 有多大, 它都不会被放到 fastbins 或者是 bins 中. mmaped chunk 当需要分配的 chunk 足够大, 而且 fastbins 和 bins 都不能满足要求, 甚至 top chunk 本身也不能满足分配需求时, ptmalloc 会使用 mmap 来直接使用内存映射来将页映射到进程空间。 这样分配的 chunk 在被 free 时将直接解除映射, 于是就将内存归还给了系统, 再次对这样的内存区的引用将导致一个 segmentation fault 错误. 这样的 chunk 也不会包含在任何 bin 中。 下图即内存分配的详细过程图： sbark与mmap 此处只是简单的介绍下，详细的可以参考本博客以前的文章(首页搜索mmap) sbark .bss 段之上的这块分配给用户程序的空间被称为 heap (堆). start_brk 指向 heap 的开始, 而 brk 指向 heap 的顶部. 可以使用系统调用 brk 和 sbrk 来增加标识 heap 顶部的 brk 值, 从而线性的增加分配给用户的 heap 空间. 在使用malloc之前, brk 的值等于 start_brk, 也就是说 heap 大小为0. ptmalloc 在开始时, 若请求的空间小于 DEFAULT_MMAP_THRESHOLD (128K bytes)时, ptmalloc 会调用 sbrk 增加一块大小为 ( 128 KB + chunk_size ) align 4K 的空间作为heap. 这就是前面所说的 ptmalloc 所维护的分配空间, 当用户请求内存分配时, 首先会在这个区域内找一块合适的 chunk 给用户. 当用户释放了 heap 中的 chunk 时, ptmalloc 又会使用 fastbins 和 bins 来组织空闲 chunk. 以备用户的下一次分配. 若需要分配的 chunk 大小小于 DEFAULT_MMAP_THRESHOLD, 而 heap 空间又不够, 则此时 ptmalloc 会通过 sbrk 调用来增加 heap 值, 也就是增加 top chunk 的大小, 每次 heap 增加的值都会 align 到4k bytes mmap 当用户的请求超过 DEFAULT_MMAP_THRESHOLD , 并且使用 sbrk 分配失败的时候, ptmalloc 会尝试使用 mmap 直接映射一块内存到进程内存空间. 使用 mmap 直接映射的 chunk 在释放时直接解除映射, 而不再属于进程的内存空间. 任何对该内存的访问都会产生段错误. 而在 heap 中分配的空间则可能会留在进程内存空间内, 还可以再次引用(当然是很危险的) 注意 从操作系统的角度看，进程的内存分配由两个系统调用完成：brk和mmap。brk是将数据段(.data)的最高地址指针 _edata 往高地址推，mmap 是在进程的虚拟地址空间中找一块空闲的。其中，mmap 分配的内存由 munmap 释放，内存释放时将立即归还操作系统；而brk分配的内存需要等到高地址内存释放以后才能释放。也就是说，如果先后通过 brk 申请了 A 和 B 两块内存，在 B 释放之前，A 是不可能释放的，仍然被进程占用，通过 top 查看疑似内存泄露。默认情况下，大于等于128KB的内存分配会调用mmap/mummap，小于128KB的内存请求调用sbrk（可以通过设置M_MMAP_THRESHOLD来调整） Glibc的新特性：M_MMAP_THRESHOLD 可以动态调整。M_MMAP_THRESHOLD 的值在 128KB 到 32MB(32位机) 或者 64MB(64位机) 之间动态调整，假如每次申请并释放一个大小为 2MB 的内存后，那么M_MMAP_THRESHOLD 的值会被调整为 2M 到2M + 4K之间的一个值。示例如下： 12345char* no_used = new char[2 * 1024 * 1024];memset(no_used, 0xfe, 2 * 1024 * 1024);delete[] no_used;// M_MMAP_THRESHOLD的值调整为 2M 到 2M + 4K 之间的一个值，后续申请 &lt;= 2 * 1024 * 1024 的内存块都会走 sbrk 而不是 mmap//而sbrk需要等到高地址内存释放以后低地址内存才能释放,会造成疑似内存泄漏的现象 mmap调用是会导致进程产生缺页中断的，为了提高性能，可以设置如下： 将动态内存改为静态，比如采用内存池技术或者启动的时候给每个线程分配一定大小，以后直接使用； 禁止mmap内存调用，禁止Glibc内存缩紧将内存归还系统，Glibc相当于实现了一个内存池功能。只需要在进程启动的时候加入两行代码： 12mallopt(M_MMAP_MAX, 0); // 禁止malloc调用mmap分配内存mallopt(M_TRIM_THRESHOLD, 0); // 禁止内存缩进，sbrk申请的内存释放后不会归还给操作系统 maolloc ptmalloc 的响应用户内存分配要求的具体步骤为: 1、获取分配区的锁，为了防止多个线程同时访问同一个分配区，在进行分配之前需要取得分配区域的锁。线程先查看线程私有实例中是否已经存在一个分配区，如果存在尝试对该分配区加锁，如果加锁成功，使用该分配区分配内存，否则，该线程搜索分配区循环链表试图获得一个空闲（没有加锁）的分配区。如果所有的分配区都已经加锁，那么 ptmalloc 会开辟一个新的分配区，把该分配区加入到全局分配区循环链表和线程的私有实例中并加锁，然后使用该分配区进行分配操作。开辟出来的新分配区一定为非主分配区，因为主分配区是从父进程那里继承来的。开辟非主分配区时会调用 mmap() 创建一个 sub-heap，并设置好 top chunk。 2、将用户的请求大小转换为实际需要分配的chunk空间大小。 3、判断所需分配 chunk 的大小是否满足 chunk_size &lt;= max_fast (max_fast 默认为 64B) ，如果是的话，则转下一步，否则跳到第5步。 4、首先尝试在 fast bins 中取一个所需大小的 chunk 分配给用户。如果可以找到，则分配结束。否则转到下一步。 5、判断所需大小是否处在 small bins 中，即判断 chunk_size &lt; 512B 是否成立。如果 chunk 大小处在 small bins 中，则转下一步，否则转到第6步。 6、根据所需分配的chunk的大小，找到具体所在的某个 small bin，从该 bin 的尾部摘取一个恰好满足大小的 chunk。若成功，则分配结束，否则，转到下一步。 7、到了这一步，说明需要分配的是一块大的内存，或者 small bins 中找不到合适的 chunk。于是，ptmalloc首先会遍历 fast bins 中的chunk，将相邻的 chunk 进行合并，并链接到 unsorted bin 中，然后遍历 unsorted bin 中的 chunk，如果 unsorted bin 只有一个 chunk，并且这个 chunk 在上次分配时被使用过，并且所需分配的 chunk 大小属于 small bins，并且 chunk 的大小大于等于需要分配的大小，这种情况下就直接将该 chunk 进行切割，分配结束，否则将根据 chunk 的空间大小将其放入 small bins 或是 large bins 中，遍历完成后，转入下一步。 8、到了这一步，说明需要分配的是一块大的内存，或者 small bins 和 unsorted bin 中都找不到合适的 chunk，并且 fast bins 和 unsorted bin 中所有的 chunk 都清除干净了。从 large bins 中按照 smallest-first，best-fit 原则，找一个合适的 chunk，从中划分一块所需大小的 chunk，并将剩下的部分链接回到 bins 中。若操作成功，则分配结束，否则转到下一步。 9、如果搜索 fast bins 和 bins 都没有找到合适的 chunk，那么就需要操作 top chunk 来进行分配了。判断 top chunk 大小是否满足所需 chunk 的大小，如果是，则从 top chunk 中分出一块来。否则转到下一步。 10、到了这一步，说明 top chunk 也不能满足分配要求，所以，于是就有了两个选择: 如果是主分配区，调用 sbrk()，增加 top chunk 大小；如果是非主分配区，调用 mmap() 来分配一个新的 sub-heap，增加 top chunk 大小；或者使用 mmap() 来直接分配。在这里，需要依靠 chunk 的大小来决定到底使用哪种方法。判断所需分配的 chunk 大小是否大于等于 mmap 分配阈值，如果是的话，则转下一步，调用 mmap() 分配，否则跳到第12步，增加 top chunk 的大小。 11、使用 mmap 系统调用为程序的内存空间映射一块 chunk_size align 4kB 大小的空间。 然后将内存指针返回给用户。 12、判断是否为第一次调用 malloc，若是主分配区，则需要进行一次初始化工作，分配一块大小为 (chunk_size + 128KB) align 4KB 大小的空间作为初始的 heap。若已经初始化过了，主分配区则调用 sbrk() 增加 heap 空间，分主分配区则在 top chunk 中切割出一个 chunk，使之满足分配需求，并将内存指针返回给用户。 free free() 函数接受一个指向分配区域的指针作为参数, 释放该指针所指向的 chunk. 而具体的释放方法则看该 chunk 所处的位置和该 chunk 的大小. free()函数的工作步骤如下: 1、free() 函数同样首先需要获取分配区的锁, 来保证线程安全. 2、判断传入的指针是否为0, 如果为0, 则什么都不做, 直接r eturn. 否则转下一步: 3、判断所需释放的 chunk 是否为 mmaped chunk, 如果是, 则直接释放 mmaped chunk, 解除内存空间映射. 该空间不再有效. 释放完成. 否则跳到下一步. 4、判断 chunk 的大小和所处的位置, 若 chunk_size &lt;= max_fast , 并且 chunk 并不位于 heap 的顶部, 也就是说并不与 top chunk 相邻, 则转到下一步, 否则跳到第6步. (因为与 top chunk 相邻的小 chunk 也和 top chunk 进行合并, 所以这里不仅需要判断大小, 还需要判断相邻情况.) 5、将 chunk 放到 fastbins 中, chunk 放入到 fastbins 中时, 并不设置该 chunk 使用位. 也不与相邻的 chunk 进行合并. 只是放进去, 如此而已. 做实验的结果还发现 ptmalloc 放入 fastbins 中的 chunk 中的用户数据去全置为 0. 但是在源代码中找不到相关的代码. 这一步做完之后释放便结束了, 程序从 free() 函数中返回.. 6、判断前一个 chunk 是否处在使用中, 如果前一个块也是空闲块, 则合并. 并转下一步. 7、判断当前释放 chunk 的下一个块是否为 top chunk, 如果是, 则转第9步, 否则转下一步. 8、判断下一个 chunk 是否处在使用中, 如果下一个 chunk 也是空闲的. 则合并, 并将合并后的 chunk 放到 bins 中. 注意, 这里在合并的过程中, 要更新 chunk 的大小, 以反映合并后的 chunk 的大小. 并转到第10步. 9、如果执行到这一步, 说明释放了一个与 top chunk 相邻的chunk. 则无论它有多大, 都将它与 top chunk 合并, 并更新 top chunk 的大小等信息. 转下一步. 10、判断合并后的 chunk 的大小是否大于 FASTBIN_CONSOLIDATION_THRESHOLD, 如果是的话, 则会触发进行 fastbins 的合并操作, fastbins 中的 chunk 将被遍历, 并于相邻的空闲 chunk 进行合并, 合并后的 chunk 会被放到 bins 中. fastbins 将变为空, 操作完成之后转下一步. 11、判断 top chunk 的大小是否大于 DEFAULT_TRIM_THERESHOLD. 如果是的话, 则会试图归还 top chunk 中的一部分给操作系统. 但是最先分配的 128KB 的空间是不会归还. ptmalloc 会一直控制这部分内存. 用于响应用户的分配请求. 做完这一步之后, 释放结束, 从 free 函数退出. 总结 详细剖析请点击此处 线程相关点击此处","categories":[{"name":"OS","slug":"OS","permalink":"http://roux.top/categories/OS/"}],"tags":[{"name":"内存分配","slug":"内存分配","permalink":"http://roux.top/tags/内存分配/"}]},{"title":"glibc内存分配基础","slug":"glibc基础分析","date":"2017-11-20T16:00:00.000Z","updated":"2018-04-22T05:50:59.895Z","comments":true,"path":"2017/11/21/glibc基础分析/","link":"","permalink":"http://roux.top/2017/11/21/glibc基础分析/","excerpt":"前言 对于很多开发者来说，内存分配和回收似乎一直都是操作系统的事情。特别是现在大多高级语言都自带 GC, 让程序员这方面的意识会更加薄弱。可能有很大一部分人认为, 我要 100byte 的空间, 那么系统就只会给我 100byte。","text":"前言 对于很多开发者来说，内存分配和回收似乎一直都是操作系统的事情。特别是现在大多高级语言都自带 GC, 让程序员这方面的意识会更加薄弱。可能有很大一部分人认为, 我要 100byte 的空间, 那么系统就只会给我 100byte。 分析 下面先来看一段代码: 1234567891011121314151617void *fn(void *args) &#123; malloc(100); // 申请 100 byte sleep(128); // 休息 128s,为了方便查看内存进程使用 return NULL;&#125;int main(int argc, char *argv[]) &#123; num = 16; pthread_t pids[num]; for (i = 0; i &lt; num; i++) &#123; pthread_create(&amp;pids[i], NULL, fn, NULL); &#125; for (i = 0; i &lt; num; i++) &#123; pthread_join(pids[i], NULL); &#125; return 0;&#125; 代码很简单: 启动 16 个线程，每个线程申请 100 byte。理论上内存使用应该是 100 byte * 16 = 1600 byte, 加上一些元数据也就 K 级别的内存。而我们在 Centos(64bit) 跑一下，发现内存使用的情况如下: 我们发现占用了 1G 的虚拟内存，看一下虚拟内存的分布，发现里面多了一堆 64M 的内存分配，而且数量刚好等于线程数。 那么问题就来了，为什么每个线程都分配了一个 64M 呢。 Arena(分配区) 导致分配这么多内存的原因其实在之前的一篇文章已经介绍。glibc 为了提高的多核场景的内存分配效率，当并发分配内存的时候，会产生多个内存分配区。每个分配区会每次向操作系统 “批发” 一片内存(64bit机器的大小是 64M), 然后再基于批发过来的内存上面分配内存，这个就是上面为什么会申请这么多 64M 内存块的原因。 这个问题并不是本文讨论的重点，只是为了引出操作系统分配内存方式在特定的场景会和我们想象的有很大的差别，进一步来细说 glibc 的内存分配方式。 sub-heap 每个进程内部只有一个主分配区以及可能会有多个非主分配区(non-arena), 主分配区分配虚拟内存可以使用 sbrk 以及 mmap， 而非主分配区是同 sub-heap(子堆) 来管理内存。 非主分配区每次会向操作系统申请一块固定大小的内存(64bit机器默认是64M)，这个固定的堆大小就叫做 sub-heap。每次分配内存先从sub-heap 里面分配，如果不够再从操作系统申请一个新的 sub-heap, 这些 sub-heap 通过链表连接起来。 小块内存 glibc 的内存分配并不是我们所想的那样，申请 100byte 就从向操作系统申请 100byte， 释放就马上归还给操作系统，而是做了一层 “缓存”, 避免频繁的触发系统调用而导致程序性能下降。 每个分配区都有一个 “缓存”，”缓存” 的几个基本组成部分是: 1234567- fast bins- unsorted bins- small bins &amp; large bins- top chunk fast bins 是用来加速小块分配。当分配或者释放小块内存(阀值默认是 64byte)， 会优先从 fast bins 里面查找，如果没有再到其他的缓存区域查找。这个阀值可以通过 M_MXFAST 来设置，最大是 80byte. unsorted bins 用来存放，大于 fast bins 阀值的内存块合并后的块，并在特定的时机会把这些内存块整理放到 small bins, large bins.. small bins &amp; large bins 和 memcached 的 slabclass 角色类似，small bins 的各个 bin 的内存块是等长的，但 large bins 同一个 bin 里面的内存块并不是等长的。 small bins 每个 bin 之间差是 8byte，最小的是 16byte, 接着是 24byte, 32byte… 最大是 512 byte large bins 差依次为 64B、512B、4096B、32768B、262144B top chunk 我们内存分配是从 sub-heap 分配出来，sub-heap 剩余未分配的部分就叫 top-chunk。内存分配会从上面那些 bin 优先分配，如果无法满足需求再通过 top-chunk 分配。 如果 top-chunk 空间不足，就会创建一个新的 sub-heap, 然后把新 sub-heap 的开始位置设置为 top-chunk. 大块内存 上面说到内存分配是通过 sub-heap 来分配，而 sub-heap 是固定大小的空间，那万一我申请的内存比这个怎么办？ glibc 可以设置 MMAP_THRESHOLD ，当超过这个阀值内存分配不是走 sub-heap 来分配, 而是通过 mmap 来分配内存。释放内存的时候直接通过 unmmap 直接把内存归还给操作系统。 需要注意的点是， mmap 分配匿名内存页是会初始化这些内存页，这对性能会有一些损耗。不太适合不断的 mmap 和 unmmap。 出处 http://www.hulkdev.com/posts/glibc-basic","categories":[{"name":"OS","slug":"OS","permalink":"http://roux.top/categories/OS/"}],"tags":[{"name":"内存分配","slug":"内存分配","permalink":"http://roux.top/tags/内存分配/"}]},{"title":"glibc内存分配之arena","slug":"arena","date":"2017-11-20T16:00:00.000Z","updated":"2018-04-22T05:50:29.455Z","comments":true,"path":"2017/11/21/arena/","link":"","permalink":"http://roux.top/2017/11/21/arena/","excerpt":"分配区 内存分配器启动默认初始化一个分配区，我们叫主分配区。一般内存分配会从主分配区进行分配，但对于多线程来说，每次分配都要等待其他线程分配完成，这个效率是非常低的。 为了解决这个问题引入子分配区，子分配区和主分配区构成一个环形链表。","text":"分配区 内存分配器启动默认初始化一个分配区，我们叫主分配区。一般内存分配会从主分配区进行分配，但对于多线程来说，每次分配都要等待其他线程分配完成，这个效率是非常低的。 为了解决这个问题引入子分配区，子分配区和主分配区构成一个环形链表。 分配内存的时候，遍历链表，看哪个分配区没有加锁，说明这个分配区没有被占用，直接使用。如果所有的分配区全部被使用，就创建一个新的分配区。 代码实现在 arena.c 的 arena_get 函数: 12345678910#define arena_get(ptr, size) do &#123; \\Void_t *vptr = NULL; \\ // 优先判断线程私有变量的分配区是否被占用 ptr = (mstate)tsd_getspecific(arena_key, vptr); \\ if(ptr &amp;&amp; !mutex_trylock(&amp;ptr-&gt;mutex)) &#123; \\ THREAD_STAT(++(ptr-&gt;stat_lock_direct)); \\ &#125; else \\ // 线程私有变量的分配区被占用, 用 arena_get2 获取分配区 ptr = arena_get2(ptr, (size)); \\ &#125; while(0) 每个线程的私有变量会存放一个分配区指针，分配时先判断这个分配区是否已经被占用。 如果未被占用，直接返回这个分配区 线程私有变量的分配区被占用，使用 arena_get2 来获取可用的分配区 123456789101112131415161718192021222324252627282930313233343536arena_get2(mstate a_tsd, size_t size)&#123; ... // 遍历已有的分配区链表，尝试找到没有被占用的分配区 do &#123; if(!mutex_trylock(&amp;a-&gt;mutex)) &#123; THREAD_STAT(++(a-&gt;stat_lock_loop)); tsd_setspecific(arena_key, (Void_t *)a); return a; &#125; a = a-&gt;next; &#125; while(a != a_tsd); ... // 如果没有找到空闲的分配区，则新建一个新的分配区 a = _int_new_arena(size); if(!a) return 0; // 新分配区指针放到线程私有变量 tsd_setspecific(arena_key, (Void_t *)a); // 新分配区加入分配区链表 mutex_init(&amp;a-&gt;mutex); err = mutex_lock(&amp;a-&gt;mutex); /* remember result */ /* Add the new arena to the global list. */ (void)mutex_lock(&amp;list_lock); a-&gt;next = main_arena.next; atomic_write_barrier (); main_arena.next = a; (void)mutex_unlock(&amp;list_lock);&#125; arena_get2 的实现很简单，先从分配区链表分配，如果失败，创建新的分配区。也就是说如果在不做限制的情况下， N 个线程就可能会有 N 个分配区。 区别 我们一般分配虚拟内存可以有两种方式，一种是直接调用 sbrk 系统调用来分配内存，另外一种方式是通过 mmap 来分配一块虚拟内存。 对于主分配区两种分配方式都可以使用，而对于子分配区，则是每次通过 mmap 来申请一大块内存，这个是这两种分配方式的主要区别。 在 32位的机器上，子分配区每次申请的 1M 大小的虚拟内存，64 位每次申请 64M。 注意 是否可以不管线程个数多少，都将线程与 arena 的个数做一一映射呢？答案是 NO！某些应用程序可能有很多线程（大于 CPU 个数），在这种情况下，如果我们给每个线程配一个 arena 简直是找麻烦，而且很没意义。所以呢，我们应用程序的 arena 数目受制于系统中 CPU 个数： 32位：2 * CPU核数 64位：8 * CPU核数 出处 http://www.hulkdev.com/posts/glibc-arena","categories":[{"name":"OS","slug":"OS","permalink":"http://roux.top/categories/OS/"}],"tags":[{"name":"内存分配","slug":"内存分配","permalink":"http://roux.top/tags/内存分配/"}]},{"title":"epoll函数","slug":"epoll函数","date":"2017-11-19T16:00:00.000Z","updated":"2018-04-22T05:48:54.383Z","comments":true,"path":"2017/11/20/epoll函数/","link":"","permalink":"http://roux.top/2017/11/20/epoll函数/","excerpt":"前言 epoll是什么 epoll 是Linux下多路复用IO接口 select/poll 的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率，因为它会复用文件描述符集用来传递结果而不用迫使开发者每次等待事件之前都必须重新准备要被侦听的文件描述符集合，另一点原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。","text":"前言 epoll是什么 epoll 是Linux下多路复用IO接口 select/poll 的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率，因为它会复用文件描述符集用来传递结果而不用迫使开发者每次等待事件之前都必须重新准备要被侦听的文件描述符集合，另一点原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。 epoll除了提供 select/poll 那种IO事件的电平触发 （Level Triggered）外，还提供了边沿触发（Edge Triggered），这就使得用户空间程序有可能缓存IO状态，减少 epoll_wait/epoll_pwait 的调用，提高应用程序效率。 epoll函数 说明：epoll对IO接口进行多路复用，提高CPU的利用率 头文件：#include &lt;sys/epoll.h&gt; 函数1：int epoll_create1(int flags);(向内核注册并打开一个 epoll 描述符) 这个函数是在linux 2.6.27中加入的，它和 epoll_create 差不多，不同的是 epoll_create1 函数的参数是 flag，当 flag 是 0 时，表示和 epoll_create 函数完全一样，不需要 size 的提示了。 当 flag = EPOLL_CLOEXEC，创建的epfd会设置FD_CLOEXEC(一般使用这种) FD_CLOEXEC：它是 fd 的一个标识说明，用来设置文件 close-on-exec 状态的。当 close-on-exec 状态为 0 时，调用 exec 时，fd 不会被关闭；状态非零时则会被关闭，这样做可以防止 fd 泄露给执行 exec 后的进程。 当 flag = EPOLL_NONBLOCK，创建的 epfd 会设置为非阻塞 int epoll_create(int size); 创建一个 epoll 的句柄，size用来告诉内核这个监听的数目最大值。 当创建好 epoll 句柄后，它就是会占用一个 fd 值，所以在使用完 epoll 后，必须调用 close() 关闭，否则可能导致 fd 被耗尽。 注意：是数量的最大值，不是 fd 的最大值(通知内核需要监听 size 个fd)。 自从Linux2.6.8版本以后，size值其实是没什么用的，不过要大于0，因为内核可以动态的分配大小，所以不需要 size 这个提示了。 为什么使用 epoll_create1 函数而不用以前的 epoll_create 函数： epoll_create 的参数 size 是老版本的实现，使用的是 hash 表, size 应该是用来算 bucket 数目，后面因为使用红黑树，这个参数不再使用, 可以忽略。 返回值：成功返回一个非负的文件描述符，出错返回-1，并设置errno： EINVAL : 无效的标志 EMFILE : 用户打开的文件超过了限制 ENFILE : 系统打开的文件超过了限制 ENOMEM : 没有足够的内存完成当前操作 函数2：int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);(epoll 的事件注册函数) epfd参数：epoll_create1 函数返回的的 epoll 描述符 op参数：操作值(想要注册的动作) EPOLL_CTL_ADD： 注册目标fd到epfd中，同时关联内部event到fd上 EPOLL_CTL_MOD： 修改已经注册到fd的监听事件 EPOLL_CTL_DEL： 从epfd中删除/移除已注册的fd，event可以被忽略，也可以为NULL fd参数：需要监听的套接字描述符 event参数：设定监听事件的结构体 1234567891011typedef union epoll_data &#123; void *ptr; int fd; __uint32_t u32; __uint64_t u64;&#125; epoll_data_t;struct epoll_event &#123; __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */&#125;; data是一个联合体，能够存储fd或其它数据，我们需要根据自己的需求定制。events表示监控的事件的集合，是一个状态值，通过状态位来表示，可以设置如下事件： EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）； EPOLLOUT：表示对应的文件描述符可以写； EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断；(并不代表对端结束了连接,通常情况下 EPOLLHUP 表示的是本端挂断) EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，就会把这个fd从epoll的队列中删除。如果还需要继续监听这个socket的话，需要再次把这个fd加入到EPOLL队列里 返回值：成功返回0，失败返回-1，并设置errno： EBADF : epfd 或者 fd 不是一个有效的文件描述符 EEXIST : op 为 EPOLL_CTL_ADD，但 fd 已经被监控 EINVAL : epfd 是无效的 epoll 文件描述符 ENOENT : op 为 EPOLL_CTL_MOD 或者 EPOLL_CTL_DEL，并且 fd 未被监控 ENOMEM : 没有足够的内存完成当前操作 ENOSPC : epoll 实例超过了 /proc/sys/fs/epoll/max_user_watches 中限制的监听数量 函数3：int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); int epoll_pwait(int epfd, struct epoll_event *events, int maxevents, int timeout, const sigset_t *sigmask); epfd参数：epoll 的描述符( epoll_create1 函数的返回值) events参数：events 指针携带有 epoll_data_t 数据 maxevents参数：告诉内核 events 有多大，该值必须大于0，但是这个 maxevents 的值不能大于创建 epoll_create() 时的 size timeout参数(毫秒)：表示超时时间。0 表示不等待立即返回，-1 代表永久阻塞，大于 0 表示等待的最大时间 epoll_pwait(since linux 2.6.19)允许一个应用程序安全的等待，直到 fd 设备准备就绪，或者捕获到一个信号量。其中 sigmask 表示要捕获的信号量。 返回值：成功返回准备好事件要求的描述符的个数，返回0代表在超时时间内没有准备好的描述符；失败返回 -1 并设置 errno: EBADF：epfd 不是一个有效的描述符 EFAULT：events 指向的内存区域没有写的权限 EINTR：在事件发生任何请求或超时过期之前，调用被信号处理程序中断 EINVAL：epfd 不是一个 epoll 描述符，或者 maxevents 参数小于或等于 0 示例： 这里使用伪代码，具体实现的代码请移步 12345678910111213141516171819202122232425epfd = epoll_create1(EPOLL_CLOEXEC);event.events = EPOLLET | EPOLLIN;event.data.fd = serverfd;epoll_ctl(epfd, EPOLL_CTL_ADD, serverfd, &amp;event);// 主循环while(true) &#123; // 这里的timeout很重要，实际使用中灵活调整 count = epoll_wait(epfd, &amp;events, MAXEVENTS, timeout); for(i = 0; i &lt; count; ++i) &#123; if(events[i].events &amp; EPOLLERR || events[i].events &amp; EPOLLHUP) // 处理错误 if(events[i].data.fd == serverfd) // 为接入的连接注册事件 else if(events[i].events &amp; EPOLLIN) // 处理可读的缓冲区 read(events[i].data.fd, buf, len); event.events = EPOLLET | EPOLLOUT; event.data.fd = events[i].data.fd; epoll_ctl(epfd, EPOLL_CTL_MOD, events[i].data.fd, &amp;event); else // 处理可写的缓冲区 write(events[i].data.fd, buf, len); // 后续可以关闭fd或者MOD至EPOLLOUT &#125;&#125; 说明 为什么用epoll 支持监听大数目的socket描述符 一个进程内，select能打开的fd是有限制的，由宏FD_SETSIZE 设置，默认值是 1024.在某些时候，这个数值是远远不够用的。解决办法有两种，一是修改宏然后重新编译内核，但与此同时会引起网络效率的下降；二是使用多进程来解决，但是创建多个进程是有代价的，而且进程间数据同步没有多线程间方便。 epoll没有这个限制，它所支持的最大 fd 上限远远大于1024，在1GB内存的机器上是10万左右（具体数目可以cat/proc/sys/fs/file-max查看） 1234//我的是centos6.9，内存2GB[roux@Vkey mnt]$ cat /proc/sys/fs/file-max 187510[roux@Vkey mnt]$ 效率的提高 select 函数每次都当监听的套接组有事件产生时就会返回，但却不能将有事件产生的套接字筛选出来，而是改变其在套接组的标志量，所以每次监听到事件，都需要将套接组整个遍历一遍。时间复杂度是O(n)。当fd数目增加时，效率会线性下降。 epoll 函数每次会将监听套结字中产生事件的套接字加到一列表中，然后我们可以直接对此列表进行操作，而没有产生事件的套接字会被过滤掉，极大的提高了IO效率。这一点尤其在套接字监听数量巨大而活跃数量很少的时候很明显。 内存处理 不管是哪种I/O机制，都无法避免fd在操作过程中拷贝的问题，而 epoll 使用了 mmap (是指文件/对象的内存映射，被映射到多个内存页上)，所以同一块内存(共享内存)就可以避免这个问题(详细看前面的零拷贝技术及 mmap)。 epoll的工作方式 epoll有两种触发模式，LT(Level-Triggered，水平触发)，ET(Edge–Triggered边缘触发)。其中LT编程模型和poll是一样的。 LT(level triggered) 是默认/缺省的工作方式，同时支持 block 和 no_block socket。这种工作方式下，内核会通知你一个 fd 是否就绪，然后才可以对这个就绪的 fd 进行I/O操作。就算你没有任何操作，系统还是会继续提示 fd 已经就绪，不过这种工作方式出错会比较小，传统的 select/poll 就是这种工作方式的代表。(水平触发，只要有数据可以读，不管怎样都会通知) ET(edge-triggered) 是高速工作方式 ，仅支持 no_block socket(非阻塞)，这种工作方式下，当 fd 从未就绪变为就绪时，内核会通知 fd 已经就绪，并且内核认为你知道该 fd 已经就绪，不会再次通知了，除非因为某些操作导致fd就绪状态发生变化。如果一直不对这个 fd 进行I/O操作，导致 fd 变为未就绪时，内核同样不会发送更多的通知，因为 only once。所以这种方式下，出错率比较高，需要增加一些检测程序。(边缘触发，只有状态发生变化时才会通知，可以理解为电平变化) 举例： LT 水平触发 儿子：“妈妈，我收到了5000元压岁钱。” 妈妈：“恩，省着点花！” 儿子：“妈妈，我今天买了个ipad，花了3000元。” 妈妈：“噢，这东西真贵。” 儿子：“妈妈，我今天买好多吃的，还剩1000元。” 妈妈：“用完了这些钱，我可不会再给你了。” 儿子：“妈妈，那1000元我没花，零花钱够用了。” 妈妈：“恩，这才是明智的做法！” 儿子：“妈妈，那1000元我没花，我要攒起来。” 妈妈：“恩，加油！” 是不是没完没了？只要儿子手中还有钱，他就会一直汇报，这就是LT模式。有钱就是1，没钱就是0，那么只要儿子还有钱，这种事件就是1-&gt;1类型事件，自然是LT。 ET 边缘触发 儿子：“妈妈，我收到了5000元压岁钱。” 妈妈：“恩，省着点花！” 儿子：“……” 妈妈：“你倒是说话啊？压岁钱呢？！” 这个就是ET模式，简洁得有点过头，但很高效！虽然妈妈可能并不这么认为。。。儿子从没钱到有钱，是一个0-&gt;1的过程，因此为ET。儿子和妈妈说过自己拿到了压岁钱就完事了，至于怎么花钱，还剩多少钱，一概不说。 LT 模式和 ET 模式的区别是 ET 模式是高电平到低电平切换的时候或者低电平切换高电平才会触发。 EPOLLIN事件: 内核的输入缓冲区 为空 低电平 内核的输入缓冲区 不为空 高电平（一直触发EPOLLIN） EPOLLOUT事件: 内核发送缓冲区不满 高电平(一直触发EPOLLOUT) 内核发送缓冲区满 低电平 关于 LT 及 ET 的详细知识请点击此处 什么时候关注EPOLLOUT事件呢？(如果在得到一个套接字马上关注，就会出现busy loop的状态) LT 模式：在write的时候关注EPOLLOUT事件，如果数据没有写完，我们就需要把未发送完的数据添加到应用层缓冲区，然后关注这个连接套接字的EPOLLOUT事件，等到EPOLLOUT事件到来，取出应用层缓冲区的数据发送，如果应用层缓冲区数据发送完成，取消关注EPOLLOUT事件。 ET 模式：ET表示边缘触发，是电平从低到高或者从高到低才会触发。我们一开始就可以关注EPOLLIN事件和EPOLLOUT事件，不会出现busy loop。所以当接收缓冲区处于高电平状态时，一定要一次性把数据全部读完。因为如果一次没有读完，接收缓冲区仍然处于高电平状态，下次不会在触发EPOLLIN事件。同理，发送缓冲区的处理类似。 注意 epoll 和 select/poll 本质上是一样的，性能上提升较大，都属于I/O多路复用模型（I/O Multiplexing Model），和阻塞，非阻塞两大I/O模型是并列的。只是对于事件处理函数角度而言，看起来是异步的（实际上是同步的回调而已）。和 epoll 组合使用大多数是非堵塞I/O方式，这时候就是同步非堵塞，也可以有堵塞I/O的情况。比如多线程server可以在 accept 上采用堵塞I/O，accept后的 socket 用 epoll 管理非堵塞的读写事件。 使用 epoll 一定要加 定时器，否则后患无穷 联合体 data 中的那个 ptr 是很有用的，只不过这就意味着你将该对象的生命周期交给了 epoll，不排除会有潜在bug的影响，需要辅以timeout 多线程环境下使用epoll，多考虑 EPOLLONESHOT EPOLLLT 也是一个不错的选择，除非你的框架能够确保每次事件触发后，都读/写至 EAGAIN 使用前请仔细阅读 man 7 epoll 总结 epoll 实现机制(简单介绍) epoll在被内核初始化时（操作系统启动），同时会开辟出epoll自己的内核高速cache区，用于安置每一个我们想监控的socket。这些socket会以红黑树的形式保存在内核cache里，以支持快速的查找、插入、删除。 这个内核高速cache区，就是建立连续的物理内存页，然后在之上建立 slab 层。简单的说，就是物理上分配好你想要的size的内存对象，每次使用时都是使用空闲的已分配好的对象。 epoll的高效就在于，当我们调用 epoll_ ctl 往里塞入百万个句柄时，epoll_ wait 仍然可以飞快的返回，并有效的将发生事件的句柄给我们用户。 这是由于我们在调用 epoll_ create 时，内核除了帮我们在epoll文件系统里建了个file结点，在内核cache里建了个红黑树用于存储以后 epoll_ ctl 传来的socket外，还会再建立一个list链表，用于存储准备就绪的事件. 当 epoll_ wait 调用时，仅仅观察这个list链表里有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait 非常高效。 而且，通常情况下即使我们要监控百万计的句柄，大多一次也只返回很少量的准备就绪句柄而已，所以，epoll_wait 仅需要从内核态copy少量的句柄到用户态而已。 那么，这个准备就绪list链表是怎么维护的呢？ 当我们执行 epoll_ctl 时，除了把socket放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。 所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了。如此，一颗红黑树，一张准备就绪句柄链表，少量的内核cache，就帮我们解决了大并发下的socket处理问题。 执行 epoll_ create 时，创建了红黑树和就绪链表，执行 epoll_ ctl 时，如果增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据。执行 epoll_wait 时立刻返回准备就绪链表里的数据即可。 三种IO复用函数的分析 参考 链接： http://blog.csdn.net/lixungogogo/article/details/52226479 https://www.cppfans.org/1418.html https://www.yuanmas.com/info/mZzgRrExOK.html http://blog.lucode.net/linux/epoll-tutorial.html http://www.liudesheng.com/2016/12/13/%E5%A4%A7%E5%B9%B6%E5%8F%91%E6%9C%8D%E5%8A%A1%E5%99%A8/%E5%9B%9B%E3%80%81epoll%E5%87%BD%E6%95%B0/ https://www.cppfans.org/1417.html http://blog.csdn.net/xiajun07061225/article/details/9250579","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"I/O复用","slug":"I-O复用","permalink":"http://roux.top/tags/I-O复用/"}]},{"title":"nil/Nil/NULL/NUL/nullptr/NSNull","slug":"NULL","date":"2017-11-18T16:00:00.000Z","updated":"2018-10-22T06:06:23.956Z","comments":true,"path":"2017/11/19/NULL/","link":"","permalink":"http://roux.top/2017/11/19/NULL/","excerpt":"nil/Nil/NULL/NUL/nullptr/NSNull 如何表示“不存在” 要理解不存在这个概念，首先需要理解存在。如何定义“存在”这个概念是一个哲学问题，海德格尔在《存在与时间》中提及了存在的不可定义性。原文如下： 『存在』这个概念是不可定义的。这是从它的最高普遍性推论出来的。这话有道理——既然定义来自最近的种加属差。确实不能把『存在』理解为存在者，令存在者归属于存在并不能使『存在』得到规定。 对于哲学来说，表示存在或者不存在这个概念是比较困难的问题。对于数学和计算机科学来说，表示不存在要简单的多，就是用存在的概念表示不存在概念。","text":"nil/Nil/NULL/NUL/nullptr/NSNull 如何表示“不存在” 要理解不存在这个概念，首先需要理解存在。如何定义“存在”这个概念是一个哲学问题，海德格尔在《存在与时间》中提及了存在的不可定义性。原文如下： 『存在』这个概念是不可定义的。这是从它的最高普遍性推论出来的。这话有道理——既然定义来自最近的种加属差。确实不能把『存在』理解为存在者，令存在者归属于存在并不能使『存在』得到规定。 对于哲学来说，表示存在或者不存在这个概念是比较困难的问题。对于数学和计算机科学来说，表示不存在要简单的多，就是用存在的概念表示不存在概念。 NULL NULL一般是这么定义的： 12345#ifdef __cplusplus#define NULL 0#else#define NULL ((void *)0)#endif 可以看出在C和C++中 NULL 的定义不同。在C语言中，不需要考虑函数重载等问题，所以直接简单定义为一个 0 地址的 void* 就行了。由于C++引入了更严格的类型检查，所以把直接 void* 类型的值赋给一个有类型指针是不行的，编译器会报错(eg:malloc)。但同时C++要保持和C的兼容性，所以在C++里，NUL L直接定义为整型 0。 nullptr 将 NULL 直接定义成 0 一般是没问题的，但是假如遇到函数重载： 12int foo(int a,void *ptr);int foo(int a,int b); 如果这样调用 foo(1,NULL) 就会有歧义，因为 NULL 是指针类型，但是同时 NULL 也是整型。同样的，这样的问题在模版类型推导的时候也会出现： 12template&lt;class T&gt;int foo(T a); 如果调用 foo(NULL) 是应该推导出 int foo(int a) 呢还是 int foo(void *a) 呢。为了解决这个问题。C++11引入了一个新的概念： nullptr。nullptr 的实现如下： 1234567891011121314constclass nullptr_t&#123;public:template&lt;class T&gt;inline operator T*() const &#123; return 0; &#125;template&lt;class C, class T&gt;inline operator T C::*() const &#123; return 0; &#125;private: void operator&amp;() const;&#125; nullptr = &#123;&#125;; 其实 nullptr 和 swift 中的 Optional 的实现非常像了。看了nullptr 的实现，可以自己写一个 Optional 的实现。 nil nil 和 NULL 语义不同，但是在底层实现上是等价的。需要注意的是，ni l可以向对象发送消息，如果消息有返回值，会有以下几种情况： 如果一个方法返回值是一个对象，那么发送给 nil 的消息将返回0(nil)。 如果方法返回值为指针类型，其指针大小为小于或者等于sizeof(void*)，float，double，long double 或者 long long 的整型标量，发送给nil的消息将返回0。 如果方法返回值为结构体，发送给nil的消息将返回0。结构体中各个字段的值将都是0。其他的结构体数据类型将不是用0填充的。 如果方法的返回值不是上述提到的几种情况，那么发送给 nil 的消息的返回值将是未定义的。 Nil Nil是OC类类型的书面空值，对应Class类型对象。底层实现和 nil 是一样的。Nil的定义如下： 123456789101112131415#ifndef Nil# if __has_feature(cxx_nullptr)# define Nil nullptr# else# define Nil __DARWIN_NULL# endif#endif#ifndef nil# if __has_feature(cxx_nullptr)# define nil nullptr# else# define nil __DARWIN_NULL# endif#endif NSNull 在OC的集合中中nil代表集合的结束，所以不能在集合里存储nil。所以就有了NSNull用一个类来表示空值。一般用来表示集合中的空对象。 NUL 用来表示字符串的结束。注意：标准C中无定义。 出处 转载：http://www.liudesheng.com/2016/02/12/nil0Nil0NULL0null0nullptr0NSNull/","categories":[{"name":"C","slug":"C","permalink":"http://roux.top/categories/C/"}],"tags":[{"name":"Others","slug":"Others","permalink":"http://roux.top/tags/Others/"}]},{"title":"select函数","slug":"select函数","date":"2017-11-17T16:00:00.000Z","updated":"2018-04-22T05:49:24.010Z","comments":true,"path":"2017/11/18/select函数/","link":"","permalink":"http://roux.top/2017/11/18/select函数/","excerpt":"select函数 说明： select()用来等待文件描述词状态的改变 头文件： #include &lt;sys/time.h&gt; #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; 原型： int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);","text":"select函数 说明： select()用来等待文件描述词状态的改变 头文件： #include &lt;sys/time.h&gt; #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; 原型： int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); nfds参数： 参数nfds 代表集合中所有文件描述符的范围，即所有文件描述符的最大值加1(一般系统最大的为1024，可以使用 ulimit 查看) readfds参数： 指向fd_set结构的指针，这个集合中应该包括文件描述符，我们是要监视这些文件描述符的读变化的，即我们关心是否可以从这些文件中读取数据了，如果这个集合中有一个文件可读，select就会返回一个大于0的值，表示有文件可读，如果没有可读的文件，则根据timeout参数再判断是否超时，若超出timeout的时间，select返回0，若发生错误返回负值。可以传入NULL值，表示不关心任何文件的读变化。 writefds参数：指向 fd_set 结构的指针，这个集合中应该包括文件描述符，我们是要监视这些文件描述符的写变化的，即我们关心是否可以向这些文件中写入数据了，如果这个集合中有一个文件可写，select就会返回一个大于0的值，表示有文件可写，如果没有可写的文件，则根据timeout再判断是否超时，若超出 timeout 的时间，select返回0，若发生错误返回负值。可以传入NULL值，表示不关心任何文件的写变化。 struct fd_set结构体：可以理解为一个集合，这个集合中存放的是文件描述符(file descriptor)，即文件句柄，这可以是我们所说的普通意义的文件，当然Unix下任何设备、管道、FIFO等都是文件形式，全部包括在内，所以，毫无疑问，一个socket就是一个文件，socket句柄就是一个文件描述符。fd_set集合可以通过一些宏由人为来操作: 12345678/* 清除描述词组set 中相关fd 的位 */void FD_CLR(int fd, fd_set *set);/* 测试描述词组set 中相关fd 的位是否为真 */int FD_ISSET(int fd, fd_set *set);/* 设置描述词组set 中相关fd 的位 */void FD_SET(int fd, fd_set *set);/* 清除描述词组set 的全部位 */void FD_ZERO(fd_set *set); fd_set集合通常是一个整数数组，其中每个整数中的每一位对应一个描述符，如： 12345678910111213141516171819fd_set set; //定义一个描述符集合//初始化描述符集，如果不初始化，则作为自动变量分配的描述符集将发生不可预期的后果FD_ZERO(&amp;set); //则set用位表示是0000,0000。FD_SET(fd, &amp;set); //若fd＝5,则set变为0001,0000(第5位置为1)//若再加入fd＝2，fd=1,则set变为0001,0011FD_SET(2, &amp;set);FD_SET(1, &amp;set);//maxfd为指定的待测试最大描述符个数(增大效率，减轻额外负担)int nready = select(maxfd+1, &amp;set, 0, 0, 0) //阻塞等待//若fd=1, fd=2上都发生可读事件，则select返回，此时set变为0000,0011。FD_ISSET(fd, &amp;set) //对需要关心的描述符进行测试，是否有所关心的事情发生//没有事件发生的fd=5需要被清空。FD_CLR(fd, &amp;set); errorfds参数：同上面两个参数的意图，用来监视文件错误异常。 timeout参数：select的超时时间，这个参数至关重要，它可以使select处于三种状态 struct timeval结构体 12345struct timeval&#123; long tv_sec; /* 秒 */ long tv_usec; /* 微秒 */&#125; 若将NULL以形参传入，即不传入时间结构，就是将select置于阻塞状态，一定等到监视文件描述符集合中某个文件描述符发生变化为止； 若将时间值设为0秒0毫秒，就变成一个纯粹的非阻塞函数，不管文件描述符是否有变化，都立刻返回继续执行，文件无变化返回0，有变化返回一个正值； timeout的值大于0，这就是等待的超时时间，即select在timeout时间内阻塞，超时时间之内有事件到来就返回了，否则在超时后不管怎样一定返回，返回值同上述。 返回值： 传递给 select 函数的参数会告诉内核： 我们所关心的文件描述符 对每个描述符，我们所关心的状态。(我们是要想从一个文件描述符中读或者写，还是关注一个描述符中是否出现异常) 我们要等待多长时间。(我们可以等待无限长的时间，等待固定的一段时间，或者根本就不等待) 从 select 函数返回后，内核告诉我们一下信息： 对我们的要求已经做好准备的描述符的个数 对于三种条件哪些描述符已经做好准备.(读，写，异常) 错误代码：执行成功则返回文件描述词状态已改变的个数, 如果返回0 代表在描述词状态改变前已超过timeout 时间, 当有错误发生时则返回-1, 错误原因存于errno, 此时参数readfds, writefds, exceptfds 和timeout的值变成不可预测 EBADF： 文件描述词为无效的或该文件已关闭 EINTR： 此调用被信号所中断 EINVAL： 参数nfds 为负值. ENOMEM： 核心内存不足 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149//服务器#include&lt;stdio.h&gt;#include&lt;sys/select.h&gt;#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;netinet/in.h&gt;#include&lt;string.h&gt;#include&lt;stdlib.h&gt;#define _FD_NUM_ 32#define _BACK_LOG_ 5int arr_fd[_FD_NUM_];int start_up()&#123; int sock = socket(AF_INET,SOCK_STREAM,0); if(sock == -1) &#123; perror(\"sock\"); exit(1); &#125; struct sockaddr_in local; local.sin_family = AF_INET; local.sin_port = htons(8888); inet_aton(\"127.0.0.1\",&amp;local.sin_addr); if(bind(sock,(struct sockaddr*)&amp;local,sizeof(local)) == -1) &#123; perror(\"bind\"); exit(1); &#125; if(listen(sock,_BACK_LOG_) == -1) &#123; perror(\"listen\"); exit(1); &#125; return sock;&#125;int main()&#123; int sock = start_up(); printf(\"server socket is: %d\\n\",sock); struct sockaddr_in client; socklen_t client_len = sizeof(client); fd_set read_set; int max_fd = sock; //array init memset(arr_fd,-1,_FD_NUM_); arr_fd[0] = sock; int i = 0, j = 0; while(1) &#123; FD_ZERO(&amp;read_set);//clear //set read_set &amp;&amp; find max_fd for(i = 0;i &lt; _FD_NUM_;i++) &#123; if(arr_fd[i] &gt; 0) &#123; FD_SET(arr_fd[i],&amp;read_set); &#125; if(arr_fd[i] &gt; max_fd) &#123; max_fd = arr_fd[i]; &#125; &#125; printf(\"max_fd: %d\\n\",max_fd); //struct timeval timeout = &#123;5,0&#125;; //BLOCK wait switch(select(max_fd + 1,&amp;read_set,NULL,NULL,NULL)) &#123; case 0://timeout printf(\"server timeout\\n\"); break; case -1://error perror(\"select\"); break; default: &#123; for(i = 0;i &lt; _FD_NUM_;i++) &#123; printf(\"arr_fd : %d\\n\",arr_fd[i]); if(arr_fd[i] &lt; 0) continue; //accept client's connect else if(arr_fd[i] == sock &amp;&amp; FD_ISSET(arr_fd[i],&amp;read_set)) &#123; int new_sock = accept(arr_fd[i],(struct sockaddr*)&amp;client,&amp;client_len); //connect failed if(new_sock &lt; 0) &#123; perror(\"accept\"); &#125; printf(\"Get a connect...\\n\"); //insert new_fd for(j = 0;j &lt; _FD_NUM_;j++) &#123; if(arr_fd[j] == -1) &#123; arr_fd[j] = new_sock; break; &#125; printf(\"Insert new_sock is : %d\\n\",new_sock); &#125; if(j == _FD_NUM_) &#123; printf(\"socket array is full\\n\"); close(new_sock); &#125; &#125; //other socket else &#123; for(i = 1;i &lt; _FD_NUM_;i++) &#123; if(arr_fd[i] &gt; 0 &amp;&amp; FD_ISSET(arr_fd[i],&amp;read_set)) &#123; char buf[1024]; memset(buf,'\\0',sizeof(buf)); ssize_t size = read(arr_fd[i],buf,sizeof(buf) - 1); if(size == 0) &#123; printf(\"clien release\\n\"); close(arr_fd[i]); arr_fd[i] = -1; &#125; else if(size &gt; 0) &#123; buf[size] = '\\0'; printf(\"client: %s\",buf); &#125; &#125; &#125; &#125; &#125; &#125; break; &#125; &#125; close(sock); return 0;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788//客户端#include&lt;stdio.h&gt;#include&lt;sys/select.h&gt;#include&lt;sys/socket.h&gt;#include&lt;sys/types.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;string.h&gt;#include&lt;netinet/in.h&gt;int main()&#123; int read_fd = 0; int write_fd = 1; int max_fd = 0; fd_set read_set; fd_set write_set; printf(\"sizeof fd_set: %d\\n\",sizeof(fd_set)); int sock = socket(AF_INET,SOCK_STREAM,0); if(sock == -1) &#123; perror(\"socket\"); return -1; &#125; printf(\"client's sock is : %d\\n\",sock); struct sockaddr_in remote; remote.sin_family = AF_INET; remote.sin_port = htons(8888); remote.sin_addr.s_addr = inet_addr(\"127.0.0.1\"); if(connect(sock,(struct sockaddr*)&amp;remote,sizeof(remote)) &lt; 0) &#123; perror(\"connect\"); return -1; &#125; max_fd = sock &gt; read_fd ? sock : read_fd; while(1) &#123; FD_ZERO(&amp;read_set); FD_ZERO(&amp;write_set); FD_SET(read_fd,&amp;read_set); FD_SET(sock,&amp;write_set); struct timeval timeout = &#123;2,0&#125;; switch(select(max_fd + 1,&amp;read_set,&amp;write_set,NULL,&amp;timeout)) &#123; case 0://timeout printf(\"select timeout\\n\"); break; case -1://error perror(\"select\"); break; default://correct &#123; // int FD_ISSET(int fd, fd_set *set); if(FD_ISSET(read_fd,&amp;read_set)) &#123; char buf[1024]; memset(buf,'\\0',sizeof(buf)); ssize_t size = read(read_fd,buf,sizeof(buf) - 1); if(size &lt; 0) &#123; perror(\"read\"); break; &#125; buf[size] = '\\0'; if(FD_ISSET(sock,&amp;write_set)) &#123; ssize_t write_size = write(sock,buf,strlen(buf)); if(write_size &lt; 0) &#123; perror(\"write\"); break; &#125; &#125; &#125; &#125; break; &#125; &#125; close(sock); return 0;&#125; 解释及注意事项 解释： 可读事件： 有数据可读 关闭连接的读的一半(接收了FIN的TCP连接，读操作不阻塞并返回0) 给监听套接口准备好新的连接 待处理错误(不阻塞并返回-1) 可写事件： 有可用与写的空间 关闭连接的写的一半 待处理错误(不阻塞并返回-1) 异常：TCP带外数据 注意： select的最大描述符数(FD_SETSIZE)：增大的方法是增大FD_SETSIZE，然后重新编译内核 混合使用stdio和select非常容易出错误，所以尽量避免与小心(缓冲区的问题：stdio有缓冲区，select使用时不知道) 因为每次select执行完了后都会对描述符集进行清空，所以需要每次调用前进行重新设置 连接数为0的情形下需要做特殊处理，因为如果读集合中没有任何套接字，select函数会立刻返回，这将导致工作者线程成为一个死循环，占用并浪费CPU。 总结 一张图来说明select函数的工作流程 select函数采用了轮询的机制来处理事件。关联到套接字列表的操作都需要使用循环，在轮询的时候需要遍历一次，再新的一轮开始时，将列表加入队列又需要遍历一次。也就是说，Select在工作一次时，需要至少遍历2次列表，导致效率低下。 参考 http://www.cnblogs.com/jinmu190/archive/2010/11/21/1883184.html http://blog.csdn.net/bzhxuexi/article/details/44833537 http://blog.csdn.net/piaojun_pj/article/details/5991968 http://c.biancheng.net/cpp/html/381.html","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"I/O复用","slug":"I-O复用","permalink":"http://roux.top/tags/I-O复用/"}]},{"title":"dirname函数与basename函数","slug":"basename函数与dirname函数","date":"2017-11-17T16:00:00.000Z","updated":"2018-04-22T05:57:54.575Z","comments":true,"path":"2017/11/18/basename函数与dirname函数/","link":"","permalink":"http://roux.top/2017/11/18/basename函数与dirname函数/","excerpt":"dirname函数 说明：截取给定路径的目录部分(以 ‘/‘ 为分隔符) 头文件：#include &lt;libgen.h&gt; 原型：char *dirname(char *path); path参数：指向一个文件的全路径的字符串 此函数可以修改路径的内容，所以传递参数时需要传递一个副本","text":"dirname函数 说明：截取给定路径的目录部分(以 ‘/‘ 为分隔符) 头文件：#include &lt;libgen.h&gt; 原型：char *dirname(char *path); path参数：指向一个文件的全路径的字符串 此函数可以修改路径的内容，所以传递参数时需要传递一个副本 返回值：去掉文件名后的目录名(可以理解为返回值为路径的上一层目录地址名) 如果路径只是一个文件名(路径名)，则返回值为当前目录。 如果路径为根目录，则返回值为根目录。 如果路径为空，则返回值为当前目录。 示例： 12345678910111213141516171819#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;libgen.h&gt;#include &lt;string.h&gt;int main ( int argc, char *argv[] )&#123; char *str = \"/mnt/linux/test.txt\"; char buf[1024] = &#123;0&#125;; strncpy (buf, str, strlen(str)); //dirname 会修改buf中的值，所以需要一个缓冲区 //直接调用dirname(str), 会使程序崩溃 printf (\"dirstr is:%s\\n\", dirname(buf)); printf (\"dir buf is:%s\\n\", buf); return 0;&#125; basename函数 说明：得到特定的路径中的最后一个 ‘/‘ 后面的内容(以 ‘/‘ 为分隔符) 头文件：#include &lt;libgen.h&gt; 原型：char *basename(char *path); path参数：指向一个文件的全路径的字符串 此函数可以修改路径的内容，所以传递参数时需要传递一个副本 返回值：基本的文件名(可以理解为返回值为路径的最后的文件名) 如果路径只是一个文件名(路径名)，则返回值为路径的副本(即文件名)。 如果路径为根目录，则返回值为根目录。 如果路径为空，则返回值为当前目录。 如果路径为 /mnt/linux/lib/ 后面没有文件名，则会报段错误 示例： 123456789101112131415161718#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;libgen.h&gt;#include &lt;string.h&gt;int main ( int argc, char *argv[] )&#123; char *str = \"/mnt/linux/test.txt\"; char buf[1024] = &#123;0&#125;; strncpy (buf, str, strlen(str)); //dirname 会修改buf中的值，所以需要一个缓冲区 printf (\"test1 basename is:%s\\n\", basename(buf)); printf (\"name buf is:%s\\n\", buf); return 0;&#125; 补充 利用 strrchr 获取文件扩展名称(后缀) 1234567891011#include &lt;stdio.h&gt;#include &lt;string.h&gt;int main ( int argc, char *argv[] )&#123; char *str = \"/mnt/linux/test.txt\"; char *suffix = strrchr (str, '.'); printf (\"suffix is:%s\\n\", suffix); return 0;&#125; 总结 解释 1234567path dirname basename\"/usr/lib\" \"/usr\" \"lib\"\"/usr/\" \"/\" \"usr\"\"usr\" \".\" \"usr\"\"/\" \"/\" \"/\"\".\" \".\" \".\"\"..\" \".\" \"..\" 注意 在某些平台上关于这两个函数的实现，在传递参数的时候传递的是只读字符串，所以无法修改，因此在传递的时候需要传递数组或者改用GNU的实现版本 思考：http://www.cnblogs.com/clover-toeic/p/3741689.html","categories":[{"name":"C","slug":"C","permalink":"http://roux.top/categories/C/"}],"tags":[{"name":"Function","slug":"Function","permalink":"http://roux.top/tags/Function/"}]},{"title":"sysconf函数与getrlimit函数及setrlimit函数","slug":"sysconf函数","date":"2017-11-16T16:00:00.000Z","updated":"2018-04-22T05:54:06.195Z","comments":true,"path":"2017/11/17/sysconf函数/","link":"","permalink":"http://roux.top/2017/11/17/sysconf函数/","excerpt":"前言 每种资源都有相关的软硬限制，软限制是内核强加给相应资源的限制值，硬限制是软限制的最大值。非授权调用进程只可以将其软限制指定为0到硬限制范围中的某个值，同时能不可逆转地降低其硬限制。授权进程可以任意改变其软硬限制。RLIM_INFINITY的值表示不对资源限制。","text":"前言 每种资源都有相关的软硬限制，软限制是内核强加给相应资源的限制值，硬限制是软限制的最大值。非授权调用进程只可以将其软限制指定为0到硬限制范围中的某个值，同时能不可逆转地降低其硬限制。授权进程可以任意改变其软硬限制。RLIM_INFINITY的值表示不对资源限制。 sysconf函数 说明：sysconf函数用于找到一个特定系统实际支持的限制值 头文件：#include &lt;unistd.h&gt; 原型： long sysconf(int name); name参数：代表限制名常量，是一些整数，分别代表一个限制名 限制名 name参数 linux测试值 说明 ARG_MAX _SC_ARG_MAX exec函数的参数最大长度（字节数） ATEXIT_MAX _SC_ATEXIT_MAX 可用atexit函数登记的最大函数个数。 CHILD_MAX _SC_CHILD_MAX 1024 每个实际用户ID的最大进程数。 HOST_NAME_MAX _SC_HOST_NAME_MAX 主机名最大程度（字节数） LINE_MAX _SC_LINE_MAX 实用程序输入行的最大长度（字节数） LOGIN_NAME_MAX _SC_LOGIN_NAME_MAX 登录名的最大长度（字节数） OPEN_MAX _SC_OPEN_MAX 1024 每个进程的最大打开文件数 PAGESIZE _SC_PAGESIZE 系统存储页的长度（字节数） 返回值：特定系统实际支持的限制值 如果 name 不是一个合适的常量，则函数会返回-1，并将 errno 设置为EINVAL 示例： 1234567891011121314151617//获取电脑系统的部分参数#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main(void)&#123; printf(\"Size of a page in bytes:%ld\\n\",sysconf(_SC_PAGESIZE)); printf(\"Max length of a hostname:%ld\\n\",sysconf(_SC_HOST_NAME_MAX)); printf(\" The maximum number of files that a process can have open at any time.:%ld\\n\",sysconf(_SC_OPEN_MAX)); printf(\" The number of clock ticks per second.:%ld\\n\",sysconf(_SC_CLK_TCK)); printf(\"The number of processors currently online .:%ld\\n\",sysconf(_SC_NPROCESSORS_ONLN)); printf(\"The number of processors configured..:%ld\\n\",sysconf(_SC_NPROCESSORS_CONF)); return 0;&#125; getrlimit函数及setrlimit函数 说明：获得、设置每个进程能够创建的各种系统资源的限制使用量 原型：int getrlimit(int resource, struct rlimit *rlim); int setrlimit(int resource, const struct rlimit *rlim); rlim：描述资源软硬限制的结构体 1234struct rlimit &#123; rlim_t rlim_cur; /*软限制(内核所能支持的资源上限)*/ rlim_t rlim_max; /*硬限制(在资源中只是作为soft limit的上限)*/&#125;; resource参数： 参数 说明 RLIMIT_AS 进程的最大虚内存空间，字节为单位。 RLIMIT_CORE 内核转存文件的最大长度。 RLIMIT_CPU 最大允许的CPU使用时间，秒为单位。当进程达到软限制，内核将给其发送SIGXCPU信号，这一信号的默认行为是终止进程的执行。然而，可以捕捉信号，处理句柄可将控制返回给主程序。如果进程继续耗费CPU时间，核心会以每秒一次的频率给其发送SIGXCPU信号，直到达到硬限制，那时将给进程发送 SIGKILL信号终止其执行。 RLIMIT_DATA 进程数据段的最大值。 RLIMIT_FSIZE 进程可建立的文件的最大长度。如果进程试图超出这一限制时，核心会给其发送SIGXFSZ信号，默认情况下将终止进程的执行。 RLIMIT_LOCKS 进程可建立的锁和租赁的最大值。 RLIMIT_MEMLOCK 进程可锁定在内存中的最大数据量，字节为单位。 RLIMIT_MSGQUEUE 进程可为POSIX消息队列分配的最大字节数。 RLIMIT_NICE 进程可通过setpriority() 或 nice()调用设置的最大完美值。 RLIMIT_NOFILE 指定比进程可打开的最大文件描述词大一的值，超出此值，将会产生EMFILE错误。 RLIMIT_NPROC 用户可拥有的最大进程数。 RLIMIT_RTPRIO 进程可通过sched_setscheduler 和 sched_setparam设置的最大实时优先级。 RLIMIT_SIGPENDING 用户可拥有的最大挂起信号数。 RLIMIT_STACK 最大的进程堆栈，以字节为单位。 返回值：成功执行时，返回0。失败返回-1，errno被设为以下的某个值 EFAULT：rlim指针指向的空间不可访问 EINVAL：参数无效 EPERM：增加资源限制值时，权能不允许 示例： 1234567891011121314151617181920212223//运行该程序可能需要高权限，并且更改后仅对当前进程及其子进程有效#include &lt;stdio.h&gt;#include &lt;sys/resource.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#define handle_error(msg) \\ do&#123;perror(msg);exit(EXIT_FAILURE);&#125;while(0)int main()&#123; struct rlimit limit; if(getrlimit(RLIMIT_NOFILE,&amp;limit) == -1) handle_error(\"getrlimit\"); printf(\"getrlimit = %d\\n\",(int)limit.rlim_cur); limit.rlim_cur = limit.rlim_cur * 2; if(setrlimit(RLIMIT_NOFILE,&amp;limit) == -1) handle_error(\"getrlimit\"); printf(\"setrlimit = %d\\n\",(int)limit.rlim_cur); return 0;&#125; 总结 详解参考：http://www.cnblogs.com/niocai/archive/2012/04/01/2428128.html","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"Others","slug":"Others","permalink":"http://roux.top/tags/Others/"}]},{"title":"poll函数","slug":"poll函数","date":"2017-11-16T16:00:00.000Z","updated":"2018-04-22T05:49:50.575Z","comments":true,"path":"2017/11/17/poll函数/","link":"","permalink":"http://roux.top/2017/11/17/poll函数/","excerpt":"poll函数 说明：等待一个文件上的某些事件(与select功能类似) 头文件：#include &lt;poll.h&gt; 原型：int poll(struct pollfd *fds, nfds_t nfds, int timeout);","text":"poll函数 说明：等待一个文件上的某些事件(与select功能类似) 头文件：#include &lt;poll.h&gt; 原型：int poll(struct pollfd *fds, nfds_t nfds, int timeout); fds指针 12345struct pollfd &#123; int fd; /* file descriptor */ short events; /* requested events */ short revents; /* returned events */ &#125;; pollfd结构体成员的fd设置为需要关注的描述符，当fd被赋值为-1（负数）时，表示忽略 events，revents事件也将被设置成0。 poll与select不同（select函数在调用之后，会清空检测描述符的数组），每当调用这个函数之后，系统不会清空这个数组，而是将有状态变化的描述符结构的revents变量状态变化，操作起来比较方便。 events是需要设置进去对fd的关注事件（关注可读、可写、异常），属于掩码（可以或），比如设置成POLLIN | POLLOUT，关注可读可写。 revents是由内核通知的，函数返回的时候，会设置对应的fd实际发生的事件，比如fd有可读的事件，设置POLLIN(下面的表格鉴于渲染的时候会发生错误，故不用) 1234567891011121314151617181920212223常量 | 说明 | 是否可以作为输入 | 是否可以作为输出----- | ----- | ----------------- | ------------ |POLLIN | 普通或优先级带数据可读 | 是 | 是 POLLRDNORM | 普通数据可读（等价POLLIN与POLLRDBAND的逻辑或，与linux版本有关） | 是 | 是 POLLRDBAND | 优先级带数据可读（linux中一般不用） | 是 | 是 POLLPRI | 高优先级数据可读 | 是 | 是 POLLOUT | 普通数据可写 | 是 | 是 POLLWRNORM | 普通数据可写（等价POLLOUT，与linux版本有关）| 是 | 是 POLLWRBAND | 优先级数据可写 | 是 | 是 POLLRDHUP | Linux2.6.17以上才支持，需要声明_GNU_SOURCE，tcp被被对方关闭连接，对方关闭了写操作 | 是 | 是 POLLERR | 发生错误 | 否 | 是 POLLHUP | 发生挂起 | 否 | 是 POLLNVAL | 描述符不是一个打开的文件 | 否 | 是 - 表格中的最后三个是不能作为events事件注册进去的，只能放到revents结果中 - nfds参数：描述符个数，结构体pollfd数组元素的个数 - timeout参数：指定等待的毫秒数，无论I/O是否准备好，poll都会返回。 - 参数设置为-1时，表示永远阻塞等待。 2. 0表示立即返回，不阻塞(立即返回并列出准备好I/O的文件描述符，并不等待其它的事件)。 3. 大于0时，表示等待指定数目的毫秒数。 返回值： 大于0：表示结构体数组fds中有fd描述符的状态发生变化，或可以读取、或可以写入、或出错。并且返回的值表示这些状态有变化的socket描述符的总数量；此时可以对fds数组进行遍历，以寻找那些revents不空的描述符，然后判断这个里面有哪些事件以读取数据。 等于0：表示没有描述符有状态变化，并且调用超时。 小于0：此时表示有错误发生，此时全局变量errno保存错误码。 错误代码： EBADF: 一个或多个结构体中指定的文件描述符无效。 EFAULT: fds指针指向的地址超出进程的地址空间。 EINTR: 请求的事件之前产生一个信号，调用可以重新发起。 EINVAL: nfds参数超出PLIMIT_NOFILE值。 ENOMEM: 可用内存不足，无法完成请求。 内核追踪-比较效率 select 内核追踪 内核代码是参考2.6.12版本的内核 1234567891011121314151617181920212223242526272829303132333435363738394041asmlinkage long sys_select(int n, fd_set __user *inp, fd_set __user *outp, fd_set __user *exp, struct timeval __user *tvp)&#123; ..... /* n 是需要监听描述符集中，最大描述加1，然后，开始申请内存 */ ret = -ENOMEM; size = FDS_BYTES(n); bits = select_bits_alloc(size); if (!bits) goto out_nofds; //设置指针，指向特定的内存，所以，才可以往fds 中个指针填充数据 fds.in = (unsigned long *) bits; fds.out = (unsigned long *) (bits + size); fds.ex = (unsigned long *) (bits + 2*size); fds.res_in = (unsigned long *) (bits + 3*size); fds.res_out = (unsigned long *) (bits + 4*size); fds.res_ex = (unsigned long *) (bits + 5*size); //用用户空间获取相应的参数值 if ((ret = get_fd_set(n, inp, fds.in)) || (ret = get_fd_set(n, outp, fds.out)) || (ret = get_fd_set(n, exp, fds.ex))) goto out; //清空需要返回给用户态的参数 zero_fd_set(n, fds.res_in); zero_fd_set(n, fds.res_out); zero_fd_set(n, fds.res_ex); //这里就是重点调用do_select() 函数来轮询，该函数轮询结束之后，返回， //然后，就可以把fds 中相应的属性返回给应用程序。 //do_select() 也是通过schedule_time() 调度返回的，那么休眠被唤醒之后，可能是被一些信号触发唤醒， //那么，下面就调用signal_pending(); 来检测信号是否异常。 ret = do_select(n, &amp;fds, &amp;timeout); ......&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*最终调用 do_select(); 函数，该函数的主要框架如下：*/int do_select(int n, fd_set_bits *fds, long *timeout)&#123; ..... //此时，进入一个死循环，退出循环的条件有: //1 -- retval != 0，就是说，监听的文件描述符有信号可以处理。 //2 -- timeout == 0, 超时了。 //3 -- signal_pending(); 检测到当前的进程接受到信号处理。 //4 -- wait-&gt;error 记录的错误事件不为，表示有错误处理。 for (;;) &#123; ...... //设置当前的进程的可中断的休眠状态 set_current_state(TASK_INTERRUPTIBLE); ...... for (i = 0; i &lt; n; ++rinp, ++routp, ++rexp) &#123; ...... for (j = 0; j &lt; __NFDBITS; ++j, ++i, bit &lt;&lt;= 1) &#123; ..... //调用fd 文件描述符对应的驱动程序的poll 函数指针指向的函数。 //如果fd 是一个网络套接，而且使用TCP 协议，那么，该函数指针就指向tcp_poll(); 函数。 mask = (*f_op-&gt;poll)(file, retval ? NULL : wait); ...... &#125; &#125;//end of 第3 层for 循环 ...... &#125;//end of 第2 层for 循环 //上面的for() 循环调用了cond_resched() 来调度CPU，那么，可能在睡眠的时候被产生信号触发返回， //所以，这里还需要调用signal_pending() 检测是否是被信号触发返回。所以，在select()函数中是可以被信号中断返回， //在pselect()函数中就可以屏蔽相应的信号。 //如果retval &gt;=1 表示有信号处理，所以，推出循环。 if (retval || !__timeout || signal_pending(current)) break; if(table.error) &#123; retval = table.error; break; &#125; //具有定时唤醒进程的调度CPU //而且，返回的时间是离__timeout 还剩下多少时间，如果已经超过__timeout，就返回0 __timeout = schedule_timeout(__timeout); &#125;//end of for(;;); ..... *timeout = __timeout; //更新参数timeout 为新的时间 return retval; //返回有多少个信号需要处理&#125; 可以看到，主要是通过“三重循环”来查询套接口是否有信息可以处理。 poll内核追踪 内核代码是参考2.6.12版本的内核 12345678910111213141516171819202122232425262728293031323334asmlinkage long sys_poll(struct pollfd __user * ufds, unsigned int nfds, long timeout)&#123; ...... //申请内存空间，存放用户层传递过来的参数 while(i!=0) &#123; struct poll_list *pp; pp = kmalloc(sizeof(struct poll_list)+ sizeof(struct pollfd)* (i&gt;POLLFD_PER_PAGE?POLLFD_PER_PAGE:i), GFP_KERNEL); if(pp==NULL) goto out_fds; pp-&gt;next=NULL; pp-&gt;len = (i&gt;POLLFD_PER_PAGE?POLLFD_PER_PAGE:i); if (head == NULL) head = pp; else walk-&gt;next = pp; walk = pp; if (copy_from_user(pp-&gt;entries, ufds + nfds-i, sizeof(struct pollfd)*pp-&gt;len)) &#123; err = -EFAULT; goto out_fds; &#125; i -= pp-&gt;len; &#125;//end of while //进入轮询的主要操作 fdcount = do_poll(nfds, head, &amp;table, timeout); ......&#125; 1234567891011121314151617181920212223242526272829 主要是进入 do_poll()函数，该函数的主要框架如下：static int do_poll(unsigned int nfds, struct poll_list *list, struct poll_wqueues *wait, long timeout)&#123; ..... //进入一个死循环，退出的条件有: //1 -- count != 0，就是说，监听的文件描述符有信号可以处理。 //2 -- timeout == 0, 超时了。 //3 -- signal_pending(); 检测到当前的进程接受到信号处理。 //4 -- wait-&gt;error 记录的错误事件不为，表示有错误处理。 for (;;) &#123; ... set_current_state(TASK_INTERRUPTIBLE); while(walk != NULL) &#123; do_pollfd( walk-&gt;len, walk-&gt;entries, &amp;pt, &amp;count); walk = walk-&gt;next; &#125; ..... if (count || !timeout || signal_pending(current)) break; count = wait-&gt;error; if (count) break; timeout = schedule_timeout(timeout); &#125; __set_current_state(TASK_RUNNING); return count;&#125; 1234567891011121314151617181920 上面的函数处理双重循环，然后，进入到 do_pollfd(); 函数中，该函数的主要框架如下： static void do_pollfd(unsigned int num, struct pollfd * fdpage,poll_table ** pwait, int *count) &#123; ...... //循环扫描文件描述符数组中的文件描述符 for (i = 0; i &lt; num; i++) &#123; ..... if (file != NULL) &#123; //执行文件操作集中的poll 指针所指向的函数。 //例如，自己在开发驱动程序的时候，此时的poll 指针，就执行我们定义注册 //到file_operations 结构中的函数。 //调用fd 文件描述符对应的驱动程序的poll 函数指针指向的函数。 //如果fd 是一个网络套接，而且使用TCP 协议，那么，该函数指针就指向tcp_poll(); 函数。 if (file-&gt;f_op &amp;&amp; file-&gt;f_op-&gt;poll) mask = file-&gt;f_op-&gt;poll(file, *pwait); ...... &#125; &#125; 对于 sys_poll()函数也是需要 3 个循环来处理与sys_select()函数的处理模式差不多。 分析 poll的机制与select类似，与select在本质上没有多大差别，管理多个描述符也是进行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。 poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。 pollfd中的events字段和revents分别用于标示关注的事件和发生的事件，故pollfd数组只需要被初始化一次 poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。 select() 函数的最后一个参数是指针类型，其值会被修改，所以，当再次调用select() 函数的时候，需要重新设置该参数。而poll() 函数的最后一个参数是值类型，不会被修改。 优缺点 优点： poll() 不要求开发者计算最大文件描述符加一的大小。 poll() 在应付大数目的文件描述符的时候速度更快，相比于select。 它没有最大连接数的限制，原因是它是基于链表来存储的。 缺点： 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。 与select一样，poll返回后，需要轮询pollfd来获取就绪的描述符 示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142/*服务器*/#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;poll.h&gt;#include &lt;string.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#define MAXSIZE 1024 //缓冲区最大值#define PORT 55555 //端口号#define LISTENQ 20 //监听的最大值#define INFTIM -1 //timeout时间int main(int argc, char *argv[])&#123; int listenfd; struct sockaddr_in serverAddr, clientAddr; bzero(&amp;serverAddr, sizeof(serverAddr)); serverAddr.sin_family = AF_INET; serverAddr.sin_port = htons(PORT); serverAddr.sin_addr.s_addr = htonl(INADDR_ANY); if((listenfd = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0)&#123; perror(\"socket\"); exit(1); &#125; //地址复用 int reuse = 1; if(setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;reuse, sizeof(reuse)) &lt; 0)&#123; perror(\"setsockopt\"); exit(1); &#125; if(bind(listenfd, (struct sockaddr*)&amp;serverAddr, sizeof(serverAddr)) &lt; 0)&#123; perror(\"bind\"); exit(1); &#125; if(listen(listenfd, LISTENQ) &lt; 0)&#123; perror(\"listen\"); exit(1); &#125; //获取每个进程最大打开的文件数 long OPEN_MAX = sysconf(_SC_OPEN_MAX); struct pollfd client[OPEN_MAX]; //注册监听事件 client[0].fd = listenfd; client[0].events = POLLIN; int i = 1; for(; i &lt; OPEN_MAX; i++)&#123; client[i].fd = -1; &#125; int sockfd, connfd; int nready; int maxi = 0; char buf[MAXSIZE]; bzero(buf, MAXSIZE); socklen_t clilen; while(1)&#123; if((nready = poll(client, maxi+1, INFTIM)) &lt; 0)&#123; perror(\"poll\"); exit(1); &#125; if(client[0].revents &amp; POLLIN)&#123; clilen = sizeof(clientAddr); if((connfd = accept(listenfd, (struct sockaddr*)&amp;clientAddr, &amp;clilen)) &lt; 0)&#123; perror(\"accept\"); exit(1); &#125; for(i = 1; i &lt; OPEN_MAX; i++)&#123; if(client[i].fd &lt; 0)&#123; client[i].fd = connfd; client[i].events = POLLIN; break; &#125; &#125; if(i == OPEN_MAX)&#123; perror(\"too many clients\"); exit(1); &#125; if(i &gt; maxi)&#123; maxi = i; &#125; if(--nready &lt;= 0)&#123; continue; &#125; &#125; for(i = 1; i &lt;= maxi; i++)&#123; if((sockfd = client[i].fd) &lt; 0)&#123; continue; &#125; bzero(buf, MAXSIZE); if(client[i].revents &amp; (POLLIN | POLLERR))&#123; int n = 0; if((n = recv(sockfd, buf, MAXSIZE, 0)) &lt; 0)&#123; if(errno == ECONNRESET)&#123; close(sockfd); client[i].fd = -1; &#125;else&#123; perror(\"recv\"); exit(1); &#125; &#125;else if(n == 0)&#123; close(sockfd); client[i].fd = -1; &#125;else if(n &gt; 0)&#123; printf(\"client : %s\", buf); if(send(sockfd, buf, strlen(buf), 0) &lt; 0)&#123; perror(\"send\"); exit(1); &#125; printf(\"\\nserver : %s\", buf); putchar(10); &#125; if(--nready &lt;= 0)&#123; break; &#125; &#125; &#125; &#125; return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/*客户端*/#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/types.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;poll.h&gt;#define MAXSIZE 1024#define PORT 55555int main()&#123; int sockfd; struct sockaddr_in clientAddr; clientAddr.sin_family = AF_INET; clientAddr.sin_port = htons(PORT); clientAddr.sin_addr.s_addr = inet_addr(\"127.0.0.1\"); if((sockfd = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0)&#123; perror(\"socket\"); exit(1); &#125; if(connect(sockfd, (struct sockaddr*)&amp;clientAddr, sizeof(clientAddr)) &lt; 0)&#123; perror(\"connect\"); exit(1); &#125; char buf[MAXSIZE]; bzero(buf, MAXSIZE); struct pollfd server[2]; server[0].fd = sockfd; server[0].events = POLLIN; server[1].fd = fileno(stdin); server[1].events = POLLIN; int nready; int maxfd = sockfd &gt; fileno(stdin)?sockfd:fileno(stdin); while(1)&#123; if((nready = poll(server, maxfd+1, -1)) &lt; 0 )&#123; perror(\"poll\"); exit(1); &#125; if(nready == 0) continue; if(server[1].revents &amp; POLLIN)&#123; if(fgets(buf, MAXSIZE, stdin) != NULL)&#123; if(send(sockfd, buf, strlen(buf), 0) &lt; 0)&#123; perror(\"send\"); exit(1); &#125; bzero(buf, MAXSIZE); &#125; &#125; if(server[0].revents &amp; POLLIN)&#123; int n = 0; if((n = recv(sockfd, buf, MAXSIZE, 0)) &lt; 0)&#123; perror(\"recv\"); exit(1); &#125;else if(n == 0)&#123; close(sockfd); &#125;else&#123; printf(\"\\nserver : %s\", buf); putchar(10); &#125; &#125; &#125; close(sockfd); return 0;&#125; 参考 http://www.cnblogs.com/orlion/p/6142838.html http://www.cnblogs.com/Anker/archive/2013/08/15/3261006.html http://blog.csdn.net/lixungogogo/article/details/52226434 http://blog.csdn.net/zhouzhenhe2008/article/details/75807720 http://blog.csdn.net/feng19870412/article/details/9001857","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"I/O复用","slug":"I-O复用","permalink":"http://roux.top/tags/I-O复用/"}]},{"title":"I/O复用及同步、异步、阻塞、非阻塞","slug":"IO复用及同(异)步和(非)阻塞","date":"2017-11-15T16:00:00.000Z","updated":"2018-04-22T05:49:20.355Z","comments":true,"path":"2017/11/16/IO复用及同(异)步和(非)阻塞/","link":"","permalink":"http://roux.top/2017/11/16/IO复用及同(异)步和(非)阻塞/","excerpt":"前言 用户空间与内核空间 现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操作系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。","text":"前言 用户空间与内核空间 现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操作系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 进程切换 为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。 从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： 保存处理机上下文，包括程序计数器和其他寄存器。 更新PCB(进程控制块)信息。 把进程的PCB(进程控制块)移入相应的队列，如就绪、在某事件阻塞等队列。 选择另一个进程执行，并更新其PCB(进程控制块)。 更新内存管理的数据结构。 恢复处理机上下文。 具体参考：进程切换 同步与异步 同步和异步，这两个概念与消息的通知机制有关。也就是同步与异步主要是从消息通知机制角度来说的。 所谓同步就是一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列。要么成功都成功，失败都失败，两个任务的状态可以保持一致。 所谓异步是不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。至于被依赖的任务最终是否真正完成，依赖它的任务无法确定，所以它是不可靠的任务序列。 异步的概念和同步相对。当一个同步调用发出后，调用者要一直等待返回消息（结果）通知后，才能进行后续的执行；当一个异步过程调用发出后，调用者不能立刻得到返回消息（结果）。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。使用哪一种通知机制，依赖于执行部件的实现，除非执行部件提供多种选择，否则不受调用者控制 如果执行部件用状态来通知，那么调用者就需要每隔一定时间检查一次，效率就很低（有些初学多线程编程的人，总喜欢用一个循环去检查某个变量的值，这其实是一种很严重的错误）； 如果是使用通知的方式，效率则很高，因为执行部件几乎不需要做额外的操作。至于回调函数，其实和通知没太多区别。 比如我去银行办理业务，可能会有两种方式： 选择排队等候 另种选择取一个小纸条上面有我的号码，等到排到我这一号时由柜台的人通知我轮到我去办理业务了 第一种：前者(排队等候)就是同步等待消息通知，也就是我要一直在等待银行办理业务情况； 第二种：后者(等待别人通知)就是异步等待消息通知。在异步消息处理中，等待消息通知者(在这个例子中就是等待办理业务的人)往往注册一个回调机制，在所等待的事件被触发时由触发机制(在这里是柜台的人)通过某种机制(在这里是写在小纸条上的号码，喊号)找到等待该事件的人。 阻塞与非阻塞 阻塞和非阻塞这两个概念与程序（线程）等待消息通知(无所谓同步或者异步)时的状态有关。也就是说阻塞与非阻塞主要是程序（线程）等待消息通知时的状态角度来说的。 阻塞调用是指调用结果返回之前，当前线程会被挂起，一直处于等待消息通知，不能够执行其他业务。函数只有在得到结果之后才会返回。 非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。虽然表面上看非阻塞的方式可以明显的提高CPU的利用率，但是也带了另外一种后果就是系统的线程切换增加。增加的CPU执行时间能不能补偿系统的切换成本需要好好评估。 注意： 对于同步调用来说，很多时候当前线程可能还是激活的，只是从逻辑上当前函数没有返回而已，此时，这个线程可能也会处理其他的消息。 如果这个线程在等待当前函数返回时，仍在执行其他消息处理，那这种情况就叫做同步非阻塞 如果这个线程在等待当前函数返回时，没有执行其他消息处理，而是处于挂起等待状态，那这种情况就叫做同步阻塞 所以同步的实现方式会有两种：同步阻塞、同步非阻塞；同理，异步也会有两种实现：异步阻塞、异步非阻塞 对于阻塞调用来说，则当前线程就会被挂起等待当前函数返回 继续上面的那个银行办理业务的例子 不论是排队还是使用号码等待通知，如果在这个等待的过程中，等待者除了等待消息通知之外不能做其它的事情，那么该机制就是阻塞的，表现在程序中,也就是该程序一直阻塞在该函数调用处不能继续往下执行。 相反，有的人喜欢在银行办理这些业务的时候一边打打电话发发短信一边等待，这样的状态就是非阻塞的，因为他(等待者)没有阻塞在这个消息通知上，而是一边做自己的事情一边等待。 但是需要注意了，同步非阻塞形式实际上是效率低下的，想象一下你一边打着电话一边还需要抬头看到底队伍排到你了没有。如果把打电话和观察排队的位置看成是程序的两个操作的话，这个程序需要在这两种不同的行为之间来回的切换，效率可想而知是低下的；而异步非阻塞形式却没有这样的问题，因为打电话是你(等待者)的事情，而通知你则是柜台(消息触发机制)的事情，程序没有在两种不同的操作中来回切换。 同步、异步、阻塞、非阻塞 同步、异步、阻塞、非阻塞，是分3个层次的：CPU层次；线程层次；程序员感知层次。 CPU层次 在CPU层次，或者说操作系统进行IO和任务调度的层次，现代操作系统通常使用异步非阻塞方式进行IO（有少部分IO可能会使用同步非阻塞轮询），即发出IO请求之后，并不等待IO操作完成，而是继续执行下面的指令（非阻塞），IO操作和CPU指令互不干扰（异步），最后通过中断的方式来通知IO操作完成结果。 线程层次 在线程层次，或者说操作系统调度单元的层次，操作系统为了减轻程序员的思考负担，将底层的异步非阻塞的IO方式进行封装，把相关系统调用（如read，write等）以同步的方式展现出来。然而，同步阻塞的IO会使线程挂起，同步非阻塞的IO会消耗CPU资源在轮询上。为了解决这一问题，就有3种思路： 多线程（同步阻塞）； IO多路复用（select，poll，epoll）（同步非阻塞，严格地来讲，是把阻塞点改变了位置）； 直接暴露出异步的IO接口，如kernel-aio和IOCP（异步非阻塞）。 程序员感知层次 在Linux中，上面提到的第2种思路用得比较广泛，也是比较理想的解决方案。然而，直接使用select之类的接口，依然比较复杂，所以各种库和框架百花齐放，都试图对IO多路复用进行封装。此时，库和框架提供的API又可以选择是以同步的方式还是异步的方式来展现。如python的asyncio库中，就通过协程，提供了同步阻塞式的API；如node.js中，就通过回调函数，提供了异步非阻塞式的API。总结因此，我们在讨论同步、异步、阻塞、非阻塞时，必须先明确是在哪个层次进行讨论。比如node.js，我们可以说她在程序员感知层次提供了异步非阻塞的API，也可以说在Linux下，她在线程层次以同步非阻塞的epoll来实现。 示例：老张爱喝茶，废话不说，煮开水。 出场人物：老张，水壶两把（普通水壶，简称水壶；会响的水壶，简称响水壶）。 同步阻塞形式 老张把水壶放到火上，立等水开。（同步阻塞） 老张觉得自己有点傻 同步非阻塞形式 老张把水壶放到火上，去客厅看电视，时不时去厨房看看水开没有。（同步非阻塞） 老张还是觉得自己有点傻，于是变高端了，买了把会响笛的那种水壶。水开之后，能大声发出嘀~~~~的噪音。 异步阻塞形式 老张把响水壶放到火上，立等水开。（异步阻塞） 老张觉得这样傻等意义不大 异步操作是可以被阻塞住的，只不过它不是在处理消息时阻塞，而是在等待消息通知时被阻塞。 异步非阻塞形式 老张把响水壶放到火上，去客厅看电视，水壶响之前不再去看它了，响了再去拿壶。（异步非阻塞） 老张觉得自己聪明了。 总结 所谓同步异步，只是对于水壶而言。 普通水壶，同步；响水壶，异步。 虽然都能干活，但响水壶可以在自己完工之后，提示老张水开了。这是普通水壶所不能及的。 同步只能让调用者去轮询自己（情况2中），造成老张效率的低下。 所谓阻塞非阻塞，仅仅对于老张而言。 立等的老张，阻塞；看电视的老张，非阻塞。 情况1和情况3中老张就是阻塞的，媳妇喊他都不知道。虽然3中响水壶是异步的，可对于立等的老张没有太大的意义。所以一般异步是配合非阻塞使用的，这样才能发挥异步的效用。 同步和异步仅仅是关注的消息如何通知的机制，而阻塞与非阻塞关注的是等待消息通知时的状态。也就是说，同步的情况下，是由处理消息者自己去等待消息是否被触发，而异步的情况下是由触发机制来通知处理消息者，所以在异步机制中，处理消息者和触发机制之间就需要一个连接的桥梁(上面例子桥梁就是能响的水壶的响声) I/O复用技术 I/O多路复用是指内核一旦发现进程指定的一个或者多个I/O条件准备就绪(通过轮询的机制)，它就通知该进程。I/O复用适用于以下场合： 当客户处理多个描述符（一般是交互式输入或网络套接字），必须使用I/O复用 当一个客户处理多个套接字时，这种情况很少见，但也可能出现 当一个TCP服务器既要处理监听套接字，又要处理已连接套接字，一般就要使用I/O复用 如果一个服务器既要使用TCP，又要使用UDP，一般就要使用I/O复用 如果一个服务器要处理多个服务或者多个协议，一般就要使用I/O复用 与多线程和多进程技术相比，I/O复用技术的最大优势就是系统开销小，系统不必创建进程/线程，也不必维护这些进程/进程，从而大大减小了系统的开销。 I/O模型 Unix下常见的I/O模型有五种，分别是：阻塞式I/O，非阻塞式I/O，I/O复用，信号驱动式I/O和异步I/O。 Unix下对于一个输入操作，通常包含两个不同的阶段： 等待数据准备好 从内核向进程复制数据 例如：对于一次read函数操作来说，数据先会被拷贝到操作系统内核的缓冲区去，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。(比如对于一次socket流传输来说，首先等待网络上的数据到达，然后复制到内核的某个缓冲区，然后再把内核缓冲区的数据复制到进程缓冲区) 阻塞式I/O模型 趣解模型 假定一个特定的场景，你的一个好朋友找你借钱，你身上没有充足的现金，于是，你要去银行取钱，银行人多，你只能在那里排队，在这段时间内，你不能离开队伍去干你自己的事情。时间都浪费在排队上面了。这就是典型的阻塞式I/O模型。 网络模型 默认情况下，所有的套接字都时阻塞的，以数据报套接字为例 如上图，我们把recvfrom函数视为系统调用，进程调用recvform函数后就阻塞于此，等待数据报的到达，一直到内核把数据报准备好后，就将数据从内核复制到用户进程，随后用户进程再对这些数据进行处理。 这种模型的好处就是，能够及时获得数据，没有延迟，但是就像上面趣解模型中讲到，对用户来说，这段时间一直要处于等到状态，不能去做其他的事情，在性能方面付出了代价。 非阻塞式I/O模型 趣解模型 还是去银行取钱，假设你无法忍受一直在那里排队，而是去旁边的商场逛逛，然后隔一段时间回来看看还有在排队没，有的话再继续去逛逛，直到有一次你回来看到没有人排队了为止。这就是非阻塞式I/O模型。 网络模型 进程把一个套接字设置成非阻塞是在通知内核：当所请求的I/O操作非得把本进程投入睡眠才能完成时，不要把本进程投入睡眠，而是返回一个错误。 如上图所示，前三次询问都返回一个错误，即内核没有数据报准备好，到第四次调用recvform函数时，数据被准备好了，它被复制到应用进程缓存区，于是recvform成功返回，应用进程随后处理数据。 优点在于：应用进程不必阻塞在recvfrom调用中，而是可以去处理其他事情 缺点在于：如趣解模型中所说，你来回跑银行带来了很大的延时，可能在你来回的路上叫到了你的号。在网络模型中即可以表现在任务完成的响应延迟增大了，隔一段时间轮询一次recvform，数据报可能在两次轮询之间的任意时间内准备好，这将会导致整体数据吞吐量的降低。 I/O复用模型 趣解模型 现在，银行都会按一个显示屏，上面会显示轮到几号客户了。这个时候，你就不用每次都去跑进去看还有排队没，而是远远的看看显示屏上轮到你没有，如果显示了你的名字，你就去取钱就行了。这就是I/O复用模型 网络模型 有了I/O复用技术，我们可以调用select或poll类型的函数，阻塞在这两个系统调用中的某一个之上，而不是阻塞在真正的I/O系统调用上。 如上图所示，进程受阻于select调用，等待可能多个套接字中的任一个变为可读。当select返回套接字可读这一条件时，应用进程就调用recvfrom把所读的数据报复制到应用进程缓冲区。 进程阻塞在select，如果进程还有其他的任务的话就能体现到I/O复用技术的好处，那个任务先返回可读条件，就去执行哪个任务。从单一的等待变成多个任务的同时等待。 这种模型较之前的模型来说，可以不必多次轮询内核，而是等到内核的通知。 信号驱动式I/O模型 趣解模型 你还是不满意银行的服务，虽然不必排队，但你在商场逛的也不放心啊，你还是要盯着显示屏，深怕没有看到显示屏上面你的名字，于是，银行也退出了全新的服务，你去银行取钱的时候，银行目前人多不能及时处理你的业务，而是叫你留下手机号，等到空闲的时候就短信通知你可以去取钱了。这就是信号驱动式I/O模型。 网络模型 我们可以用信号，让内核在描述符就绪时发送SIGIO信号告知我们。 如上图所示，进程建立SIGIO的信号处理程序（就要趣解模型中的留下手机号），并通过sigaction系统调用安装一个信号处理函数，该系统调用将立即返回，进程继续工作，知道数据报准备好后，内核产生一个SIGIO信号，告知应用进程以及准备好，于是就在信号处理程序中调用recvfrom读取数据报，并通知主循环数据已准备好待处理，也可以立即通知主循环让他读取数据报。 这种模型的好处就是，在数据报没有准备好的期间，应用进程不必阻塞，继续执行主循环，只要等待来自信号处理函数的通知即可。 异步I/O模型 趣解模型 你细细的想了想自己取钱时为了什么，无非时借给你的朋友，银行都退出了网上银行服务，你只需要知道你的好朋友的银行卡号，然后在网银中申请转账，银行后台会给你处理，然后把钱打到你朋友的账户下面，等这些都处理好后，银行会给你发一条短信，告诉你转账成功，这个时候你就可以跟你的好朋友说，钱已经打给你了。这就是异步I/O模型，取钱借钱的繁琐事就交给银行后台给你处理吧。 网络模型 POSIX规范中提供一些函数，这些函数的工作机制是：告知内核启动某个操作，并让内核在整个操作完成后通知我们。 如上图所示，我们调用 aioread 函数(POSIX异步I/O函数以 aio 或 lio_ 开头)，给内核传递描述符，缓冲区指针，缓冲区大小和文件偏移，并告诉内核完成整个操作后通知我们。 不同于信号驱动式I/O模型，信号是在数据已复制到进程缓冲区才产生的。 各种I/O模型的比较 以一张图来说明五种I/O操作的差异： 同步I/O操作：导致请求进程阻塞，直到I/O操作完成 异步I/O操作：不导致进程阻塞 前四种都属于同步I/O操作慢系统都会阻塞与recvfrom操作，而异步I/O不会。 总结 联系与解释： http://yaocoder.blog.51cto.com/2668309/1308899 http://www.jianshu.com/p/02f76566fd90","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"I/O复用","slug":"I-O复用","permalink":"http://roux.top/tags/I-O复用/"}]},{"title":"随笔2017.11.15","slug":"随笔17.11.15","date":"2017-11-14T16:00:00.000Z","updated":"2018-10-24T14:32:49.822Z","comments":true,"path":"2017/11/15/随笔17.11.15/","link":"","permalink":"http://roux.top/2017/11/15/随笔17.11.15/","excerpt":"随笔&emsp;&emsp;最近一段时间说起来也不知道忙了个什么(琐事太多了)，但是收获还挺大的。&emsp;&emsp;前两天领悟到一个道理：和利益沾边的事情，总会有那么些人，让你明白你所认识的世界还是充满了勾心斗角(心累)。","text":"随笔&emsp;&emsp;最近一段时间说起来也不知道忙了个什么(琐事太多了)，但是收获还挺大的。&emsp;&emsp;前两天领悟到一个道理：和利益沾边的事情，总会有那么些人，让你明白你所认识的世界还是充满了勾心斗角(心累)。&emsp;&emsp;今天想通了另一个道理：拿得起，放得下(一定要放得下)。&emsp;&emsp;说起来，真心喜欢程序员这一类人。也没什么坏心思(就是有时候有自己的小聪明，但是这又算得了什么)，而且说话干事比较直接点(也好也不好，但是同类人之间真心交流很舒服，嘿嘿！)。&emsp;&emsp;一直听别人说：程序员话少，钱多，死得早。自己也曾这样黑过自己，哈哈。但是，我想说的是换个角度考虑：程序员话少是因为学的东西多了，就知道自己所看到的天地是多么的广阔，所以说前会考虑(有时也是懒得说，说了对方也不明白(没人懂你)，也有时思考的多了，就知道自己的肤浅，从而不敢说了)；赚的钱多是因为从事互联网行业的基本上的工作时间都是996(在毕业才进公司的第一年知识不足，不加班怎么充实自己，怎样提升自己)，用身体和时间换来的金钱和一身病(这个也不一定，但是特别累是肯定的)。一直认为从事算法研究及AI人工智能领域的人，对数学的要求很高从而对大脑的思考要求也很高，最后秃头几率就会变大(是不是有误解。。。)，而一般的程序员，个人感觉还是等上年龄再讨论吧，哈哈。。。。。。&emsp;&emsp;感觉我自己话还挺多的(是不是太菜了？？？)，心也挺大的(心情不好，睡一觉就ok了！)。其实，活着不难，但是好好活下去挺不容易的，所以活着就是最美好的事了，能好好的活下去岂不是更美好！&emsp;&emsp;自己喜欢的事尽早去做，用心去做，所有的问题最终都能得到解决的(不论完美亦或不完美)，感受生活，从未体会到的美好(我是不是还活在梦里，哈哈)。","categories":[{"name":"生活","slug":"生活","permalink":"http://roux.top/categories/生活/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://roux.top/tags/随笔/"}]},{"title":"Linux中用gdb 查看代码堆栈的信息","slug":"gdb","date":"2017-11-07T16:00:00.000Z","updated":"2017-11-25T10:50:11.280Z","comments":true,"path":"2017/11/08/gdb/","link":"","permalink":"http://roux.top/2017/11/08/gdb/","excerpt":"说明 core dump 一般是在segmentation fault（段错误）的情况下产生的文件，需要通过ulimit来设置才会得到的。 调试的话输入： gdb filename core filename 就是产生 core 文件的可执行文件，core 就是产生的 dump 文件","text":"说明 core dump 一般是在segmentation fault（段错误）的情况下产生的文件，需要通过ulimit来设置才会得到的。 调试的话输入： gdb filename core filename 就是产生 core 文件的可执行文件，core 就是产生的 dump 文件 查看栈信息 当程序被停住了，你需要做的第一件事就是查看程序是在哪里停住的。当你的程序调用了一个函数，函数的地址，函数参数，函数内的局部变量都会被压入“栈”（Stack）中。你可以用GDB命令来查看当前的栈中的信息。 下面是一些查看函数调用栈信息的GDB命令： 打印当前的函数调用栈的所有信息。 backtrace(简写：bt) backtrace (简写：bt ) n是一个正整数，表示只打印栈顶上n层的栈信息。 n是一个负整数，表示只打印栈底下n层的栈信息。 如果你要查看某一层的信息，你需要在切换当前的栈，一般来说，程序停止时，最顶层的栈就是当前栈，如果你要查看栈下面层的详细信息，首先要做的是切换当前栈。 frame(简写：f) n是一个从0开始的整数，是栈中的层编号。比如：frame 0，表示栈顶，frame 1，表示栈的第二层。 frame args frame命令让你可以从一个帧移动到另一个帧，并打印你所选择的帧。args可以是帧的地址或者编号。如果没有指定参数，frame会输出当前栈帧。 select-frame 使用select-frame命令你可以从一个帧移动到另一个帧但是不会输出任何信息，它是frame的无输出版本。 up (n) 表示向栈的上面移动n层，可以不打n，表示向上移动一层。 down (n) 表示向栈的下面移动n层，可以不打n，表示向下移动一层。 上面的命令，都会打印出移动到的栈层的信息。如果你不想让其打出信息。你可以使用这三个命令： select-frame 对应于 frame 命令。 up-silently 对应于 up 命令。 down-silently 对应于 down 命令。 查看当前栈层的信息，你可以用以下GDB命令： frame (简写：f) 会打印出这些信息：栈的层编号，当前的函数名，函数参数值，函数所在文件及行号，函数执行到的语句。 info frame (简写：info f) 这个命令会打印出更为详细的当前栈层的信息，只不过，大多数都是运行时的地址。比如：函数地址，调用函数的地址，被调用函数的地址，目前的函数是由什么样的程序语言写成的、函数参数地址及值、局部变量的地址等等。 info args 打印出当前函数的参数名及其值。 info locals 打印出当前函数中所有局部变量及其值。 info catch 打印出当前的函数中的异常处理信息。 查看源程序 显示源代码 GDB 可以打印出所调试程序的源代码，当然，在程序编译时一定要加上-g的参数，把源程序信息编译到执行文件中。不然就看不到源程序了。当程序停下来以后，GDB会报告程序停在了那个文件的第几行上。你可以用list命令来打印程序的源代码。 list 显示当前行后面的源程序。 list - 显示当前行前面的源程序。 搜索源代码 forward-search (简写：search) 向前面搜索。 reverse-search 全部搜索。 指定源文件的路径 某些时候，用-g编译过后的执行程序中只是包括了源文件的名字，没有路径名。GDB提供了可以让你指定源文件的路径的命令，以便GDB进行搜索。 directory(简写：dir） 加一个源文件路径到当前路径的前面。如果你要指定多个路径，UNIX下你可以使用“:”，Windows下你可以使用“;”。 show directories 显示定义了的源文件搜索路径。 源代码的内存 你可以使用info line命令来查看源代码在内存中的地址。 info line后面可以跟“行号”，“函数名”，“文件名:行号”，“文件名:函数名”，这个命令会打印出所指定的源码在运行时的内存地址。 还有一个命令（disassemble）你可以查看源程序的当前执行时的机器码，这个命令会把目前内存中的指令dump出来。 查看运行时数据 print (简写：p) print / 是表达式，是你所调试的程序的语言的表达式（GDB可以调试多种编程语言），是输出的格式，比如，如果要把表达式按16进制的格式输出，那么就是/x(print/x)。 表达式 在表达式中，有几种GDB所支持的操作符，它们可以用在任何一种语言中。 @ 是一个和数组有关的操作符，在后面会有更详细的说明。 :: 指定一个在文件或是一个函数中的变量。 {} 表示一个指向内存地址的类型为type的一个对象。 程序变量 在GDB中，你可以随时查看以下三种变量的值： 全局变量（所有文件可见的） 静态全局变量（当前文件可见的） 局部变量（当前Scope可见的） 如果你的局部变量和全局变量发生冲突（也就是重名），一般情况下是局部变量会隐藏全局变量，也就是说，如果一个全局变量和一个函数中的局部变量同名时，如果当前停止点在函数中，用print显示出的变量的值会是函数中的局部变量的值。如果此时你想查看全局变量的值时，你可以使用“::”操作符： file::variable function::variable 可以通过这种形式指定你所想查看的变量，是哪个文件中的或是哪个函数中的。例如，查看文件f2.c中的全局变量x的值：gdb) p &#39;f2.c&#39;::x 当然，“::”操作符会和C++中的发生冲突，GDB能自动识别“::”是否C++的操作符，所以你不必担心在调试C++程序时会出现异常。 另外，需要注意的是，如果你的程序编译时开启了优化选项，那么在用GDB调试被优化过的程序时，可能会发生某些变量不能访问，或是取值错误码的情况。这个是很正常的，因为优化程序会删改你的程序，整理你程序的语句顺序，剔除一些无意义的变量等，所以在GDB调试这种程序时，运行时的指令和你所编写指令就有不一样，也就会出现你所想象不到的结果。对付这种情况时，需要在编译程序时关闭编译优化。 一般来说，几乎所有的编译器都支持编译优化的开关，例如，GNU 的C/C++编译器GCC，你可以使用“-gstabs”选项来解决这个问题。 数组 有时候，你需要查看一段连续的内存空间的值。比如数组的一段，或是动态分配的数据的大小。你可以使用GDB的“@”操作符，“@”的左边是第一个内存的地址的值，“@”的右边则你你想查看内存的长度。例如，你的程序中有这样的语句：int *array = (int *) malloc (len * sizeof (int));于是，在GDB调试过程中，你可以以如下命令显示出这个动态数组的取值： p *array@len @ 的左边是数组的首地址的值，也就是变量array所指向的内容，右边则是数据的长度，其保存在变量len中，其输出结果，大约是下面这个样子的： (gdb) p *array@len $1 = {2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32,34, 36, 38, 40} 如果是静态数组的话，可以直接用print数组名，就可以显示数组中所有数据的内容了。 输出格式 一般来说，GDB会根据变量的类型输出变量的值。但你也可以自定义GDB的输出的格式。例如，你想输出一个整数的十六进制，或是二进制来查看这个整型变量的中的位的情况。要做到这样，你可以使用GDB的数据显示格式： x 按十六进制格式显示变量。 d 按十进制格式显示变量。 u 按十六进制格式显示无符号整型。 o 按八进制格式显示变量。 t 按二进制格式显示变量。 a 按十六进制格式显示变量。 c 按字符格式显示变量。 f 按浮点数格式显示变量。 1234567891011121314151617(gdb) p i$21 = 101(gdb) p/a i$22 = 0x65(gdb) p/c i$23 = 101 &apos;e&apos;(gdb) p/f i$24 = 1.41531145e-43(gdb) p/x i$25 = 0x65(gdb) p/t i$26 = 1100101 自动显示 你可以设置一些自动显示的变量，当程序停住时，或是在你单步跟踪时，这些变量会自动显示。相关的GDB命令是display。 display display/ expr是一个表达式，fmt表示显示的格式，addr表示内存地址，当你用display设定好了一个或多个表达式后，只要你的程序被停下来，GDB会自动显示你所设置的这些表达式的值。 格式 i 和 s 同样被display支持，一个非常有用的命令是：display/i $pc $pc是GDB的环境变量，表示着指令的地址，/i则表示输出格式为机器指令码，也就是汇编。于是当程序停下后，就会出现源代码和机器指令码相对应的情形，这是一个很有意思的功能。 下面是一些和display相关的GDB命令： undisplay delete display 删除自动显示，dnums意为所设置好了的自动显式的编号。如果要同时删除几个，编号可以用空格分隔，如果要删除一个范围内的编号，可以用减号表示（如：2-5） disable display enable display disable和enalbe不删除自动显示的设置，而只是让其失效和恢复。 info display 查看display设置的自动显示的信息。GDB会打出一张表格，向你报告当然调试中设置了多少个自动显示设置，其中包括，设置的编号，表达式，是否enable。 设置显示选项 set print address (on/off) 打开地址输出，当程序显示函数信息时，GDB会显出函数的参数地址。系统默认为打开的。 show print address 查看当前地址显示选项是否打开。 set print array (on/off) 打开数组显示，打开后当数组显示时，每个元素占一行，如果不打开的话，每个元素则以逗号分隔。这个选项默认是关闭的。与之相关的两个命令如下，我就不再多说了。 show print array 查看当前数组显示选项是否打开。 set print elements 这个选项主要是设置数组的，如果你的数组太大了，那么就可以指定一个来指定数据显示的最大长度，当到达这个长度时，GDB就不再往下显示了。如果设置为0，则表示不限制。 show print elements 查看print elements的选项信息。 set print null-stop 如果打开了这个选项，那么当显示字符串时，遇到结束符则停止显示。这个选项默认为off。 set print pretty (on/off) 如果打开printf pretty这个选项，那么当GDB显示结构体时会比较漂亮。 show print pretty 查看GDB是如何显示结构体的。 set print sevenbit-strings 设置字符显示，是否按“\\nnn”的格式显示，如果打开，则字符串或字符数据按\\nnn显示，如“\\065”。 show print sevenbit-strings 查看字符显示开关是否打开。 set print union 设置显示结构体时，是否显式其内的联合体数据。 当打开这个开关时，执行 p foo 命令后，会如下显示：$1 = {it = Tree, form = {tree = Acorn, bug = Cocoon}} 当关闭这个开关时，执行 p foo 命令后，会如下显示：$1 = {it = Tree, form = {...}} show print union 查看联合体数据的显示方式 set print object 在C++中，如果一个对象指针指向其派生类，如果打开这个选项，GDB会自动按照虚方法调用的规则显示输出，如果关闭这个选项的话，GDB就不管虚函数表了。这个选项默认是off。 show print object 查看对象选项的设置。 set print static-members 这个选项表示，当显示一个C++对象中的内容是，是否显示其中的静态数据成员。默认是on。 show print static-members 查看静态数据成员选项设置。 set print vtbl 当此选项打开时，GDB将用比较规整的格式来显示虚函数表时。其默认是关闭的。 show print vtbl 查看虚函数显示格式的选项。 历史记录 当你用GDB的print查看程序运行时的数据时，你每一个print都会被GDB记录下来。 GDB会以$1, $2, $3 …..这样的方式为你每一个print命令编上号。于是，你可以使用这个编号访问以前的表达式，如$1。这个功能所带来的好处是，如果你先前输入了一个比较长的表达式，如果你还想查看这个表达式的值，你可以使用历史记录来访问，省去了重复输入。 GDB环境变量 你可以在GDB的调试环境中定义自己的变量，用来保存一些调试程序中的运行数据。要定义一个GDB的变量很简单只需使用GDB的set命令。GDB的环境变量和UNIX一样，也是以$起头。如：set $foo = *object_ptr 使用环境变量时，GDB会在你第一次使用时创建这个变量，而在以后的使用中，则直接对其賦值。环境变量没有类型，你可以给环境变量定义任一的类型。包括结构体和数组。 show convenience 该命令查看当前所设置的所有的环境变量。 这是一个比较强大的功能，环境变量和程序变量的交互使用，将使得程序调试更为灵活便捷。例如：set $i = 0 print bar[$i++]-&gt;contents 于是，当你就不必，print bar[0]-&gt;contents, printbar[1]-&gt;contents 地输入命令了。输入这样的命令后，只用敲回车，重复执行上一条语句，环境变量会自动累加，从而完成逐个输出的功能。 查看寄存器 要查看寄存器的值，很简单，可以使用如下命令： info registers 查看寄存器(可指定)的情况。（除了浮点寄存器） info all-registers 查看所有寄存器的情况。（包括浮点寄存器） 寄存器中放置了程序运行时的数据，比如程序当前运行的指令地址（ip），程序的当前堆栈地址（sp）等等。你同样可以使用print命令来访问寄存器的情况，只需要在寄存器名字前加一个 $ 符号就可以了。如：p $eip。 改变程序的执行 一旦使用GDB挂上被调试程序，当程序运行起来后，你可以根据自己的调试思路来动态地在GDB中更改当前被调试程序的运行线路或是其变量的值，这个强大的功能能够让你更好的调试你的程序，比如，你可以在程序的一次运行中走遍程序的所有分支。 修改变量值 修改被调试程序运行时的变量值，在GDB中很容易实现，使用GDB的print命令即可完成。如：(gdb) print x=4 x=4这个表达式是C/C++的语法，意为把变量x的值修改为4。 在某些时候，很有可能你的变量和GDB中的参数冲突，此时，你可以使用setvar命令来告诉GDB，width不是你GDB的参数，而是程序的变量名，如：(gdb) set var width=47 另外，还可能有些情况，GDB并不报告这种错误，所以保险起见，在你改变程序变量取值时，最好都使用setvar格式的GDB命令。 跳转执行 一般来说，被调试程序会按照程序代码的运行顺序依次执行。GDB提供了乱序执行的功能，也就是说，GDB可以修改程序的执行顺序，可以让程序执行随意跳跃。这个功能可以由GDB的jump命令来完： jump 指定下一条语句的运行点。可以是文件的行号，可以是file:line格式，可以是+num这种偏移量格式。表式着下一条运行语句从哪里开始。 注意，jump命令不会改变当前的程序栈中的内容，所以，当你从一个函数跳到另一个函数时，当函数运行完返回时进行弹栈操作时必然会发生错误，可能结果还是非常奇怪的，甚至于产生程序Core Dump。所以最好是同一个函数中进行跳转。 熟悉汇编的人都知道，程序运行时，有一个寄存器用于保存当前代码所在的内存地址。所以，jump命令也就是改变了这个寄存器中的值。于是，你可以使用set $pc来更改跳转执行的地址。如：set $pc = 0x485 产生信号量 使用singal命令，可以产生一个信号量给被调试的程序。如：中断信号Ctrl+C。这非常方便于程序的调试，可以在程序运行的任意位置设置断点，并在该断点用GDB产生一个信号量，这种精确地在某处产生信号非常有利程序的调试。 语法是：signal ，UNIX的系统信号量通常从1到15。所以取值也在这个范围。 single命令和shell的kill命令不同，系统的kill命令发信号给被调试程序时，是由GDB截获的，而single命令所发出一信号则是直接发给被调试程序的。 强制函数返回 如果你的调试断点在某个函数中，并还有语句没有执行完。你可以使用return命令强制函数忽略还没有执行的语句并返回。 return 使用return命令取消当前函数的执行，并立即返回，如果指定了，那么该表达式的值会被认作函数的返回值。 强制调用函数 call 表达式中可以一是函数，以此达到强制调用函数的目的。并显示函数的返回值，如果函数返回值是void，那么就不显示。 另一个相似的命令也可以完成这一功能——print，print后面可以跟表达式，所以也可以用他来调用函数，print和call的不同是，如果函数返回void，call则不显示，print则显示函数返回值，并把该值存入历史数据中。 在不同语言中使用GDB 下面是几个相关于GDB语言环境的命令： show language 查看当前的语言环境。如果GDB不能识为你所调试的编程语言，那么，C语言被认为是默认的环境。 info frame 查看当前函数的程序语言。 info source 查看当前文件的程序语言。 如果GDB没有检测出当前的程序语言，那么你也可以手动设置当前的程序语言。使用set language命令即可做到。 当set language命令后什么也不跟的话，你可以查看GDB所支持的语言种类： 12345678910111213(gdb) set languageThe currently understood settings are:local or auto Automatic setting based on source filec Use the C languagec++ Use the C++ languageasm Use the Asm languagechill Use the Chill languagefortran Use the Fortran languagejava Use the Java languagemodula-2 Use the Modula-2 languagepascal Use the Pascal languagescheme Use the Scheme language 于是你可以在set language后跟上被列出来的程序语言名，来设置当前的语言环境 资料 参考： https://www.ibm.com/developerworks/cn/linux/sdk/gdb/index.html http://www.cnblogs.com/chengliangsheng/p/3597010.html 深入：http://www.voidcn.com/article/p-gddyzspu-wz.html","categories":[{"name":"Tools","slug":"Tools","permalink":"http://roux.top/categories/Tools/"}],"tags":[{"name":"GDB","slug":"GDB","permalink":"http://roux.top/tags/GDB/"}]},{"title":"centos7 mysql数据库安装和配置","slug":"centos7MySQL安装","date":"2017-11-04T16:00:00.000Z","updated":"2018-04-22T05:44:42.790Z","comments":true,"path":"2017/11/05/centos7MySQL安装/","link":"","permalink":"http://roux.top/2017/11/05/centos7MySQL安装/","excerpt":"前言 在 centos 7 安装 MySQL 时遇见了一些问题，后面按照这篇转载的文章安装成功，而且网上许多的文章都过时了，故在此记录，以备以后使用。 目前我用的是 centos6.9 就不演示了，下面是原文的环境及安装操作。","text":"前言 在 centos 7 安装 MySQL 时遇见了一些问题，后面按照这篇转载的文章安装成功，而且网上许多的文章都过时了，故在此记录，以备以后使用。 目前我用的是 centos6.9 就不演示了，下面是原文的环境及安装操作。 系统环境 yum update升级以后的系统版本为 12[root@yl-web yl]# cat /etc/redhat-releaseCentOS Linux release 7.1.1503 (Core) mysql安装 一般网上给出的资料都是 123#yum install mysql#yum install mysql-server#yum install mysql-devel 安装mysql和mysql-devel都成功，但是安装mysql-server失败，如下： 12345678[root@yl-web yl]# yum install mysql-serverLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * base: mirrors.sina.cn * extras: mirrors.sina.cn * updates: mirrors.sina.cnNo package mysql-server available.Error: Nothing to do 查资料发现是CentOS 7 版本将MySQL数据库软件从默认的程序列表中移除，用mariadb代替了。 有两种解决办法： 方法一：安装mariadb MariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可。开发这个分支的原因之一是：甲骨文公司收购了MySQL后，有将MySQL闭源的潜在风险，因此社区采用分支的方式来避开这个风险。MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。 安装mariadb，大小59 M。 1[root@yl-web yl]# yum install mariadb-server mariadb mariadb数据库的相关命令是： 1234567systemctl start mariadb #启动MariaDBsystemctl stop mariadb #停止MariaDBsystemctl restart mariadb #重启MariaDBsystemctl enable mariadb #设置开机启动 所以先启动数据库 1[root@yl-web yl]# systemctl start mariadb 然后就可以正常使用mysql了 12345678910111213141516171819202122[root@yl-web yl]# mysql -u root -pEnter password: Welcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 3Server version: 5.5.41-MariaDB MariaDB ServerCopyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test |+--------------------+4 rows in set (0.00 sec)MariaDB [(none)]&gt; 安装mariadb后显示的也是 MariaDB [(none)]&gt; ，可能看起来有点不习惯。下面是第二种方法。 方法二：官网下载安装mysql-server 123# wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm# rpm -ivh mysql-community-release-el7-5.noarch.rpm# yum install mysql-community-server 安装成功后重启mysql服务。 1# service mysqld restart 初次安装mysql，root账户没有密码。 12345678910111213141516171819202122232425[root@yl-web yl]# mysql -u root Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 3Server version: 5.6.26 MySQL Community Server (GPL)Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test |+--------------------+4 rows in set (0.01 sec)mysql&gt; 设置密码 1234mysql&gt; set password for &apos;root&apos;@&apos;localhost&apos; =password(&apos;password&apos;);Query OK, 0 rows affected (0.00 sec)mysql&gt; 不需要重启数据库即可生效。 在mysql安装过程中如下内容： 12345678910Installed: mysql-community-client.x86_64 0:5.6.26-2.el7 mysql-community-devel.x86_64 0:5.6.26-2.el7 mysql-community-libs.x86_64 0:5.6.26-2.el7 mysql-community-server.x86_64 0:5.6.26-2.el7Dependency Installed: mysql-community-common.x86_64 0:5.6.26-2.el7Replaced: mariadb.x86_64 1:5.5.41-2.el7_0 mariadb-devel.x86_64 1:5.5.41-2.el7_0 mariadb-libs.x86_64 1:5.5.41-2.el7_0 mariadb-server.x86_64 1:5.5.41-2.el7_0 所以安装完以后mariadb自动就被替换了，将不再生效。 12[root@yl-web yl]# rpm -qa |grep mariadb[root@yl-web yl]# 配置mysql 编码 mysql配置文件为/etc/my.cnf 最后加上编码配置 12[mysql]default-character-set =utf8 这里的字符编码必须和/usr/share/mysql/charsets/Index.xml中一致。 远程连接设置 把在所有数据库的所有表的所有权限赋值给位于所有IP地址的root用户。 1mysql&gt; grant all privileges on *.* to root@&apos;%&apos;identified by &apos;password&apos;; 如果是新用户而不是root，则要先新建用户 1mysql&gt;create user &apos;username&apos;@&apos;%&apos; identified by &apos;password&apos;; 此时就可以进行远程连接了。 总结 时刻关注新的技术与一些重要的工具的版本，及时更新一些文章的错误 出处 转载：http://www.cnblogs.com/starof/p/4680083.html","categories":[{"name":"Database","slug":"Database","permalink":"http://roux.top/categories/Database/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://roux.top/tags/MySQL/"}]},{"title":"看书 & 积累","slug":"看书&积累","date":"2017-11-04T16:00:00.000Z","updated":"2018-04-22T05:56:13.216Z","comments":true,"path":"2017/11/05/看书&积累/","link":"","permalink":"http://roux.top/2017/11/05/看书&积累/","excerpt":"随笔–看书 &amp; 积累 积累 &emsp;&emsp;今天看了一篇关于创作的文章，稍有感触。&emsp;&emsp;文章的作者说自己对自己的输出(包括写博客等)要求比较高(原创、高质量)，所以身边能谈得来的没有几个。看完后，想了想，感觉还是需要分层次与阶段来说的。","text":"随笔–看书 &amp; 积累 积累 &emsp;&emsp;今天看了一篇关于创作的文章，稍有感触。&emsp;&emsp;文章的作者说自己对自己的输出(包括写博客等)要求比较高(原创、高质量)，所以身边能谈得来的没有几个。看完后，想了想，感觉还是需要分层次与阶段来说的。 &emsp;&emsp;一开始，我就想到了我自己。最近的博文有原创的，也有转载的，第一时间就感觉自己的输出太水了。但是转念一想，自己还是一名学生，知识的积累都不够，何谈全部原创输出，更何况高质量。等到知识积累的足够，自然而然的就有了输出的来源，在质量上也就同样的有了保证。&emsp;&emsp;所以说看清自己的位置，多思考，有了自己的判断，再来看待问题也就能够不那么容易动摇亦或冲动了。 看书 &emsp;&emsp;说到积累与思考，顺便分析下最近看书的一些问题。&emsp;&emsp;首先自己对知识的积累大部分通过三个途径：一是看书、二是看视频及看博客、三是与同学和老师交流。这么长时间来，也有些感受了。&emsp;&emsp;就看书简单来说，看书知识全面，而且在看书的过程中做好笔记加强记忆，而且能够让自己有空间独立思考(时刻问自己为什么)。&emsp;&emsp;看视频及博客，学到的知识主要，但是总有种被人牵着鼻子走的感觉，少了自己独立思考的空间(是什么，为什么，这些都已经说清了)，最终发现都听懂了，但是真正自己来做，却是无从下手或者就不会做。&emsp;&emsp;与同学和老师交流，获益多多。但是一般最多与同学交流(能真正说到一起的却寥寥无几)，老师也只是偶尔交流(老师也有事要忙的)。&emsp;&emsp;所以，我在知识积累的路上，从看视频与博客到看书与博客，最终看书与看博客占70%，与同学交流20%，与老师交流10%。也许以后还会用更好的方式，但是目前还在探索。","categories":[{"name":"生活","slug":"生活","permalink":"http://roux.top/categories/生活/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://roux.top/tags/随笔/"}]},{"title":"tee函数","slug":"tee函数","date":"2017-11-02T16:00:00.000Z","updated":"2018-04-22T05:47:39.866Z","comments":true,"path":"2017/11/03/tee函数/","link":"","permalink":"http://roux.top/2017/11/03/tee函数/","excerpt":"tee 说明：在两个管道文件描述符之间复制数据，同是零拷贝。但它不消耗数据，数据被操作之后，仍然可以用于后续操作。 头文件：#define _GNU_SOURCE #include &lt;fcntl.h&gt; 原型：long tee(int fd_in, int fd_out, size_t len, unsigned int flags);","text":"tee 说明：在两个管道文件描述符之间复制数据，同是零拷贝。但它不消耗数据，数据被操作之后，仍然可以用于后续操作。 头文件：#define _GNU_SOURCE #include &lt;fcntl.h&gt; 原型：long tee(int fd_in, int fd_out, size_t len, unsigned int flags); fdin参数：待读取数据的文件描述符。 fdout参数：待写入数据的文件描述符。 len参数：表示复制的数据的长度。 flags参数：同splice函数。 返回值： 返回值&gt;0：表示复制的字节数。 返回0：表示没有复制任何数据。 返回-1：表示失败，并设置errno。 错误代码： EINVAL：fd_in 或者 fd_out 不是管道描述符，或者 fd_in 和 fd_out 是同一个管道描述符。 ENOMEM：Out of memory。 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/*splice()和tee()实现将文件\"./test1.txt\"同时拷贝到文件\"./test2.txt\"和\"./test3.txt\"中*/#define _GNU_SOURCE#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;int main(void)&#123; int fd1 = open(\"./test1.txt\", O_RDONLY); int fd2 = open(\"./test2.txt\", O_RDWR| O_CREAT | O_TRUNC, 0666); int fd3 = open(\"./test3.txt\", O_RDWR| O_CREAT | O_TRUNC, 0666); /*用于向\"./test2.txt\"输入数据*/ int pipefd2[2]; /*用于向\"./test3.txt\"输入数据*/ int pipefd3[2]; int ret; ret = pipe(pipefd2); if(ret &lt; 0) &#123; perror(\"pipe\"); exit(1); &#125; ret = pipe(pipefd3); if(ret &lt; 0) &#123; perror(\"pipe\"); exit(1); &#125; int len; /*将fd1文件的内容输入管道pipefd2中*/ len = splice(fd1, NULL, pipefd2[1], NULL, 1024, SPLICE_F_MORE); if(len &lt; 0)&#123; perror(\"splice\"); exit(1); &#125; /*将管道pipefd2的内容复制到管道pipefd3中，不消耗管道pipefd2上的数据，管道pipefd2上的数据可以用于后续操作*/ tee(pipefd2[0], pipefd3[1], 1024, SPLICE_F_NONBLOCK); /*将管道pipefd2的内容写入fd2文件中*/ len = splice(pipefd2[0], NULL, fd2, NULL, 1024, SPLICE_F_MORE); if(len &lt; 0) &#123; perror(\"splice\"); exit(1); &#125; /*将管道pipefd3的内容写入fd3文件中*/ len = splice(pipefd3[0], NULL, fd3, NULL, 1024, SPLICE_F_MORE); if(len &lt; 0) &#123; perror(\"splice\"); exit(1); &#125; close(fd1); close(fd2); close(fd3); close(pipefd2[0]); close(pipefd2[1]); close(pipefd3[0]); close(pipefd3[1]); return 0;&#125; 1234567891011121314//测试[roux@Vkey 桌面]$ lstee.c test1.txt[roux@Vkey 桌面]$ gcc tee.c[roux@Vkey 桌面]$ ./a.out[roux@Vkey 桌面]$ lsa.out tee.c test1.txt test2.txt test3.txt[roux@Vkey 桌面]$ cat test2.txthello world![roux@Vkey 桌面]$ cat test3.txthello world![roux@Vkey 桌面]$ cat test1.txthello world![roux@Vkey 桌面]$","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"零拷贝","slug":"零拷贝","permalink":"http://roux.top/tags/零拷贝/"}]},{"title":"STDIN_FILENO 的作用及与 stdin 的区别","slug":"STDIN_FILENO","date":"2017-11-02T16:00:00.000Z","updated":"2018-04-22T05:53:43.886Z","comments":true,"path":"2017/11/03/STDIN_FILENO/","link":"","permalink":"http://roux.top/2017/11/03/STDIN_FILENO/","excerpt":"1. STDIN_FILENO 的作用及与 stdin 的区别 STDIN_FILENO的作用 STDIN_FILENO属于系统API接口库，其声明为 int 型，是一个打开文件句柄，对应的函数主要包括 open/read/write/close 等系统级调用。 操作系统一级提供的文件API都是以文件描述符来表示文件。STDIN_FILENO 就是标准输入设备（一般是键盘）的文件描述符。 区别 数据类型不一致： stdin 类型为 FILE* STDIN_FILENO 类型为 int 使用 stdin 的函数主要有：fread、fwrite、fclose等，基本上都以f开头 使用 STDIN_FILENO 的函数有：read、write、close等","text":"1. STDIN_FILENO 的作用及与 stdin 的区别 STDIN_FILENO的作用 STDIN_FILENO属于系统API接口库，其声明为 int 型，是一个打开文件句柄，对应的函数主要包括 open/read/write/close 等系统级调用。 操作系统一级提供的文件API都是以文件描述符来表示文件。STDIN_FILENO 就是标准输入设备（一般是键盘）的文件描述符。 区别 数据类型不一致： stdin 类型为 FILE* STDIN_FILENO 类型为 int 使用 stdin 的函数主要有：fread、fwrite、fclose等，基本上都以f开头 使用 STDIN_FILENO 的函数有：read、write、close等 stdin 等是 FILE * 类型，属于标准I/O，高级的输入输出函数。 STDIN_FILENO 等是文件描述符，是非负整数，一般定义为0, 1, 2，属于没有buffer的I/O，直接调用系统调用，在 #include &lt;unistd.h&gt;。 STDIN_FILENO 是标准输入的文件描述符，详见 /usr/include/unistd.h 1234/* Standard file descriptors. */#define STDIN_FILENO 0 /* Standard input. */#define STDOUT_FILENO 1 /* Standard output. */#define STDERR_FILENO 2 /* Standard error output. */ 层次不一样。 STDIN 属于标准库处理的输入流，其声明为 FILE 型的，对应的函数前面都有f开头，如fopen/fread/fwrite/fclose 标准库调用等 STDIN_FILENO属于系统API接口库，其声明为 int 型，是一个打开文件句柄，对应的函数主要包括 open/read/write/close 等系统级调用。 标准库内封装了系统 API 调用，如 fread 内部实现调用 read。 操作系统一级提供的文件API都是以文件描述符来表示文件。 STDIN_FILENO 就是标准输入设备（一般是键盘）的文件描述符。 2. 出处 在学习网络编程时，看到说明文档里的示例代码遇到，不明白，所以在此记录，留着复习查看 转载：http://blog.csdn.net/yeyuangen/article/details/6781999","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"Others","slug":"Others","permalink":"http://roux.top/tags/Others/"}]},{"title":"splice函数","slug":"splice函数","date":"2017-11-01T16:00:00.000Z","updated":"2018-04-22T05:47:46.241Z","comments":true,"path":"2017/11/02/splice函数/","link":"","permalink":"http://roux.top/2017/11/02/splice函数/","excerpt":"splice 说明：splice函数用于在两个文件描述符(官方文档解释为管道)之间的移动数据 头文件：#define _GNU_SOURCE 1 #include &lt;fcntl.h&gt; #define _GNU_SOURCE 1：一定要放在 #include &lt;fcntl.h&gt; 的前面 因为 #include &lt;fcntl.h&gt; 头文件的加载需要用到，否则会报错，错误在隐式声明 splice 函数，而且对于 splice 函数的flags 参数不识别 原型：long splice(int fd_in, loff_t *off_in, int fd_out, loff_t *off_out, size_t len, unsigned int flags);","text":"splice 说明：splice函数用于在两个文件描述符(官方文档解释为管道)之间的移动数据 头文件：#define _GNU_SOURCE 1 #include &lt;fcntl.h&gt; #define _GNU_SOURCE 1：一定要放在 #include &lt;fcntl.h&gt; 的前面 因为 #include &lt;fcntl.h&gt; 头文件的加载需要用到，否则会报错，错误在隐式声明 splice 函数，而且对于 splice 函数的flags 参数不识别 原型：long splice(int fd_in, loff_t *off_in, int fd_out, loff_t *off_out, size_t len, unsigned int flags); fd_in： 是待输入描述符。 如果它是一个管道文件描述符，则 off_in 必须设置为 NULL； 如果 off_in 不是一个管道文件描述符（比如socket），那么 off_in 表示从输入数据流的何处开始读取数据，此时若为 NULL，则从输入数据流的当前偏移位置读入。 fd_out/off_out： 含义与 fd_in/off_in 相同，不过用于输出数据流。 len：指定移动数据的长度。 flags：则控制数据如何移动，它可以设置成下表中的某些值的按位或。 SPLICE_F_MOVE：如果合适的话，按整页内存移动数据。这只是给内核的一个提示。不过，因为它的实现存在BUG，所以自内核2.6.21后，它实际上没有任何效果 SPLICE_F_NONBLOCK：非阻塞的 splice 操作，但实际效果还会受文件描述符本身的阻塞状态影响 SPLICE_F_MORE：告知操作系统内核下一个 splice 系统调用将会有更多的数据传来 SPLICE_F_GIFT：对 splice 没有效果 注意：使用splice函数时，fd_in和fd_out必须至少有一个是管道文件描述符。 返回值： 返回值&gt;0：表示移动的字节数。 返回0：表示没有数据可以移动。这通常发生在从管道中读数据（fd_in是管道文件描述符）而该管道没有被写入任何数据时。 返回-1；表示失败，并设置errno。 错误代码： EBADF：所指文件描述符有错。 EINVAL：目标文件系统不支持 splice，或者目标文件以追加方式打开，或者两个文件描述符都不是管道描述符，或者某个 offset 参数被用于不支持随机访问的设备（比如字符设备）。 ENOMEM：内存不够。 ESPIPE：某个参数是管道描述符，但其偏移不是NULL。(参数fd_in（或fd_out）是管道文件描述符，而off_in（或off_out）不为NULL) 示例： 由于网上的大多数的代码运行起来都是错误的，对于很多人形成了误导，而且基本上网上的版本都一样，都没测试过。所以本示例会带测试结果，以供参考。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182//使用splice实现聊天功能#define _GNU_SOURCE 1 //很重要，一定放在#include &lt;fcntl.h&gt;前面#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;assert.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;poll.h&gt;#include &lt;fcntl.h&gt;#define BUFFER_SIZE 64int main(int argc, char *argv[])&#123; if( argc &lt;= 2 )&#123; printf( \"usage: %s ip_address port_number！\\n\", basename(argv[0])); exit(1); &#125; const char* ip = argv[1]; int port = atoi(argv[2]); struct sockaddr_in server_address; bzero(&amp;server_address, sizeof( server_address )); server_address.sin_family = AF_INET; inet_pton(AF_INET, ip, &amp;server_address.sin_addr); server_address.sin_port = htons( port ); int sockfd = socket(PF_INET, SOCK_STREAM, 0); assert(sockfd &gt;= 0); if (connect(sockfd, (struct sockaddr*)&amp;server_address, sizeof(server_address)) &lt; 0) &#123; printf( \"connection failed\\n\" ); close( sockfd ); exit(1); &#125; struct pollfd fds[2]; fds[0].fd = 0; fds[0].events = POLLIN; fds[0].revents = 0; fds[1].fd = sockfd; fds[1].events = POLLIN | POLLRDHUP; fds[1].revents = 0; char read_buf[BUFFER_SIZE]; int pipefd[2]; int ret = pipe(pipefd); assert(ret != -1); while(1) &#123; ret = poll(fds, 2, -1); if(ret &lt; 0) &#123; printf(\"poll failure\\n\"); break; &#125; if(fds[1].revents &amp; POLLRDHUP) &#123; printf( \"server close the connection\\n\" ); break; &#125; else if(fds[1].revents &amp; POLLIN) &#123; memset(read_buf, '\\0', BUFFER_SIZE); recv(fds[1].fd, read_buf, BUFFER_SIZE-1, 0); printf( \"%s\\n\", read_buf ); &#125; if(fds[0].revents &amp; POLLIN) &#123; //将输入流的客户端数据定向到管道中 ret = splice(0, NULL, pipefd[1], NULL, 55555, SPLICE_F_MORE | SPLICE_F_MOVE); //将管道的输出定向到sockfd连接文件符上 ret = splice(pipefd[0], NULL, sockfd, NULL, 55555, SPLICE_F_MORE | SPLICE_F_MOVE); &#125; &#125; close( sockfd ); return 0;&#125; 测试(利用 nc -l 来监听一个端口) 123456客户端测试[roux@Vkey test]$ nc -l 5555hello //客户端发送消息i am server //接收服务器的消息^C //结束[roux@Vkey test]$ 1234567服务器测试[roux@Vkey test]$ ./a.out 127.0.0.1 5555hello //接收客户端的消息i am server //服务器发送消息server close the connection //检测到客户端链接关闭[roux@Vkey test]$ - 总结 网上的资料或者代码，一定要亲测通过，否则只是单纯的复制粘贴，这样还不如不写出来","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"零拷贝","slug":"零拷贝","permalink":"http://roux.top/tags/零拷贝/"}]},{"title":"sendfile函数","slug":"sendfile函数","date":"2017-10-30T16:00:00.000Z","updated":"2018-04-22T05:49:32.024Z","comments":true,"path":"2017/10/31/sendfile函数/","link":"","permalink":"http://roux.top/2017/10/31/sendfile函数/","excerpt":"sendfile 说明：sendfile函数在两个文件描述符之间直接传递数据（完全在内核中操作），从而避免了内核缓冲区和用户缓冲区之间的数据拷贝。(一般用于当所传送的文件不需要被用户修改的情况) 头文件：#include &lt;sys/sendfile.h&gt; 原型：ssize_t sendfile(int out_fd,int in_fd, off_t * offset,size_t count);","text":"sendfile 说明：sendfile函数在两个文件描述符之间直接传递数据（完全在内核中操作），从而避免了内核缓冲区和用户缓冲区之间的数据拷贝。(一般用于当所传送的文件不需要被用户修改的情况) 头文件：#include &lt;sys/sendfile.h&gt; 原型：ssize_t sendfile(int out_fd,int in_fd, off_t * offset,size_t count); out_fd：待写入内容的文件描述符。(out_fd可以是任何文件(Linux2.6之后)) in_fd：待读出内容的文件描述符。(in_fd必须是一个支持类似mmap函数的文件描述符，即它必须指向真实的文件(例如用open打开的文件)，不能是socket和管道) offset：指定从读入文件流的哪个位置开始读，如果为空，则使用读入文件流默认的起始位置。 count：指定在文件描述符in_fd和out_fd之间传输的字节数(一般用stat系列函数来获得打开文件的大小)。 错误代码： EAGAIN： 无阻塞I/O设置O_NONBLOCK时,写操作(write)阻塞了. EBADF： 输出或者输入的文件描述符没有打开. EFAULT： 错误的地址. EINVAL： 描述符不可用或者锁定了,或者用mmap()函数操作的in_fd不可用. EIO： 当读取(read)in_fd时发生未知错误. ENOMEM： 读(read)in_fd时内存不足. 返回值：成功，则返回传输的字节数，失败，则返回-1，并设置errno。 与read和write读写函数的区别 系统调用 read() 产生一个上下文切换：从 user mode 切换到 kernel mode，然后 DMA 执行拷贝，把文件数据从硬盘读到一个 kernel buffer 里。 数据从 kernel buffer 拷贝到 user buffer，然后系统调用 read() 返回，这时又产生一个上下文切换：从kernel mode 切换到 user mode。 系统调用 write() 产生一个上下文切换：从 user mode 切换到 kernel mode，然后把步骤2读到 user buffer 的数据拷贝到 kernel buffer（数据第2次拷贝到 kernel buffer），不过这次是个不同的 kernel buffer，这个 buffer 和 socket 相关联。 系统调用 write() 返回，产生一个上下文切换：从 kernel mode 切换到 user mode（第4次切换了），然后 DMA 从 kernel buffer 拷贝数据到协议栈（第4次拷贝了）。 上面4个步骤有4次上下文切换，有4次拷贝，如果能减少切换次数和拷贝次数将会有效提升性能。 sendfile的效率 sendfile系统调用，文件数据被copy至内核缓冲区 再从内核缓冲区copy至内核中socket相关的缓冲区 最后再socket相关的缓冲区copy到协议引擎 示例： 本示例是让服务器把一个文件发送个所连接的客户端(本示例用到了popen函数、select函数、access函数)(其中的部分函数我的博客网络编程分类里就有，select可自行查找) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206/*服务端*/#include&lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;wait.h&gt;#include &lt;errno.h&gt;#include &lt;sys/sendfile.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/stat.h&gt;#define PORT 6000 //定义端口#define LISTENQ 20 //定义最大连接数#define BUFFSIZE 4096 //定义缓冲区大小#define FILE_NAME_MAX_SIZE 512 //定义文件缓冲大小int main(int argc, char *argv[])&#123; char fileName[FILE_NAME_MAX_SIZE]; bzero(fileName, FILE_NAME_MAX_SIZE); printf(\"Please input the file name you want to send: \"); scanf(\"%s\", &amp;fileName); getchar(); if(access(fileName, R_OK) == -1)&#123; //判断文件的权限 printf(\"this file can not read!\\n\"); exit(1); &#125; int sockfd, connfd; struct sockaddr_in serverAddr, clientAddr; bzero(&amp;serverAddr, sizeof(serverAddr)); serverAddr.sin_family = AF_INET; serverAddr.sin_addr.s_addr = htonl(INADDR_ANY); serverAddr.sin_port = htons(PORT); if((sockfd = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0)&#123; perror(\"socket error\"); exit(1); &#125; int reuse = 1; if(setsockopt(sockfd, SOL_SOCKET, SO_REUSEADDR, &amp;reuse, sizeof(reuse)) &lt; 0)&#123; //地址复用 perror(\"setsockopt error\"); exit(1); &#125; if(bind(sockfd, (struct sockaddr*)&amp;serverAddr, sizeof(serverAddr)) &lt; 0)&#123; perror(\"bind error\"); exit(1); &#125; if(listen(sockfd, LISTENQ) &lt; 0)&#123; perror(\"listen error\"); exit(1); &#125; int client[FD_SETSIZE]; //申请数组存放已连接的描述符 memset(client, -1, FD_SETSIZE); fd_set sock_set; //定义连接(读)的事件集合 fd_set write_set; //写的事件集合 int i = 0; int maxfd = sockfd; //最大的描述符个数 int maxi = -1; //存放已连接的数组的下标的最大值 int nready = 0; //就绪事件的个数 while(1)&#123; FD_ZERO(&amp;sock_set); //清空连接(读)事件集合 FD_ZERO(&amp;write_set); FD_SET(sockfd, &amp;sock_set); //设置连接(读)事件 FD_SET(sockfd, &amp;write_set); if((nready = select(maxfd+1, &amp;sock_set, &amp;write_set, NULL, NULL)) &lt; 0)&#123; perror(\"select error\"); exit(1); &#125; if(FD_ISSET(sockfd, &amp;sock_set))&#123; //判断事件是否是连接(读)事件 socklen_t length = sizeof(clientAddr); if((connfd = accept(sockfd, (struct sockaddr*)&amp;clientAddr, &amp;length)) &lt; 0)&#123; //处理连接事件 perror(\"accept error\"); exit(1); &#125; for(i = 0; i &lt; FD_SETSIZE; i++)&#123; if(client[i] &lt; 0)&#123; //将已连接的描述符放进数组 client[i] = connfd; i++; break; &#125; &#125; if(i == FD_SETSIZE)&#123; printf(\"too many clients!\\n\"); exit(1); &#125; FD_SET(connfd, &amp;write_set); //设置新的描述符 if(connfd &gt; maxfd)&#123; //更新最大文件描述符 maxfd = connfd; &#125; if(i &gt; maxi)&#123; //扩充数组的已连接描述符最大下标 maxi = i; &#125; if(--nready &lt; 0)&#123; //判断是否事件处理完 continue; &#125; &#125; for(i = 0; i &lt; maxi; i++)&#123; if(client[i] &lt; 0)&#123; continue; &#125; if(FD_ISSET(client[i], &amp;write_set))&#123; //判断时间是否为写事件 char buff[BUFFSIZE]; int count; bzero(buff, BUFFSIZE); strncpy(buff, fileName, strlen(fileName) &gt; FILE_NAME_MAX_SIZE ? FILE_NAME_MAX_SIZE : strlen(fileName)); //发送文件名 if((count = send(connfd, buff, BUFFSIZE, 0)) &lt; 0)&#123; perror(\"send file information error\"); exit(1); &#125; int filefd = open(fileName, O_RDONLY); struct stat stat_buf; //定义stat结构获取文件大小 fstat(filefd, &amp;stat_buf); //绑定打开的文件 FILE *fd = fdopen(filefd, \"rb\"); if(NULL == fd)&#123; printf(\"File: %s not found!\\n\", fileName); int judge = 1; //定义标识符判断文件是否存在 if(send(connfd, &amp;judge, sizeof(judge), 0) &lt; 0)&#123; perror(\"send judge error\"); exit(1); &#125; close(connfd); exit(1); &#125;else&#123; int judge = 0; if(send(connfd, &amp;judge, sizeof(judge), 0) &lt; 0)&#123; perror(\"send judge error\"); exit(1); &#125; printf(\"\\nstart transfering md5!\\n\"); //发送文件的md5值进行判断 char cmd[BUFFSIZE] = \"md5sum \"; strcat(cmd, fileName); bzero(buff, BUFFSIZE); FILE *stream = popen(cmd, \"r\"); int tmp = 0; if((tmp = fread(buff, sizeof(char), BUFFSIZE, stream)) &lt;= 0)&#123; perror(\"fread md5 error\"); exit(1); &#125; int a = 0; if((a = send(connfd, buff, tmp, 0)) &lt; 0)&#123; perror(\"send md5 error\"); exit(1); &#125; pclose(stream); printf(\"Transfer md5 finished!\\n\"); //发送文件 if(sendfile(connfd, filefd, NULL, stat_buf.st_size) &lt; 0)&#123; perror(\"sendfile error\"); exit(1); &#125; fclose(fd); close(filefd); printf(\"Transfer file finished!\\n\"); &#125; close(client[i]); FD_CLR(client[i], &amp;write_set); //清空已处理的写事件 client[i] = -1; //判断是否还有未处理的写事件 if(--nready &lt;= 0)&#123; break; &#125; &#125; &#125; &#125; return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141/*客户端*//*客户端的代码与服务器的代码相对应，只有接收文件功能，而且是单进程*/#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;strings.h&gt;//#include &lt;sys/select.h&gt;//#include &lt;wait.h&gt;#define PORT 6000#define LISTENQ 20#define BUFFSIZE 4096#define FILE_NAME_MAX_SIZE 512int main(int argc, char *argv[])&#123; int clientfd; if(argc != 2)&#123; fprintf(stderr, \"usage: ./fileclient &lt;IP_Address&gt;\\n\"); exit(1); &#125; struct sockaddr_in clientAddr; bzero(&amp;clientAddr, sizeof(clientAddr)); clientAddr.sin_family = AF_INET; clientAddr.sin_addr.s_addr = htonl(INADDR_ANY); clientAddr.sin_port = htons(PORT); if((clientfd = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0)&#123; perror(\"socket error\"); exit(1); &#125; if(connect(clientfd, (struct sockaddr*)&amp;clientAddr, sizeof(clientAddr)) &lt; 0)&#123; perror(\"connect error\"); exit(1); &#125; char buff[BUFFSIZE]; char fileName[FILE_NAME_MAX_SIZE]; bzero(fileName, FILE_NAME_MAX_SIZE); int count; bzero(buff, BUFFSIZE); if((count = recv(clientfd, buff, BUFFSIZE, 0)) &lt; 0)&#123; perror(\"recv fileName error\"); exit(1); &#125; strncpy(fileName, buff, strlen(buff) &gt; FILE_NAME_MAX_SIZE ? FILE_NAME_MAX_SIZE : strlen(buff)); int judge = 0; if(recv(clientfd, &amp;judge, sizeof(judge), 0) &lt; 0)&#123; perror(\"recv judge error\"); exit(1); &#125; if(judge == 1)&#123; printf(\"the file was not found at server\\n\"); exit(1); &#125; printf(\"Preparing receive file: %s --from-- %s\\n\", fileName, argv[1]); FILE *fd = fopen(fileName, \"wb+\"); if(NULL == fd)&#123; perror(\"open error\"); exit(1); &#125; bzero(buff, BUFFSIZE); printf(\" start receiving md5!\\n\"); char buf[BUFFSIZE]; bzero(buf, BUFFSIZE); if(recv(clientfd, buf, BUFFSIZE, 0) &lt; 0)&#123; perror(\"recv md5 error\"); exit(1); &#125; printf(\"receive md5 finished!\\n\"); int length = 0; while(length = recv(clientfd, buff, BUFFSIZE, 0))&#123; if(length &lt; 0)&#123; perror(\"recv\"); exit(1); &#125; int writeLen = fwrite(buff, sizeof(char), length, fd); if(writeLen &lt; length)&#123; perror(\"write error\"); exit(1); &#125; bzero(buff, BUFFSIZE); &#125; printf(\"Received file: %s --from-- %s!\\n\", fileName, argv[1]); fclose(fd); char cmd[BUFFSIZE] = \"md5sum \"; strcat(cmd, fileName); char mbuf[BUFFSIZE]; bzero(mbuf, BUFFSIZE); FILE *stream = popen(cmd, \"r\"); int tmp = fread(mbuf, sizeof(char), BUFFSIZE, stream); int flag = -1, k = 0; if(buf != NULL &amp;&amp; mbuf != NULL)&#123; for(k = 0; k &lt; tmp; k++)&#123; if(buf[k] != mbuf[k])&#123; flag = 1; break; &#125; flag = 0; &#125; &#125; if(flag == 0)&#123; printf(\"the md5 of this file is same to source\\n\"); &#125;else if(flag == 1)&#123; printf(\"the md5 of this file is different to source\\n\"); &#125;else&#123; printf(\"error!\\n\"); &#125; sleep(10); pclose(stream); close(clientfd); return 0;&#125; 细节优化 详情：http://www.linuxdiyf.com/viewarticle.php?id=69189","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"零拷贝","slug":"零拷贝","permalink":"http://roux.top/tags/零拷贝/"}]},{"title":"没有正确安装GNOME电源管理器解决办法","slug":"Linux磁盘写满","date":"2017-10-28T16:00:00.000Z","updated":"2018-04-22T05:51:14.486Z","comments":true,"path":"2017/10/29/Linux磁盘写满/","link":"","permalink":"http://roux.top/2017/10/29/Linux磁盘写满/","excerpt":"前言 昨天晚上在 centos 上需要解压一个文件(centos装在vmware上)，但是解压到一半就报错说是内存不足，我用 df 查看了下发现根目录已经被写满了，然后由于熄灯了就没有处理。 第二天早上打开 centos 出现错误 没有正确安装GNOME电源管理器 ，导致登陆显示窗体界面，只是黑屏，然后在网上搜了下解决方法，发现大体上就是进入 mini 窗口(也就是黑框)，清除 /tmp 下的东西(也不全是这个目录，主要是留出空间来让系统启动)，然后进行了操作，最终解决！","text":"前言 昨天晚上在 centos 上需要解压一个文件(centos装在vmware上)，但是解压到一半就报错说是内存不足，我用 df 查看了下发现根目录已经被写满了，然后由于熄灯了就没有处理。 第二天早上打开 centos 出现错误 没有正确安装GNOME电源管理器 ，导致登陆显示窗体界面，只是黑屏，然后在网上搜了下解决方法，发现大体上就是进入 mini 窗口(也就是黑框)，清除 /tmp 下的东西(也不全是这个目录，主要是留出空间来让系统启动)，然后进行了操作，最终解决！ 解决步骤 进行登录，然后提示你错误，然后按 ctrl + alt + F1~F7 因为每个人的窗口不一样，所以要 F1 到 F7 下面会进入到 mini 界面，会出现 login 让你登陆，你输入用户名(尽量root，后面操作方便)及密码，登录成功后使用 df -h 查看系统的使用情况，使用 du -h filename/directoryname 查看文件或目录的使用情况 然后根据个人情况进行一些清理工作 比如我的就是 tmp 目录占用很多(tmp目录是一个临时文件存放的目录)，然后进入 tmp 目录执行 rm -rf * (记得备份重要的文件)，然后重启就可以啦！ 重启之后记得给磁盘扩容，及时清理一些垃圾文件","categories":[{"name":"OS","slug":"OS","permalink":"http://roux.top/categories/OS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://roux.top/tags/Linux/"}]},{"title":"关于最近学习的一点思考","slug":"随笔","date":"2017-10-27T16:00:00.000Z","updated":"2018-04-22T05:56:56.191Z","comments":true,"path":"2017/10/28/随笔/","link":"","permalink":"http://roux.top/2017/10/28/随笔/","excerpt":"&emsp;&emsp;晃眼到了大三，所认识的一些同学都已经找到了满意的工作，而我还满足在自己比别人起步早的那么一点扯淡的事情上(比我起步早的大有人在)。","text":"&emsp;&emsp;晃眼到了大三，所认识的一些同学都已经找到了满意的工作，而我还满足在自己比别人起步早的那么一点扯淡的事情上(比我起步早的大有人在)。&emsp;&emsp;意识到这一点的我，一开始并没有就去奋发图强，而是仅仅比以前的状态能努力一点罢了(一直处于对自己想干什么的似懂非懂的状态中)。后面，分到了导师，导师有一些项目想要人去帮忙，原本我以为我可以的，但是我错了。我知道这次没有认清自己，也过于自大了，开始了开学的第一次反思。&emsp;&emsp;也就在那次反思以后，改变了一些作息习惯，驱散了部分迷茫，规划了自己近期的一些事情。学习的过程中，避免不了查资料，发现一些问题以前查过，但是没有做记录而且当时并没有深入了解，导致再次遇到脑子还是一片问号，第二次反思。&emsp;&emsp;反思时，想起了以前在CSDN上写博客的事情(已经好久没更新了)，但是想到CSDN的局限性(我比较喜欢自由)，所以就想着自己搭建博客(当时只知道WordPress)，然后在网上找到了简易的hexo + github搭建教程，就搭了一个(也就是现在这个)。同一时间，看到了一篇文章讲解一些学习的方法(深度学习)，而且看了许多的面经(因为想着明年参加校园实习生招聘)，买了一些专业知识的相关书籍，准备补充自己的知识库。于是 学习 + 思考 + 查资料 + 写博客 的计划就这样。&emsp;&emsp;如今，已经明确了方向，每天思考着，充实着自己。&emsp;&emsp;一颗小草，扎根在肥沃的土壤里，努力地汲取着营养，让自己成长！","categories":[{"name":"生活","slug":"生活","permalink":"http://roux.top/categories/生活/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://roux.top/tags/随笔/"}]},{"title":"dup与dup2详解","slug":"dup与dup2详解","date":"2017-10-27T16:00:00.000Z","updated":"2018-04-22T05:58:05.069Z","comments":true,"path":"2017/10/28/dup与dup2详解/","link":"","permalink":"http://roux.top/2017/10/28/dup与dup2详解/","excerpt":"前言 三个Linux默认的描述符 0：标准输入 1：标准输出 2：标准错误 dup和dup2的作用都是用来复制一个文件的描述符，它们经常用来重定向进程的stdin、stdout和stderr","text":"前言 三个Linux默认的描述符 0：标准输入 1：标准输出 2：标准错误 dup和dup2的作用都是用来复制一个文件的描述符，它们经常用来重定向进程的stdin、stdout和stderr 在 Linux 下，通过 open 打开以文件后，会返回一个文件描述符，文件描述符会指向一个文件表，文件表中的节点指针会指向节点表。 文件描述符表 1234567struct fileDescription &#123; int index; void *pointer;&#125;; 除了整形，还有一个指针，指向文件表，内核为所有打开文件维持一张文件表，每个文件表项包含： 文件状态标志（读、写、添写、同步和非阻塞等） 当前文件的偏移量 指向该文件v节点表项的指针 v节点表中包含了文件所有者、文件长度、文件所在的设备、指向文件实际数据块在磁盘上所在位置的指针等 文件指针是关键，标志两个文件描述符是否一致，看文件指针是否一致即可，如果两个或者多个文件描述符指向同一个文件表，那么对他们的操作是对同一个文件进行操作 文件描述词(下文会用到，等同于文件描述符) 函数 头文件：#include &lt;unistd.h&gt; 原型：int dup (int oldfd); int dup2(int odlfd, int newfd); oldfd：要被复制的文件描述词 newfd：在 dup2 函数中指定的新文件描述词 说明： dup() 用来复制参数 oldfd 所指的文件描述词， 并将它返回。 利用 dup 函数，我们可以复制一个文件描述词，传给该函数一个既有的描述词，它就会返回一个新的描述词，这个新的描述词是传给它的旧描述词的拷贝，这意味着这两个文件描述词共享同一个数据结构，即所有的锁定，读写指针，各项权限和标志位等等。 但复制成功时返回最小的尚未被使用的文件描述词(这点和open函数是一样的)，这个文件描述词指向 oldfd 所拥有的文件表项 dup2() 用来复制参数 oldfd 所指的文件描述词, 并将它拷贝至参数newfd 后一块返回，并不关闭 oldfd。 若参数newfd为一个已打开的文件描述词, 则 newfd 所指的文件会先被关闭。 dup2()所复制的文件描述词, 与原来的文件描述词共享各种文件状态 注：dup2() 相当于先后执行了 close() 函数和 fcntl(oldfd, F_DUPFD, newfd);函数 dup2 函数和先后调用 close 和 fcntl 函数是不一样的，具体在于 dup2 函数关闭文件描述词和进行文件描述词复制这两个操作是作为一个原子操作执行的，是不能被打断的。 返回值：当复制成功时, 则返回最小及尚未使用的文件描述词。 若有错误则返回-1， errno 会存放错误代码 错误代码：EBADF 表示参数 fd 非有效的文件描述词， 或该文件已关闭 区别：dup2 和 dup 的区别就是可以用 newfd 参数指定新描述符的数值，如果 newfd 已经打开，则先将其关闭，如果 newfd 等于 oldfd，则 dup2 返回newfd 而不关闭它 示例： 1234567891011121314151617181920212223242526272829303132333435#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdio.h&gt;int main(int argc, char *argv[])&#123; int fd, copyfd; fd = open(\"test.txt\", O_RDWR | O_CREAT); //复制fd给copyfd copyfd = dup(fd); char buf1[] = \"hello \"; char buf2[] = \"world!\"; //往fd文件写入内容 if (write(fd, buf1, sizeof(buf1)) &lt; 0)&#123; perror(\"write fd\"); &#125; //打印出fd和copyfd的偏移量，经过上面的写操作，都变成7了(写入sizeof(buf1)和sizeof(buf2)的大小为7) printf(\"%d\\n\", (int)lseek(fd, 0, SEEK_CUR)); printf(\"%d\\n\", (int)lseek(copyfd, 0, SEEK_CUR)); //往copyfd写入内容 if (write(copyfd, buf2, sizeof(buf2)) &lt; 0)&#123; perror(\"write copyfd\"); &#125; //打印出fd和copyfd的偏移量，经过上面的写操作，都变成14了(写入buf1和buf2两次，大小为14) printf(\"%d\\n\", (int)lseek(fd, 0, SEEK_CUR)); printf(\"%d\\n\", (int)lseek(copyfd, 0, SEEK_CUR)); return 0;&#125; 1234567891011121314151617181920212223242526#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main()&#123; int pfds[2]; if ( pipe(pfds) == 0 )&#123; //建立一个管道 if ( fork() == 0 )&#123; //子进程关闭stdout端 close(1); dup2( pfds[1], 1 ); //将stdout重定向到管道输入端 close( pfds[0] ); //关闭管道输出端 execlp( \"ls\", \"ls\", \"-1\", NULL ); //执行ls -l命令，输出到管道输入端 &#125;else&#123; //父进程关闭stdin端 close(0); dup2( pfds[0], 0 ); //将stdin重定向到管道输出端 close( pfds[1] ); //关闭管道输入端 execlp( \"wc\", \"wc\", \"-l\", NULL ); //将管道的结果当做输入执行wc -l命令 &#125;else&#123; perror(\"fork\"); &#125; &#125; return 0;&#125; 总结 一开始并没有想写这篇文章，因为简单(不就是两个函数么，而且功能还一样)，但是在我用的过程中，遇到许多的地方不是多么明白，就去查资料，但是多数都是讲解的不全面，对于一些细节还是没有讲到或者过于粗略，所以写下了这篇文章。 本文总结了多数的文章的内容，如有问题请通知我修改，谢谢！ 参考文章 https://baike.baidu.com/item/%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E8%AF%8D http://c.biancheng.net/cpp/html/231.html http://c.biancheng.net/cpp/html/232.html http://www.jianshu.com/p/4a5f71b9bf1d http://10706198.blog.51cto.com/10696198/1775981 http://www.bkjia.com/Linux/357797.html http://www.cnblogs.com/frank-yxs/p/5925628.html http://www.01happy.com/c-dup-dup2/ http://blog.csdn.net/zhouhong1026/article/details/8151235","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"Function","slug":"Function","permalink":"http://roux.top/tags/Function/"}]},{"title":"页缓存page cache和地址空间address_space","slug":"page cache和address_space","date":"2017-10-27T16:00:00.000Z","updated":"2018-04-22T05:52:52.005Z","comments":true,"path":"2017/10/28/page cache和address_space/","link":"","permalink":"http://roux.top/2017/10/28/page cache和address_space/","excerpt":"前言 在学习 mmap 的时候，看到物理地址和进程虚拟地址建立–的映射关系的时候，遇到页缓存 page cache 和地址空间 address_space，不清楚，故查阅资料，学习并做此总结 在 Linux 操作系统中，当应用程序需要读取文件中的数据时，操作系统先分配一些内存，将数据从存储设备读入到这些内存中，然后再将数据分发给应用程序；当需要往文件中写数据时，操作系统先分配内存接收用户数据，然后再将数据从内存写到磁盘上。文件 Cache 管理指的就是对这些由操作系统分配，并用来存储文件数据的内存的管理。 Cache 管理的优劣通过两个指标衡量：一是 Cache 命中率，Cache 命中时数据可以直接从内存中获取，不再需要访问低速外设，因而可以显著提高性能；二是有效 Cache 的比率，有效 Cache 是指真正会被访问到的 Cache 项，如果有效 Cache 的比率偏低，则相当部分磁盘带宽会被浪费到读取无用 Cache 上，而且无用 Cache 会间接导致系统内存紧张，最后可能会严重影响性能","text":"前言 在学习 mmap 的时候，看到物理地址和进程虚拟地址建立–的映射关系的时候，遇到页缓存 page cache 和地址空间 address_space，不清楚，故查阅资料，学习并做此总结 在 Linux 操作系统中，当应用程序需要读取文件中的数据时，操作系统先分配一些内存，将数据从存储设备读入到这些内存中，然后再将数据分发给应用程序；当需要往文件中写数据时，操作系统先分配内存接收用户数据，然后再将数据从内存写到磁盘上。文件 Cache 管理指的就是对这些由操作系统分配，并用来存储文件数据的内存的管理。 Cache 管理的优劣通过两个指标衡量：一是 Cache 命中率，Cache 命中时数据可以直接从内存中获取，不再需要访问低速外设，因而可以显著提高性能；二是有效 Cache 的比率，有效 Cache 是指真正会被访问到的 Cache 项，如果有效 Cache 的比率偏低，则相当部分磁盘带宽会被浪费到读取无用 Cache 上，而且无用 Cache 会间接导致系统内存紧张，最后可能会严重影响性能 在Linux 2.4内核中块缓存 buffer cache 和页缓存 page cache 是并存的，表现的现象是同一份文件的数据，可能即出现在 buffer cache中，又出现在页缓存中，这样就造成了物理内存的浪费。 Linux 2.6内核对两个 cache 进行了合并，统一使用页缓存在做缓存，只有极少数的情况下才使用到 buffer cache 每一个 Page Cache 包含若干 Buffer Cache 内存管理系统和 VFS(virtual file system) 只与 Page Cache 交互，内存管理系统负责维护每项 Page Cache 的分配和回收，同时在使用 memory map 方式访问时负责建立映射；VFS 负责 Page Cache 与用户空间的数据交换。而具体文件系统则一般只与 Buffer Cache 交互，它们负责在外围存储设备和 Buffer Cache 之间交换数据 buffer cache和page cache的区别 我们要理解的是不管是buffer cache还是page cache都是为了处理块设备和内存交互时高速访问的问题 buffer cache是面向底层块设备的，所以它的粒度是文件系统的块，块设备和系统采用块进行交互。块再转换成磁盘的基本物理结构扇区。扇区的大小是512KB，而文件系统的块一般是2KB, 4KB, 8KB。扇区和块之间是可以快速转换的 随着内核的功能越来越完善，块粒度的缓存已经不能满足性能的需要。内核的内存管理组件采用了比文件系统的块更高级别的抽象，页page，页的大小一般从4KB到2MB,粒度更大，处理的性能更高。所以缓存组件为了和内存管理组件更好地交互，创建了页缓存page cache来代替原来的buffer cache 页缓存是面向文件，面向内存的。通过一系列的数据结构，比如inode, address_space, page，将一个文件映射到页的级别，通过page + offset就可以定位到一个文件的具体位置 buffer cache实际操作时按块为基本单位，page cache操作时按页为基本单位，新建了一个BIO的抽象，可以同时处理多个非连续的页的IO操作，也就是所谓的scatter/gather IO buffer cache目前主要用在需要按块传输的场景下，比如超级块的读写等。而 page cache 可以用在所有以文件为单元的场景下，比如网络文件系统等等，缓存组件抽象了地址空间 address_space 这个概念来作为文件系统和页缓存的中间适配器，屏蔽了底层设备的细节 buffer cache 可以和 page cache 集成在一起，属于一个 page 的块缓存使用 buffer_head 链表的方式组织，page_cache 维护了一个private 指针指向这个 buffer_head 链表，buffer_head 链表维护了一个指针指向这个页 page。这样只需要在页缓存中存储一份数据即可 文件系统的 inode 实际维护了这个文件所有的块 block 的块号，通过对文件偏移量 offset 取模可以很快定位到这个偏移量所在的文件系统的块号，磁盘的扇区号。同样，通过对文件偏移量 offset 进行取模可以计算出偏移量所在的页的偏移量，地址空间 address_space 通过指针可以方便的获取两端 inode 和 page 的信息，所以可以很方便地定位到一个文件的offset 在各个组件中的位置 文件字节偏移量 –&gt; 页偏移量 –&gt; 文件系统块号 block –&gt; 磁盘扇区号 - 页缓存page cache和地址空间address_space page_cache page cache 是面向内存，面向文件的，这正好说明了页缓存的作用，它位于内存和文件之间，文件IO操作实际上只和页缓存交互，不直接和内存交互 Linux内核使用 page 数据结构来描述物理内存页帧，内核创建了mem_map 数组来表示所有的物理页帧，mem_map 的数组项就是 page 12345678910struct page&#123; unsigned long flags; atomic_t _count; atomic_t _mapcount; unsigned long private; struct address_space *mapping; pgoff_t index; struct list_head lru; void *virtual;&#125;; 参数： 一些标志位flags来表示该页是否是脏页，是否正在被写回等等 _count, _mapcount表示这个页被多少个进程使用和映射 private指针指向了这个页对应的buffer cache的buffer_head链表，建立了页缓存和块缓存的联系 mapping指向了地址空间address_space，表示这个页是一个页缓存中页，和一个文件的地址空间对应 index是这个页在文件中的页偏移量，通过文件的字节偏移量可以计算出文件的页偏移量 页缓存实际上就是采用了一个基数树结构将一个文件的内容组织起来存放在物理内存page中。文件IO操作直接和页缓存交互。采用缓存原理来管理块设备的IO操作 12345struct radix_tree_root&#123; unsigned int height; gfp_t gfp_mask; struct radix_tree_root *rnode;&#125;; 文件的每个数据块最多只能对应一个 Page Cache 项，它通过两个数据结构来管理这些 Cache 项，一个是 radix tree(一种搜索树，来快速定位 Cache 项)，另一个是双向链表(active_list 和 inactive_list 两个双向链表，实现物理内存的回收) 一个文件inode对应一个地址空间address_space。而一个address_space对应一个页缓存基数树，这几个组件的关系如下: address_space address_space 是Linux内核中的一个关键抽象，它是页缓存和外部设备中文件系统的桥梁，可以说关联了内存系统和文件系统，文件系统可以理解成数据源 inode 指向这个地址空间的宿主，也就是数据源 page_tree 指向了这个地址空间对应的页缓存的基数树。这样就可以通过inode --&gt; address_space --&gt; page_tree找打一个文件对应的页缓存页 1234567891011121314struct address_space&#123; struct inode *host; //所有者：inode或块设备 struct radix_tree_root page_tree; //所有页的基数树 unsigned int i_mmap_wrutable; //VM_SHAREAD映射的计数 struct prio_tree_root i_mmap; //私有和共享映射的树 struct list_head i_mmap_nonlinear; //VM_NONLINEAR映射的链表元素 unsigned long nrpages; //页的总数 pgoff_t writeback_index; //回写由此开始 struct address_space_operations *a_ops; //方法，即地址空间操作 unsigned long flags; //错误标志位/gfp掩码 struct backing_dev_info *backing_dev_info;//设备预读 struct list_head; private_list; struct address_space private_list;&#125; __attribute__((aligned(sizeof(long)))); 读文件时，首先通过要读取的文件内容的偏移量offset计算出要读取的页，然后通过该文件的inode找到这个文件对应的地址空间address_space，然后在address_space中访问该文件的页缓存，如果页缓存命中，那么直接返回文件内容，如果页缓存缺失，那么产生一个页缺失异常，创业一个页缓存页，然后从磁盘中读取相应文件的页填充该缓存页，租后从页缺失异常中恢复，继续往下读 写文件时，首先通过所写内容在文件中的偏移量计算出相应的页，然后还是通过inode找到address_space,通过address_space找到页缓存中页，如果页缓存命中，直接把文件内容修改更新在页缓存的页中。写文件就结束了。这时候文件修改位于页缓存，并没有写回writeback到磁盘文件中去 一个页缓存中的页如果被修改，那么会被标记成脏页。脏页需要写回到磁盘中的文件块。有两种方式可以把脏页写回磁盘，也就是flush 手动调用sync()或者fsync()系统调用把脏页写回 pdflush进程会定时把脏页写回到磁盘 脏页不能被置换出内存，如果脏页正在被写回，那么会被设置写回标记，这时候该页就被上锁，其他写请求被阻塞直到锁释放 在某些情况下我们可能需要绕过页缓存机制，比如系统存在大日志的情况，比如数据库系统，日志不会被经常重复读取，如果都缓存在内存中会影响系统的性能。内核提供了直接IO的方式，O_DIRECT,可以绕过页缓存，直接把文件内容从堆中写到磁盘文件 普通文件IO需要复制两次，第一次复制是从磁盘到内存缓冲区，第二次是从内存缓冲区到进程的堆 从磁盘中读取文件相应的页填充页缓存中的页，也就是第一次复制 从页缓存的页复制内容到文件进程的堆空间的内存中，也就是第二次复制 最后物理内存同一个文件的内容存在了两份拷贝，一份是页缓存，一份是用户进程的堆空间对应的物理内存空间 总结 用户进程访问内存只能通过页表结构，内核可以通过虚拟地址直接访问物理内存。 用户进程不能访问内核的地址空间，这里的地址空间指的是虚拟地址空间，这是肯定的，因为用户进程的虚拟地址空间和内核的虚拟地址空间是不重合的，内核虚拟地址空间必须特权访问 page结构表示物理内存页帧，同一个物理内存地址可以同时被内核进程和用户进程访问，只要将用户进程的页表项也指向这个物理内存地址。也就是mmap的实现原理 参考文章 http://blog.csdn.net/iter_zc/article/details/44195731 https://www.ibm.com/developerworks/cn/linux/l-cache/index.html","categories":[{"name":"OS","slug":"OS","permalink":"http://roux.top/categories/OS/"}],"tags":[{"name":"Memory","slug":"Memory","permalink":"http://roux.top/tags/Memory/"}]},{"title":"linux查看多线程运行状态","slug":"linux查看多线程运行状态","date":"2017-10-26T16:00:00.000Z","updated":"2018-04-22T05:58:29.763Z","comments":true,"path":"2017/10/27/linux查看多线程运行状态/","link":"","permalink":"http://roux.top/2017/10/27/linux查看多线程运行状态/","excerpt":"前言 最近学习网络编程，在进线程这部分遇到了一些问题： 不知道堆栈的调用情况 不知道多线程的运行状态 因此进行了知识的普及(这里参考了不少的网上博客的见解，进行了整合以及测试)，如下：","text":"前言 最近学习网络编程，在进线程这部分遇到了一些问题： 不知道堆栈的调用情况 不知道多线程的运行状态 因此进行了知识的普及(这里参考了不少的网上博客的见解，进行了整合以及测试)，如下： proc查看 查看status文件 命令：cat /proc/1/status 注：命令中的 1 是想要查看的进程的 pid 查看sched文件 命令：cat /proc/1/sched 注：同上 查看线程的具体情况 命令：ls /proc/1/task 注：task下是以线程id 值命名的目录，可以使用ls |wc 统计出的值和上面两种方式查出的结果一样。进入各线程id的目录，可以查看具体线程的资源信息 注：上面查看文件的方法，主要是对单进程的线程统计。如像统计apache、nginx、zabbix这类程序会同时开启N个进程。如果要统计这类程序的线程数，就是所有进程下的线程数的之和 pstree 说明：这个命令可以看到当前运行的线程树 命令：pstree 注：如果想查看某个进程的详细线程情况，可以使用pstree -p &lt;pid&gt;的方法： ps 说明：ps关于线程的参数 12345H Show threads as if they were processes-L Show threads, possibly with LWP and NLWP columns-T Show threads, possibly with SPID columnm Show threads after processes-m Show threads after processes 关键参数 -L 参数显示进程，并尽量显示其LWP( LWP为轻量级进程（即：线程），(light weight process, or thread) )(线程ID)和NLWP(线程的个数) ps -eLf | grep &lt;name&gt; -T 参数可以开启线程查看 ps -T -p &lt;pid&gt; top 说明：top命令可以实时显示各个线程情况 使用： 在top命令后，按H键；或者top -H 表示根据线程信息来显示 在top中也可以查看进程（或线程）在哪个CPU上执行的，执行top后，按 f，然后按 j（选中* J: P = Last used cpu (SMP)），然后按空格或回车退出设置，在 top 的显示中会多出 P 这一列是最近一次运行该线程（或进程）的CPU pstack 说明：pstack 是一个栈跟踪命令，可以显示线程信息 使用： 知道名字 用pgrep process_name来得到进程的 pid 然后运行：pstack pid 或者直接运行：pstack $(pgrep process_name) 知道 pid 运行：pstack pid","categories":[{"name":"OS","slug":"OS","permalink":"http://roux.top/categories/OS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://roux.top/tags/Linux/"}]},{"title":"mmap函数","slug":"mmap函数详解","date":"2017-10-26T16:00:00.000Z","updated":"2018-04-22T05:52:10.520Z","comments":true,"path":"2017/10/27/mmap函数详解/","link":"","permalink":"http://roux.top/2017/10/27/mmap函数详解/","excerpt":"前言 共享内存可以说是最有用的进程间通信方式，也是最快的 IPC 形式, 因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据: 一次从输入文件到共享内存区，另一次从共享内存区到输出文件。 实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。","text":"前言 共享内存可以说是最有用的进程间通信方式，也是最快的 IPC 形式, 因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据: 一次从输入文件到共享内存区，另一次从共享内存区到输出文件。 实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。 内存映射，简而言之就是将内核空间的一段内存区域映射到用户空间。映射成功后，用户对这段内存区域的修改可以直接反映到内核空间，相反，内核空间对这段区域的修改也直接反映用户空间。那么对于内核空间与用户空间两者之间需要大量数据传输等操作的话效率是非常高的。当然，也可以将内核空间的一段内存区域同时映射到多个进程，这样还可以实现进程间的共享内存通信。 系统调用mmap()就是用来实现上面说的内存映射。最长见的操作就是文件（在Linux下设备也被看做文件）的操作，可以将某文件映射至内存(进程空间)，如此可以把对文件的操作转为对内存的操作，以此避免更多的lseek()与read()、write()操作，这点对于大文件或者频繁访问的文件而言尤其受益。 mmap概念 mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。如下图所示： 由上图可以看出，进程的虚拟地址空间，由多个虚拟内存区域构成。虚拟内存区域是进程的虚拟地址空间中的一个同质区间，即具有同样特性的连续地址范围。上图中所示的text数据段（代码段）、初始数据段、BSS数据段、堆、栈和内存映射，都是一个独立的虚拟内存区域。而为内存映射服务的地址空间处在堆栈之间的空余部分。 mmap调用步骤： 首先，应用程序调用mmap，陷入到内核中后调用do_mmap_pgoff。 该函数从应用程序的地址空间中分配一段区域作为映射的内存地址，并使用一个VMA（vm_area_struct）结构代表该区域，之后就返回到应用程序。 当应用程序访问mmap所返回的地址指针时，由于虚实映射尚未建立，会触发缺页中断。之后系统会调用缺页中断处理函数，在缺页中断处理函数中，内核通过相应区域的VMA结构判断出该区域属于文件映射，于是调用具体文件系统的接口读入相应的 Page Cache 项，并填写相应的虚实映射表。 经过这些步骤之后，应用程序就可以正常访问相应的内存区域了。 linux内核使用vm_area_struct结构来表示一个独立的虚拟内存区域，由于每个不同质的虚拟内存区域功能和内部机制都不同，因此一个进程使用多个vm_area_struct结构来分别表示不同类型的虚拟内存区域。各个vm_area_struct结构使用链表或者树形结构链接，方便进程快速访问，如下图所示： vm_area_struct结构中包含区域起始和终止地址以及其他相关信息，同时也包含一个vm_ops指针，其内部可引出所有针对这个区域可以使用的系统调用函数。这样，进程对某一虚拟内存区域的任何操作需要用要的信息，都可以从vm_area_struct中获得。mmap函数就是要创建一个新的vm_area_struct结构，并将其与文件的物理磁盘地址相连。 vm_area_struct结构如下： 12345678910111213141516171819202122232425262728#include &lt;linux/mm_types.h&gt;/* This struct defines a memory VMM memory area. */struct vm_area_struct &#123;struct mm_struct * vm_mm; /* VM area parameters */unsigned long vm_start;unsigned long vm_end;/* linked list of VM areas per task, sorted by address */struct vm_area_struct *vm_next;pgprot_t vm_page_prot;unsigned long vm_flags;/* AVL tree of VM areas per task, sorted by address */short vm_avl_height;struct vm_area_struct * vm_avl_left;struct vm_area_struct * vm_avl_right;/* For areas with an address space and backing store,vm_area_struct *vm_next_share;struct vm_area_struct **vm_pprev_share;struct vm_operations_struct * vm_ops;unsigned long vm_pgoff; /* offset in PAGE_SIZE units, *not* PAGE_CACHE_SIZE */struct file * vm_file;unsigned long vm_raend;void * vm_private_data; /* was vm_pte (shared mem) */&#125;; mmap内存映射原理 在用户虚拟地址空间中寻找空闲的满足要求的一段连续的虚拟地址空间,为映射做准备(由内核mmap系统调用完成) 进程在用户空间调用库函数mmap，原型：void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset); 在当前进程的虚拟地址空间中，寻找一段空闲的满足要求的连续的虚拟地址 为此虚拟区分配一个vm_area_struct结构，接着对这个结构的各个域进行了初始化 将新建的虚拟区结构（vm_area_struct）插入进程的虚拟地址区域链表或树中 解释(假设每个进程拥有2G字节的用户虚存空间)： 虚存空间最终得映射到某个物理存储空间（内存或磁盘空间），才真正可以使用，所以这2G的范围内不可以任意使用 因为用户进程经过编译、链接后形成的映象文件有一个代码段和数据段（包括data段和bss段），这些空间(包括堆栈的空间)是在建立一个进程的运行映像时就分配好的，所以内核需要一个能表示这个区域的东西 在内核中,这样每个区域用一个结构struct vm_area_struct 来表示.它描述的是一段连续的、具有相同访问属性的虚存空间，该虚存空间的大小为物理内存页面的整数倍。可以使用 cat /proc//maps来查看一个进程的内存使用情况,pid是进程号.其中显示的每一行对应进程的一个vm_area_struct结构 通常，进程所使用到的虚存空间不连续，且各部分虚存空间的访问属性也可能不同。所以一个进程的虚存空间需要多个vm_area_struct结构来描述。在vm_area_struct结构的数目较少的时候，各个vm_area_struct按照升序排序，以单链表的形式组织数据（通过vm_next指针指向下一个vm_area_struct结构）。点击查看 但是当vm_area_struct结构的数据较多的时候，仍然采用链表组织的化，势必会影响到它的搜索速度。针对这个问题，vm_area_struct还添加了vm_avl_hight（树高）、vm_avl_left（左子节点）、vm_avl_right（右子节点）三个成员来实现AVL树，以提高vm_area_struct的搜索速度。 调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系(设备驱动完成) 为映射分配了新的虚拟地址区域后，通过待映射的文件指针，在文件描述符表中找到对应的文件描述符，通过文件描述符，链接到内核“已打开文件集”中该文件的文件结构体（struct file），每个文件结构体维护着和这个已打开文件相关各项信息。 通过该文件的文件结构体，链接到file_operations模块，调用内核函数 mmap，其原型为：int mmap(struct file *, struct vm_area_struct *)，不同于用户空间库函数。 内核mmap函数通过虚拟文件系统inode模块定位到文件磁盘物理地址。 通过remap_pfn_range函数建立页表，即实现了文件地址和虚拟地址区域的映射关系。此时，这片虚拟地址并没有任何数据关联到主存中。(Linux有2个方法建立页表) 使用 remap_pfn_range 一次建立所有页表 原型：int remap_pfn_range(struct vm_area_struct *vma, unsigned long virt_addr, unsigned long pfn, unsigned long size, pgprot_t prot); vma 用户进程创建一个vma区域 virt_addr 重新映射应当开始的用户虚拟地址. 这个函数建立页表为这个虚拟地址范围从 virt_addr 到 virt_addr_size. pfn 页帧号, 对应虚拟地址应当被映射的物理地址. 这个页帧号简单地是物理地址右移 PAGE_SHIFT 位. 对大部分使用, VMA 结构的 vm_paoff 成员正好包含你需要的值. size 正在被重新映射的区的大小, 以字节. prot 给新 VMA 要求的”protection”. 驱动可(并且应当)使用在 vma-&gt;vm_page_prot 中找到的值. 返回值：成功返回 0, 失败返回一个负的错误值 使用 nopage VMA方法每次建立一个页表项 原型：struct page *(*nopage)(struct vm_area_struct *vma, unsigned long address, int *type); address 代表从用户空间传过来的用户空间虚拟地址. 返回值：成功则返回一个有效映射页,失败返回NULL 使用方面的限制 remap_pfn_range不能映射常规内存，只存取保留页和在物理内存顶之上的物理地址。因为保留页和在物理内存顶之上的物理地址内存管理系统的各个子模块管理不到。640 KB 和 1MB 是保留页可能映射，设备I/O内存也可以映射。 如果想把kmalloc()申请的内存映射到用户空间，则可以通过mem_map_reserve()把相应的内存设置为保留后就可以。 进程发起对这片映射空间的访问(由缺页中断完成)，实现文件内容到物理内存（主存）的拷贝 前两个阶段仅在于创建虚拟区间并完成地址映射，但是并没有将任何文件数据的拷贝至主存，真正的文件读取是当进程发起读或写操作时 进程的读或写操作访问虚拟地址空间这一段映射地址，通过查询页表，发现这一段地址并不在物理页面上。因为目前只建立了地址映射，真正的硬盘数据还没有拷贝到内存中，因此引发缺页异常。 page cache及swap cache中页面的区分：一个被访问文件的物理页面都驻留在page cache或swap cache中，一个页面的所有信息由struct page来描述。struct page中有一个域为指针mapping ，它指向一个struct address_space类型结构。page cache或swap cache中的所有页面就是根据address_space结构以及一个偏移量来区分的。 文件与 address_space 结构的对应：一个具体的文件在打开后，内核会在内存中为之建立一个struct inode结构，其中的 i_mapping 域指向一个 address_space 结构。这样，一个文件就对应一个address_space 结构，一个 address_space 与一个偏移量能够确定一个 page cache 或 swap cache 中的一个页面。因此，当要寻址某个数据时，很容易根据给定的文件及数据在文件内的偏移量而找到相应的页面。 进程调用 mmap() 时，只是在进程空间内新增了一块相应大小的缓冲区，并设置了相应的访问标识，但并没有建立进程空间到物理页面的映射。因此，第一次访问该空间时，会引发一个缺页异常。 缺页异常进行一系列判断，确定无非法操作后，内核发起请求调页过程。 调页过程先在交换缓存空间（swap cache）中寻找需要访问的内存页，如果找到，则直接返回地址。如果没有找到，则判断该页是否在交换区 (swap area)，如果在，则执行一个换入操作。如果上述两种情况都不满足，处理程序将分配新的物理页面，并把它插入到page cache中。进程最终将更新进程页表。(使用 nopage 函数) 之后进程即可对这片主存进行读或者写的操作，如果写操作改变了其内容，一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程。 注： 对于映射普通文件情况（非共享映射），缺页异常处理程序首先会在 page cache 中根据 address_space 以及数据偏移量寻找相应的页面。如果没有找到，则说明文件数据还没有读入内存，处理程序会从磁盘读入相应的页面，并返回相应地址，同时，进程页表也会更新. 注： 修改过的脏页面并不会立即更新回文件中，而是有一段时间的延迟，可以调用msync()来强制同步, 这样所写的内容就能立即保存到文件里了。 mmap函数 说明：mmap()用来将某个文件内容映射到内存中，对该内存区域的存取即是直接对该文件内容的读写 头文件：#include &lt;unistd.h&gt; #include &lt;sys/mman.h&gt; 原型：void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offsize); start：指向欲对应的内存起始地址，通常设为NULL，代表让系统自动选定地址，对应成功后该地址会返回 length：代表将文件中多大的部分对应到内存 prot：代表映射区域的保护方式 PROT_EXEC 映射区域可被执行； PROT_READ 映射区域可被读取； PROT_WRITE 映射区域可被写入； PROT_NONE 映射区域不能存取。 flags：会影响映射区域的各种特性 MAP_FIXED 如果参数 start 所指的地址无法成功建立映射时，则放弃映射，不对地址做修正。通常不鼓励用此旗标。 MAP_SHARED 对应射区域的写入数据会复制回文件内，而且允许其他映射该文件的进程共享。 MAP_PRIVATE 对应射区域的写入操作会产生一个映射文件的复制，即私人的”写入时复制” (copy on write)对此区域作的任何修改都不会写回原来的文件内容。 MAP_ANONYMOUS 建立匿名映射，此时会忽略参数fd，不涉及文件，而且映射区域无法和其他进程共享。 MAP_DENYWRITE 只允许对应射区域的写入操作，其他对文件直接写入的操作将会被拒绝。 MAP_LOCKED 将映射区域锁定住，这表示该区域不会被置换(swap)。 注：在调用mmap()时必须要指定MAP_SHARED 或MAP_PRIVATE fd：open()返回的文件描述词，代表欲映射到内存的文件 offset：文件映射的偏移量，通常设置为0，代表从文件最前方开始对应，offset必须是分页大小的整数倍 返回值：若映射成功则返回映射区的内存起始地址，否则返回MAP_FAILED(-1)，错误原因存于errno 中 错误代码： EBADF 参数fd 不是有效的文件描述词。 EACCES 存取权限有误。如果是 MAP_PRIVATE 情况下文件必须可读，使用 MAP_SHARED 则要有 PROT_WRITE 以及该文件要能写入。 EINVAL 参数 start、length 或 offset 有一个不合法。 EAGAIN 文件被锁住，或是有太多内存被锁住。 ENOMEM 内存不足。 系统调用mmap()用于共享内存的两种方式 使用普通文件提供的内存映射 适用于任何进程之间 需要打开或创建一个文件，然后再调用mmap() 示例： 123456789101112131415161718192021#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/mman.h&gt;int main(void)&#123; /*利用mmap()来读取/etc/passwd 文件内容*/ int fd; void *start; struct stat sb; fd = open(\"/etc/passwd\", O_RDONLY); /*打开/etc/passwd */ fstat(fd, &amp;sb); /* 取得文件大小 */ start = mmap(NULL, sb.st_size, PROT_READ, MAP_PRIVATE, fd, 0); if(start == MAP_FAILED) /* 判断是否映射成功 */ return; printf(\"%s\", start); munmap(start, sb.st_size); /* 解除映射 */ closed(fd); return 0;&#125; 通过mmap()实现共享内存的通信 适用于具有亲缘关系的进程之间 由于父子进程特殊的亲缘关系，在父进程中先调用 mmap()，然后调用 fork()。那么在调用 fork() 之后，子进程继承父进程匿名映射后的地址空间，同样也继承 mmap() 返回的地址，这样，父子进程就可以通过映射区域进行通信了 一般来说，子进程单独维护从父进程继承下来的一些变量。而 mmap() 返回的地址，却由父子进程共同维护。 对于具有亲缘关系的进程实现共享内存最好的方式应该是采用匿名内存映射的方式。此时，不必指定具体的文件，只要设置相应的标志即可 进程 A 和 B 共享内存示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/*进程A*/#include &lt;sys/mman.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;error.h&gt;#define BUF_SIZE 100int main(int argc, char **argv)&#123; int fd, nread, i; struct stat sb; char *mapped, buf[BUF_SIZE]; for (i = 0; i &lt; BUF_SIZE; i++)&#123; buf[i] = '#'; &#125; /* 打开文件 */ if ((fd = open(argv[1], O_RDWR)) &lt; 0)&#123; perror(\"open\"); &#125; /* 获取文件的属性 */ if ((fstat(fd, &amp;sb)) == -1) &#123; perror(\"fstat\"); &#125; /* 将文件映射至进程的地址空间 */ if ((mapped = (char *)mmap(NULL, sb.st_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0)) == (void *)-1)&#123; perror(\"mmap\"); &#125; /* 文件已在内存, 关闭文件也可以操纵内存 */ close(fd); /* 每隔两秒查看存储映射区是否被修改 */ while (1)&#123; printf(\"%s\\n\", mapped); sleep(2); &#125; return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445/*进程B*/#include &lt;sys/mman.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;error.h&gt;#define BUF_SIZE 100int main(int argc, char **argv)&#123; int fd, nread, i; struct stat sb; char *mapped, buf[BUF_SIZE]; for (i = 0; i &lt; BUF_SIZE; i++)&#123; buf[i] = '#'; &#125; /* 打开文件 */ if ((fd = open(argv[1], O_RDWR)) &lt; 0)&#123; perror(\"open\"); &#125; /* 获取文件的属性 */ if ((fstat(fd, &amp;sb)) == -1)&#123; perror(\"fstat\"); &#125; /* 私有文件映射将无法修改文件 */ if ((mapped = (char *)mmap(NULL, sb.st_size, PROT_READ | PROT_WRITE, MAP_PRIVATE, fd, 0)) == (void *)-1)&#123; perror(\"mmap\"); &#125; /* 映射完后, 关闭文件也可以操纵内存 */ close(fd); /* 修改一个字符 */ mapped[20] = '9'; return 0;&#125; 匿名映射实现父子进程通信示例： 1234567891011121314151617181920212223242526272829#include &lt;sys/mman.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#define BUF_SIZE 100int main(int argc, char** argv)&#123; char *p_map; /* 匿名映射,创建一块内存供父子进程通信 */ p_map = (char *)mmap(NULL, BUF_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS, -1, 0); if(fork() == 0)&#123; sleep(1); printf(\"child got a message: %s\\n\", p_map); sprintf(p_map, \"%s\", \"hi, dad, this is son\"); munmap(p_map, BUF_SIZE); //实际上，进程终止时，会自动解除映射。 exit(0); &#125; sprintf(p_map, \"%s\", \"hi, this is father\"); sleep(2); printf(\"parent got a message: %s\\n\", p_map); return 0;&#125; 相关函数 munmap函数 说明：munmap()用来取消参数start 所指的映射内存起始地址，参数length 则是欲取消的内存大小。当进程结束或利用exec 相关函数来执行其他程序时，映射内存会自动解除，但关闭对应的文件描述词时不会解除映射 头文件：#include &lt;unistd.h&gt; #include &lt;sys/mman.h&gt; 原型：int munmap(void *start, size_t length); 返回值：如果解除映射成功则返回0，否则返回－1，错误原因存于errno 中 错误代码EINVAL参数 start 或length 不合法 msync函数 说明：进程在映射空间的对共享内容的改变并不直接写回到磁盘文件中，往往在调用munmap()后才执行该操作。可以通过调用msync()函数来实现磁盘文件内容与共享内存一致，即同步操作。 头文件：#include &lt;sys/mman.h&gt; 原型：int msync(void *addr, size_t len, int flags); addr：文件映射到进程空间的地址 len：映射空间的大小 flags：刷新的参数设置 MS_ASYNC（异步）： 调用会立即返回，不等到更新的完成； MS_SYNC（同步）： 调用会等到更新完成之后返回； MS_INVALIDATE（通知使用该共享区域的进程，数据已经改变）： 在共享内容更改之后，使得文件的其他映射失效，从而使得共享该文件的其他进程去重新获取最新值 返回值：成功则返回0；失败则返回-1 示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;sys/mman.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;error.h&gt;#define BUF_SIZE 100int main(int argc, char **argv)&#123; int fd, nread, i; struct stat sb; char *mapped, buf[BUF_SIZE]; for (i = 0; i &lt; BUF_SIZE; i++) &#123; buf[i] = '#'; &#125; /* 打开文件 */ if ((fd = open(argv[1], O_RDWR)) &lt; 0) &#123; perror(\"open\"); &#125; /* 获取文件的属性 */ if ((fstat(fd, &amp;sb)) == -1) &#123; perror(\"fstat\"); &#125; /* 将文件映射至进程的地址空间 */ if ((mapped = (char *)mmap(NULL, sb.st_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0)) == (void *)-1) &#123; perror(\"mmap\"); &#125; /* 映射完后, 关闭文件也可以操纵内存 */ close(fd); printf(\"%s\", mapped); /* 修改一个字符,同步到磁盘文件 */ mapped[20] = '9'; if ((msync((void *)mapped, sb.st_size, MS_SYNC)) == -1) &#123; perror(\"msync\"); &#125; /* 释放存储映射区 */ if ((munmap((void *)mapped, sb.st_size)) == -1) &#123; perror(\"munmap\"); &#125; return 0;&#125; mmap的优点 对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率。 实现了用户空间和内核空间的高效交互方式。两空间的各自修改操作可以直接反映在映射的区域内，从而被对方空间及时捕捉。 提供进程间共享内存及相互通信的方式。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的。 同时，如果进程A和进程B都映射了区域C，当A第一次读取C时通过缺页从磁盘复制文件页到内存中；但当B再读C的相同页面时，虽然也会产生缺页异常，但是不再需要从磁盘中复制文件过来，而可直接使用已经保存在内存中的文件数据。 可用于实现高效的大规模数据传输。内存空间不足，是制约大数据操作的一个方面，解决方案往往是借助硬盘空间协助操作，补充内存的不足。但是进一步会造成大量的文件I/O操作，极大影响效率。这个问题可以通过mmap映射很好的解决。换句话说，但凡是需要用磁盘空间代替内存的时候，mmap都可以发挥其功效。 注意 使用mmap需要注意的一个关键点是，mmap映射区域大小必须是物理页大小(page_size)的整倍数（32位系统中通常是4k字节）。原因是，内存的最小粒度是页，而进程虚拟地址空间和内存的映射也是以页为单位。为了匹配内存的操作，mmap从磁盘到虚拟地址空间的映射也必须是页。 内核可以跟踪被内存映射的底层对象（文件）的大小，进程可以合法的访问在当前文件大小以内又在内存映射区以内的那些字节。也就是说，如果文件的大小一直在扩张，只要在映射区域范围内的数据，进程都可以合法得到，这和映射建立时文件的大小无关。 映射建立之后，即使文件关闭，映射依然存在。因为映射的是磁盘的地址，不是文件本身，和文件句柄无关。同时可用于进程间通信的有效地址空间不完全受限于被映射文件的大小，因为是按页映射。 文件大小, mmap的参数 len 都不能决定进程能访问的大小, 而是容纳文件被映射部分的最小页面数决定进程能访问的大小 对于用mmap()映射普通文件来说，进程会在自己的地址空间新增一块空间，空间大小由mmap()的len参数指定 注意，进程并不一定能够对全部新增空间都能进行有效访问。进程能够访问的有效地址大小取决于文件被映射部分的大小。简单的说，能够容纳文件被映射部分大小的最少页面个数决定了进程从mmap()返回的地址开始，能够有效访问的地址空间大小。超过这个空间大小，内核会根据超过的严重程度返回发送不同的信号给进程 1234567891011121314151617181920212223242526272829303132333435#include &lt;sys/mman.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main(int argc, char** argv)&#123; int fd,i; int pagesize,offset; char *p_map; struct stat sb; /* 取得page size */ pagesize = sysconf(_SC_PAGESIZE); printf(\"pagesize is %d\\n\",pagesize); /* 打开文件 */ fd = open(argv[1], O_RDWR, 00777); fstat(fd, &amp;sb); printf(\"file size is %zd\\n\", (size_t)sb.st_size); offset = 0; p_map = (char *)mmap(NULL, pagesize * 2, PROT_READ|PROT_WRITE, MAP_SHARED, fd, offset); close(fd); p_map[sb.st_size] = '9'; /* 导致总线错误 */ p_map[pagesize] = '9'; /* 导致段错误 */ munmap(p_map, pagesize * 2); return 0;&#125; 总结 最近在学系网络编程，关于 mmap 、零拷贝与共享内存的知识看了许多，然后自己在学习的过程中进行了总结(看了好多的博客，进行了部分测试(知识不够，不能全面测试))，虽然还有好多的不懂得，但是总结下来慢慢消化与学习 本文不是个人原创(现在也没那个水平。。。)，所以内容都是自己根据资料所总结，如果涉及到版权问题(或者文章中的错误)，还望通知，予以修正，谢谢！ 更深入的剖析：http://dig404.com/2014/12/26/libpcap-mmap-3/ 参考 http://c.biancheng.net/cpp/html/138.html http://chuansong.me/n/1768538651716 http://blog.chinaunix.net/uid-26669729-id-3077015.html http://www.10tiao.com/html/546/201704/2650629303/1.html http://www.cnblogs.com/huxiao-tee/p/4660352.html https://nieyong.github.io/wiki_cpu/mmap%E8%AF%A6%E8%A7%A3.html http://blog.csdn.net/maverick1990/article/details/48050975","categories":[{"name":"OS","slug":"OS","permalink":"http://roux.top/categories/OS/"}],"tags":[{"name":"内存分配","slug":"内存分配","permalink":"http://roux.top/tags/内存分配/"}]},{"title":"一次命令行与程序间的交流","slug":"popen函数","date":"2017-10-25T16:00:00.000Z","updated":"2018-04-22T05:53:12.206Z","comments":true,"path":"2017/10/26/popen函数/","link":"","permalink":"http://roux.top/2017/10/26/popen函数/","excerpt":"前言 最近学习刚好遇到一个问题：在程序里面传递一个命令来让终端命令行执行，然后将结果返回到主程序，主程序用返回的结果来操作。 思路： 我在一开始想的是直接在终端执行命令然后写到一个临时文件(读取完就删除)里面，然后主程序读取文件的内容进行操作，但是考虑到我的程序要承受高并发操作(而且每次执行一下，都要创建一个临时文件，这种开销太大)，并且每次都要对磁盘进行操作，遇见大数据量的话效率太低，所以这种办法行不通 放弃了第一种方法，然后我想到的是利用子进程调用exec()函数来完成，但是最后的结果返回到父进程没有想通，无果。 后面我想到管道这个ipc方法，创建一个子进程继续利用exec()函数来执行命令，然后将执行的结果输出到管道的输入端，父进程读取即可，这是个方法。 然后我考虑这种方法的替代方案，无果，网上查询资料发现有函数popen()可以实现，故记录。","text":"前言 最近学习刚好遇到一个问题：在程序里面传递一个命令来让终端命令行执行，然后将结果返回到主程序，主程序用返回的结果来操作。 思路： 我在一开始想的是直接在终端执行命令然后写到一个临时文件(读取完就删除)里面，然后主程序读取文件的内容进行操作，但是考虑到我的程序要承受高并发操作(而且每次执行一下，都要创建一个临时文件，这种开销太大)，并且每次都要对磁盘进行操作，遇见大数据量的话效率太低，所以这种办法行不通 放弃了第一种方法，然后我想到的是利用子进程调用exec()函数来完成，但是最后的结果返回到父进程没有想通，无果。 后面我想到管道这个ipc方法，创建一个子进程继续利用exec()函数来执行命令，然后将执行的结果输出到管道的输入端，父进程读取即可，这是个方法。 然后我考虑这种方法的替代方案，无果，网上查询资料发现有函数popen()可以实现，故记录。 第一次尝试123456789101112131415161718192021#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define MAXSIZE 1024int main(void)&#123; system(\"ls &gt; tmp\"); //执行ls &gt; tmp命令 FILE *fp = fopen(\"tmp\", \"rb\"); if(NULL == fp)&#123; perror(\"open file\"); exit(1); &#125; char ch[MAXSIZE]; int i = 0; while((ch[i] = fgetc(fp)) != EOF)&#123; //读取fp描述符缓冲区的数据存放在ch数组里 i++; &#125; fclose(fp); return 0;&#125; 第二次尝试 说明：fork 一个子进程，并创建一个匿名管道，在子进程中执行shell 命令，并将其标准输出 dup 到匿名管道的输入端，父进程从管道中读取 123456789101112131415161718192021222324252627282930313233int execmd(char* cmd, char* buf, int len)&#123; int fd[2]; pid_t pid; int n, count; bzero(buf, len); if (pipe(fd) &lt; 0) return -1; if ((pid = fork()) &lt; 0) return -1; else if (pid &gt; 0)&#123; close(fd[1]); while ((n = read(fd[0], buf + count, len)) &gt; 0 &amp;&amp; count &gt; len) count += n; close(fd[0]); if (waitpid(pid, NULL, 0) &gt; 0) return -1; &#125;else&#123; close(fd[0]); if (fd[1] != STDOUT_FILENO)&#123; if (dup2(fd[1], STDOUT_FILENO) != STDOUT_FILENO)&#123; return -1; &#125; close(fd[1]); &#125; if (execl(\"/bin/sh\", \"sh\", \"-c\", cmd, (char*)0) == -1) return -1; &#125; return 0;&#125; 第三次尝试12345678910111213141516171819void execmd(const char *cmd, char *result)&#123; char buf[1024]; char ps[1024]=&#123;0&#125;; FILE *fp; strcpy(ps, cmd); if((fp = popen(ps, \"rb\"))!= NULL)&#123; while(fgets(buf, 1024, fp)!=NULL)&#123; strcat(result, buf); if(strlen(result)&gt;1024) break; &#125; pclose(fp); ptr = NULL; &#125; else&#123; printf(\"popen %s error/n\", ps); &#125;&#125; 总结： 可以利用popen函数进行命令行和程序间的参数传递，巧妙利用string系列函数 可以和程序的参数 argv 结合，然后传递给 popen 得到返回结果","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"Function","slug":"Function","permalink":"http://roux.top/tags/Function/"}]},{"title":"linux下/sbin/nologin和/bin/false的区别","slug":"nologin和false的区别","date":"2017-10-25T16:00:00.000Z","updated":"2017-11-25T10:51:45.383Z","comments":true,"path":"2017/10/26/nologin和false的区别/","link":"","permalink":"http://roux.top/2017/10/26/nologin和false的区别/","excerpt":"linux下/sbin/nologin和/bin/false的区别 /bin/false是最严格的禁止 login 选项，一切服务都不能用。而/sbin/nologin只是不允许 login 系统，但可以使用其他 ftp 等服务。如果想要用 false 在禁止 login 的同时允许 ftp，则必须在/etc/shells里增加一行/bin/false。","text":"linux下/sbin/nologin和/bin/false的区别 /bin/false是最严格的禁止 login 选项，一切服务都不能用。而/sbin/nologin只是不允许 login 系统，但可以使用其他 ftp 等服务。如果想要用 false 在禁止 login 的同时允许 ftp，则必须在/etc/shells里增加一行/bin/false。 知道了Linux用户管理最重要的两个文件就是/etc/passwd和/etc/shadow这两个文件。其中/etc/passwd是用来存储登陆用户信息的，它的基本格式如下： 12345root:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologins 由上面的格式可以看出，每一行代表一个用户的信息，一共包括7个字段的信息，每个字段的信息用冒号隔开。这7个字段分别代表： 账号名称：即登陆时的用户名 密码：早期UNIX系统的密码是放在这个文件中的，但因为这个文件的特性是所有程序都能够读取，所以，这样很容易造成数据被窃取，因此后来就将这个字段的密码数据改放到/etc/shadow中了(这项被置为x表示) UID：用户ID，每个账号名称对应一个 UID，通常UID=0表示 root 管理员 GID：组ID，与/etc/group有关，/etc/group与/etc/passwd差不多，是用来规范用户组信息的 用户信息说明栏： 用来解释这个账号是干什么的 家目录：home目录，即用户登陆以后跳转到的目录，以root用户为例，/root是它的家目录，所以root用户登陆以后就跳转到/root目录这里 Shell：用户使用的 shell，通常使用/bin/bash这个 shell，这也就是为什么登陆 Linux 时默认的 shell 是 bash 的原因，就是在这里设置的，如果要想更改登陆后使用的 shell，可以在这里修改。另外一个很重要的东西是有一个 shell 可以用来替代让账号无法登陆的命令，那就是/sbin/nologin。 当我看到这里的时候，我就去登陆我们实验室的服务器，打开/etc/passwd这个文件，里面果然有很多的类似上面格式的用户账号信息。 由于我们实验室服务器开放了ftp服务，而我正好有一个ftp的账号，我看到我的账号信息是这样的roux:x:530:525::/opt/ftp:/sbin/nologin 通过上面的学习，我觉得它的意思大概是这样的，用户名是 roux，x 表示密码经过加密放到/etc/shadow文件中了，UID 是 530，GID 是 525，访问的目录是/opt/ftp，我看了一下，这个目录下的内容正好是我登陆 ftp 后所看到的，至于最后一个/sbin/nologin，应该是登录时候使用的 shell，但是它为什么是 nologin 呢，难道不让我登陆吗？ 于是我用 root 权限登陆到里面，把后面的/sbin/nologin改成了/bin/bash，重新用ssh进行登陆，真的登陆进去了，而且登陆后的目录正好是/opt/ftp。但是我的权限依旧没有改变，很多文件还是打不开。 于是我明白了，这个 nologin 的作用就是限制某些用户通过 ssh 登陆到 shell 上。有时候为了进行系统维护工作，临时禁止其他用户登录，可以使用 nologin 文件，具体做法是在/etc/目录下创建一个名称为 nologin 的文件。例如： #touch /etc/nologin 这样将禁止随后的用户登录到系统中。禁止用户登录时，/etc/nologin 文件中的内容将会显示给用户，会一闪而过。 当用户试图登陆时，将会给用户显示&quot;disable login by admin temperarily!&quot;，当系统维护结束以后，再删除/etc/nologin文件，其他用户就又可以恢复登陆了，这只是限于能登陆 shel l的用户来说的，对于那些登陆shell 为/sbin/nologin的用户来说没有影响，因为他们本身就无法登陆shell。 总结：/etc/nologin 文件存在时 除 root 用户外其他任意用户无法登录","categories":[{"name":"OS","slug":"OS","permalink":"http://roux.top/categories/OS/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://roux.top/tags/Linux/"},{"name":"OS","slug":"OS","permalink":"http://roux.top/tags/OS/"}]},{"title":"open系列函数","slug":"open系列函数","date":"2017-10-24T16:00:00.000Z","updated":"2018-04-22T05:52:31.165Z","comments":true,"path":"2017/10/25/open系列函数/","link":"","permalink":"http://roux.top/2017/10/25/open系列函数/","excerpt":"- fopen函数 说明：fopen()是一个常用的函数，用来以指定的方式打开文件 头文件：#include &lt;stdio.h&gt; 原型：FILE *fopen(const char *path, const char *mode)","text":"- fopen函数 说明：fopen()是一个常用的函数，用来以指定的方式打开文件 头文件：#include &lt;stdio.h&gt; 原型：FILE *fopen(const char *path, const char *mode) mode: 打开方式 说明 r 以只读方式打开文件，该文件必须存在。 r+ 以读/写方式打开文件，该文件必须存在。 rb+ 以读/写方式打开一个二进制文件，只允许读/写数据。 rt+ 以读/写方式打开一个文本文件，允许读和写。 w 打开只写文件，若文件存在则长度清为0，即该文件内容消失，若不存在则创建该文件。 w+ 打开可读/写文件，若文件存在则文件长度清为零，即该文件内容会消失。若文件不存在则建立该文件。 a 以附加的方式打开只写文件。若文件不存在，则会建立该文件，如果文件存在，写入的数据会被加到文件尾，即文件原先的内容会被保留（EOF符保留)。 a+ 以附加方式打开可读/写的文件。若文件不存在，则会建立该文件，如果文件存在，则写入的数据会被加到文件尾后，即文件原先的内容会被保留（原来的EOF符 不保留)。 wb 以只写方式打开或新建一个二进制文件，只允许写数据。 wb+ 以读/写方式打开或建立一个二进制文件，允许读和写。 wt+ 以读/写方式打开或建立一个文本文件，允许读写。 at+ 以读/写方式打开一个文本文件，允许读或在文本末追加数据。 ab+ 以读/写方式打开一个二进制文件，允许读或在文件末追加数据。 返回值：文件顺利打开后，指向该流的文件指针就会被返回。若果文件打开失败则返回NULL，并把错误代码存在errno 中 示例： 12345678910111213141516#include &lt;stdio.h&gt;int main()&#123; FILE* fp; char str[100] = \"Hello World!\"; fstream=fopen(\"test.txt\", \"at+\"); if(fp == NULL)&#123; printf(\"open file test.txt failed!\\n\"); exit(1); &#125; else&#123; printf(\"open file test.txt succeed!\\n\"); &#125; fclose(fp); return 0;&#125; 注意： 若打开文件失败，接下来的读写动作也无法顺利进行，所以在fopen()后请作错误判断及处理 文件操作完成后，需要将文件关闭，一定要注意，否则会造成文件所占用内存泄露和在下次访问文件时出现问题 文件读取方式(文本文件与二进制文件的区别在系统存储上它们实际上并没有什么区别，都是以二进制的方式存储于硬盘上。之所以分二进制文件和文本文件，主要是逻辑上的区分，文本文件更人为可读而已) 二进制：二进制方式很简单，读文件时，会原封不动的读出文件的全部內容，写的時候，也是把內存缓冲区的內容原封不动的写到文件中 文本方式(仅Windows和DOS)：在写文件时，会将换行符号CRLF(0x0D 0x0A) 全部转换成单个的 0x0A，并且当遇到结束符 CTRLZ(0x1A)时，就认为文件已经结束。相应的，写文件时，会将所有的 0x0A 换成 0x0D0x0A。所以，若使用文本方式打开二进制文件时，就很容易出现文件读不完整，或內容不对的错误。 - open函数 说明：打开和创建文件 头文件：#include &lt;sys/types.h&gt;` include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;` 原型：int open(const char *pathname, int flags) int open(const char *pathname, int flags, mode_t mode) flags：(下面前三种互斥，利用&quot;|&quot;来组合使用) O_RDONLY 以只读方式打开文件 O_WRONLY 以只写方式打开文件 O_RDWR 以可读写方式打开文件 O_CREAT 若欲打开的文件不存在则自动建立该文件。 O_EXCL 如果O_CREAT 也被设置，此指令会去检查文件是否存在。文件若不存在则建立该文件，否则将导致打开文件错误。此外，若O_CREAT与O_EXCL同时设置，并且欲打开的文件为符号连接，则会打开文件失败。 O_NOCTTY 如果欲打开的文件为终端机设备时，则不会将该终端机当成进程控制终端机。 O_TRUNC 若文件存在并且以可写的方式打开时，此旗标会令文件长度清为0，而原来存于该文件的 资料也会消失。 O_APPEND 当读写文件时会从文件尾开始移动，也就是所写入的数据会以附加的方式加入到文件后面。 O_NONBLOCK 以不可阻断的方式打开文件，也就是无论有无数据读取或等待，都会立即返回进程之中。 O_NDELAY 同O_NONBLOCK。 O_SYNC 以同步的方式打开文件。 O_NOFOLLOW 如果参数pathname 所指的文件为一符号连接，则会令打开文件失败。 O_DIRECTORY 如果参数pathname 所指的文件并非为一目录，则会令打开文件失败 mode：(只有创建新文件时才生效，用于指定文件的权限(权限受到umask的限制)) S_IRWXU, 00700 权限, 代表该文件所有者具有可读、可写及可执行的权限. S_IRUSR 或S_IREAD, 00400 权限, 代表该文件所有者具有可读取的权限. S_IWUSR 或S_IWRITE, 00200 权限, 代表该文件所有者具有可写入的权限. S_IXUSR 或S_IEXEC, 00100 权限, 代表该文件所有者具有可执行的权限. S_IRWXG 00070 权限, 代表该文件用户组具有可读、可写及可执行的权限. S_IRGRP 00040 权限, 代表该文件用户组具有可读的权限. S_IWGRP 00020 权限, 代表该文件用户组具有可写入的权限. S_IXGRP 00010 权限, 代表该文件用户组具有可执行的权限. S_IRWXO 00007 权限, 代表其他用户具有可读、可写及可执行的权限. S_IROTH 00004 权限, 代表其他用户具有可读的权限 S_IWOTH 00002 权限, 代表其他用户具有可写入的权限. S_IXOTH 00001 权限, 代表其他用户具有可执行的权限. 返回值：成功则返回文件描述符，否则返回 -1 错误代码： EEXIST 参数pathname 所指的文件已存在, 却使用了O_CREAT 和O_EXCL 旗标. EACCESS 参数pathname 所指的文件不符合所要求测试的权限. EROFS 欲测试写入权限的文件存在于只读文件系统内. EFAULT 参数pathname 指针超出可存取内存空间. EINVAL 参数mode 不正确. ENAMETOOLONG 参数 pathname 太长. ENOTDIR 参数pathname 不是目录. ENOMEM 核心内存不足. ELOOP 参数pathname 有过多符号连接问题. EIO I/O 存取错误. 示例： 12345678910111213141516171819#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;int main(void)&#123; int fp = open(\"test.txt\", O_RDWR | O_CREAT, 0666); if(fp == -1)&#123; perror(\"open file\"); exit(1); &#125;else&#123; printf(\"success!\\n\"); &#125; close(fp); return 0;&#125; 运行结果 说明：umask为0002，创建的时候使用0666，最终的权限为0666-0002=0664(-rw-rw-r–) - fdopen函数 说明：fdopen()会将参数fildes 的文件描述词, 转换为对应的文件指针 头文件：#include &lt;stdio.h&gt; 原型：FILE *fdopen(int fd, const char *mode) mode:参考fopen(必须和原先文件描述词读写模式相同) 返回值：转换成功时返回指向该流的文件指针. 失败则返回NULL, 并把错误代码存在errno 中 示例： 1234567891011121314#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(void)&#123; FILE * fp = fdopen(0, \"w+\"); if(fp == NULL)&#123; perror(\"fdopen\"); exit(1); &#125; fprintf(fp, \"%s\\n\", \"hello!\"); fclose(fp); return 0;&#125; - popen函数 说明：popen()会使用pipe()建立管道然后调用fork()产生子进程，然后从子进程中调用/bin/sh -c 来执行参数command 的指令，通过管道将结果传送至父进程 头文件：#include &lt;stdio.h&gt; 原型：FILE *popen(const char *command, const char *type) type:”r”代表读取，”w”代表写入 返回值：若成功则返回文件指针, 否则返回NULL, 错误原因存于errno 中 示例： 123456789101112#include &lt;stdio.h&gt;int main(void)&#123; FILE *fp; char buffer[80]; fp = popen(\"cat /etc/passwd\", \"r\"); fgets(buffer, sizeof(buffer), fp); printf(\"%s\\n\", buffer); pclose(fp); return 0;&#125;","categories":[{"name":"C","slug":"C","permalink":"http://roux.top/categories/C/"}],"tags":[{"name":"Function","slug":"Function","permalink":"http://roux.top/tags/Function/"}]},{"title":"Linux 中的零拷贝技术","slug":"Linux中的零拷贝技术","date":"2017-10-24T16:00:00.000Z","updated":"2018-04-22T05:47:30.029Z","comments":true,"path":"2017/10/25/Linux中的零拷贝技术/","link":"","permalink":"http://roux.top/2017/10/25/Linux中的零拷贝技术/","excerpt":"Linux 中的零拷贝函数 直接IO 如果应用程序可以直接访问网络接口存储，那么在应用程序访问数据之前存储总线就不需要被遍历，数据传输所引起的开销将会是最小的。应用程序或者运行在用户模式下的库函数可以直接访问硬件设备的存储，操作系统内核除了进行必要的虚拟存储配置工作之外，不参与数据传输过程中的其它任何事情。直接 I/O 使得数据可以直接在应用程序和外围设备之间进行传输，完全不需要操作系统内核页缓存的支持","text":"Linux 中的零拷贝函数 直接IO 如果应用程序可以直接访问网络接口存储，那么在应用程序访问数据之前存储总线就不需要被遍历，数据传输所引起的开销将会是最小的。应用程序或者运行在用户模式下的库函数可以直接访问硬件设备的存储，操作系统内核除了进行必要的虚拟存储配置工作之外，不参与数据传输过程中的其它任何事情。直接 I/O 使得数据可以直接在应用程序和外围设备之间进行传输，完全不需要操作系统内核页缓存的支持 针对数据传输不需要经过应用程序地址空间的零拷贝技术 利用 mmap() 在 Linux 中，减少拷贝次数的一种方法是调用 mmap() 来代替调用 read，比如： 12tmp_buf = mmap(file, len);write(socket, tmp_buf, len); 首先，应用程序调用了 mmap() 之后，数据会先通过 DMA 拷贝到操作系统内核的缓冲区中去。接着，应用程序跟操作系统共享这个缓冲区，这样，操作系统内核和应用程序存储空间就不需要再进行任何的数据拷贝操作。应用程序调用了 write() 之后，操作系统内核将数据从原来的内核缓冲区中拷贝到与 socket 相关的内核缓冲区中。接下来，数据从内核 socket 缓冲区拷贝到协议引擎中去，这是第三次数据拷贝操作。 通过使用 mmap() 来代替 read(), 已经可以减半操作系统需要进行数据拷贝的次数。当大量数据需要传输的时候，这样做就会有一个比较好的效率。但是，这种改进也是需要代价的，使用 mmap() 其实是存在潜在的问题的。当对文件进行了内存映射，然后调用 write() 系统调用，如果此时其他的进程截断了这个文件，那么 write() 系统调用将会被总线错误信号 SIGBUS 中断，因为此时正在执行的是一个错误的存储访问。这个信号将会导致进程被杀死，解决这个问题可以通过以下这两种方法： 为 SIGBUS 安装一个新的信号处理器，这样，write() 系统调用在它被中断之前就返回已经写入的字节数目，errno 会被设置成 success。但是这种方法也有其缺点，它不能反映出产生这个问题的根源所在，因为 BIGBUS 信号只是显示某进程发生了一些很严重的错误。 第二种方法是通过文件租借锁来解决这个问题的，这种方法相对来说更好一些。我们可以通过内核对文件加读或者写的租借锁，当另外一个进程尝试对用户正在进行传输的文件进行截断的时候，内核会发送给用户一个实时信号：RT_SIGNAL_LEASE 信号，这个信号会告诉用户内核破坏了用户加在那个文件上的写或者读租借锁，那么 write() 系统调用则会被中断，并且进程会被 SIGBUS 信号杀死，返回值则是中断前写的字节数，errno 也会被设置为 success。文件租借锁需要在对文件进行内存映射之前设置。 12345678910if(fcntl(diskfd, F_SETSIG, RT_SIGNAL_LEASE) == -1) &#123; perror(\"kernel lease set signal\"); return -1;&#125;/* l_type can be F_RDLCK F_WRLCK 加锁*//* l_type can be F_UNLCK 解锁*/if(fcntl(diskfd, F_SETLEASE, l_type))&#123; perror(\"kernel lease set type\"); return -1;&#125; 使用 mmap 是 POSIX 兼容的，但是使用 mmap 并不一定能获得理想的数据传输性能。数据传输的过程中仍然需要一次 CPU 拷贝操作，而且映射操作也是一个开销很大的虚拟存储操作，这种操作需要通过更改页表以及冲刷 TLB (TLB(Translation Lookaside Buffer)转换检测缓冲区是一个内存管理单元,用于改进虚拟地址到物理地址转换速度的缓存) （使得 TLB 的内容无效）来维持存储的一致性。但是，因为映射通常适用于较大范围，所以对于相同长度的数据来说，映射所带来的开销远远低于 CPU 拷贝所带来的开销。 sendfile() 为了简化用户接口，同时还要继续保留 mmap()/write() 技术的优点：减少 CPU 的拷贝次数，Linux 在版本 -1 中引入了 sendfile() 这个系统调用。 sendfile() 不仅减少了数据拷贝操作，它也减少了上下文切换。首先：sendfile() 系统调用利用 DMA 引擎将文件中的数据拷贝到操作系统内核缓冲区中，然后数据被拷贝到与 socket 相关的内核缓冲区中去。接下来，DMA 引擎将数据从内核 socket 缓冲区中拷贝到协议引擎中去。如果在用户调用 sendfile () 系统调用进行数据传输的过程中有其他进程截断了该文件，那么 sendfile () 系统调用会简单地返回给用户应用程序中断前所传输的字节数，errno 会被设置为 success。如果在调用 sendfile() 之前操作系统对文件加上了租借锁，那么 sendfile() 的操作和返回状态将会和 mmap()/write () 一样。 sendfile() 系统调用不需要将数据拷贝或者映射到应用程序地址空间中去，所以 sendfile() 只是适用于应用程序地址空间不需要对所访问数据进行处理的情况。相对于 mmap() 方法来说，因为 sendfile 传输的数据没有越过用户应用程序 / 操作系统内核的边界线，所以 sendfile () 也极大地减少了存储管理的开销。但是，sendfile () 也有很多局限性，如下所列： sendfile() 局限于基于文件服务的网络应用程序，比如 web 服务器。据说，在 Linux 内核中实现 sendfile() 只是为了在其他平台上使用 sendfile() 的 Apache 程序。 由于网络传输具有异步性，很难在 sendfile () 系统调用的接收端进行配对的实现方式，所以数据传输的接收端一般没有用到这种技术。 基于性能的考虑来说，sendfile () 仍然需要有一次从文件到 socket 缓冲区的 CPU 拷贝操作，这就导致页缓存有可能会被传输的数据所污染。 在我们调用sendfile时，如果有其它进程截断了文件会发生什么呢？假设我们没有设置任何信号处理程序，sendfile调用仅仅返回它在被中断之前已经传输的字节数，errno会被置为success。如果我们在调用sendfile之前给文件加了锁，sendfile的行为仍然和之前相同，我们还会收到RT_SIGNAL_LEASE的信号 带有 DMA 收集拷贝功能的 sendfile() 上小节介绍的 sendfile() 技术在进行数据传输仍然还需要一次多余的数据拷贝操作，通过引入一点硬件上的帮助，这仅有的一次数据拷贝操作也可以避免。为了避免操作系统内核造成的数据副本，需要用到一个支持收集操作的网络接口，这也就是说，待传输的数据可以分散在存储的不同位置上，而不需要在连续存储中存放。这样一来，从文件中读出的数据就根本不需要被拷贝到 socket 缓冲区中去，而只是需要将缓冲区描述符传到网络协议栈中去，之后其在缓冲区中建立起数据包的相关结构，然后通过 DMA 收集拷贝功能将所有的数据结合成一个网络数据包。网卡的 DMA 引擎会在一次操作中从多个位置读取包头和数据。 Linux 2.4 版本中的 socket 缓冲区就可以满足这种条件，这也就是用于 Linux 中的众所周知的零拷贝技术，这种方法不但减少了因为多次上下文切换所带来开销，同时也减少了处理器造成的数据副本的个数。对于用户应用程序来说，代码没有任何改变。首先，sendfile() 系统调用利用 DMA 引擎将文件内容拷贝到内核缓冲区去；然后，将带有文件位置和长度信息的缓冲区描述符添加到 socket 缓冲区中去，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，DMA 引擎会将数据直接从内核缓冲区拷贝到协议引擎中去，这样就避免了最后一次数据拷贝。 通过这种方法，CPU 在数据传输的过程中不但避免了数据拷贝操作，理论上，CPU 也永远不会跟传输的数据有任何关联，这对于 CPU 的性能来说起到了积极的作用：首先，高速缓冲存储器没有受到污染；其次，高速缓冲存储器的一致性不需要维护，高速缓冲存储器在 DMA 进行数据传输前或者传输后不需要被刷新。然而实际上，后者实现起来非常困难。源缓冲区有可能是页缓存的一部分，这也就是说一般的读操作可以访问它，而且该访问也可以是通过传统方式进行的。只要存储区域可以被 CPU 访问到，那么高速缓冲存储器的一致性就需要通过 DMA 传输之前冲刷新高速缓冲存储器来维护。而且，这种数据收集拷贝功能的实现是需要硬件以及设备驱动程序支持的。 splice() splice() 是 Linux 中与 mmap() 和 sendfile() 类似的一种方法。它也可以用于用户应用程序地址空间和操作系统地址空间之间的数据传输。splice() 适用于可以确定数据传输路径的用户应用程序，它不需要利用用户地址空间的缓冲区进行显式的数据传输操作。那么，当数据只是从一个地方传送到另一个地方，过程中所传输的数据不需要经过用户应用程序的处理的时候，spice() 就成为了一种比较好的选择。splice() 可以在操作系统地址空间中整块地移动数据，从而减少大多数数据拷贝操作。而且，splice() 进行数据传输可以通过异步的方式来进行，用户应用程序可以先从系统调用返回，而操作系统内核进程会控制数据传输过程继续进行下去。splice() 可以被看成是类似于基于流的管道的实现，管道可以使得两个文件描述符相互连接，splice 的调用者则可以控制两个设备（或者协议栈）在操作系统内核中的相互连接。 splice() 系统调用和 sendfile() 非常类似，用户应用程序必须拥有两个已经打开的文件描述符，一个用于表示输入设备，一个用于表示输出设备。与 sendfile() 不同的是，splice() 允许任意两个文件之间互相连接，而并不只是文件到 socket 进行数据传输。对于从一个文件描述符发送数据到 socket 这种特例来说，一直都是使用 sendfile() 这个系统调用，而 splice 一直以来就只是一种机制，它并不仅限于 sendfile() 的功能。也就是说，sendfile() 只是 splice() 的一个子集，在 Linux -6.23 中，sendfile() 这种机制的实现已经没有了，但是这个 API 以及相应的功能还存在，只不过 API 以及相应的功能是利用了 splice() 这种机制来实现的。 在数据传输的过程中，splice() 机制交替地发送相关的文件描述符的读写操作，并且可以将读缓冲区重新用于写操作。它也利用了一种简单的流控制，通过预先定义的水印（ watermark ）来阻塞写请求。有实验表明，利用这种方法将数据从一个磁盘传输到另一个磁盘会增加 30% 到 70% 的吞吐量，数据传输的过程中， CPU 的负载也会减少一半。 Linux 2.6.17 内核引入了 splice() 系统调用，但是，这个概念在此之前 ] 其实已经存在了很长一段时间了。1988 年，Larry McVoy 提出了这个概念，它被看成是一种改进服务器端系统的 I/O 性能的一种技术，尽管在之后的若干年中经常被提及，但是 splice 系统调用从来没有在主流的 Linux 操作系统内核中实现过，一直到 Linux 2.6.17 版本的出现。splice 系统调用需要用到四个参数，其中两个是文件描述符，一个表示文件长度，还有一个用于控制如何进行数据拷贝。splice 系统调用可以同步实现，也可以使用异步方式来实现。在使用异步方式的时候，用户应用程序会通过信号 SIGIO 来获知数据传输已经终止。splice() 系统调用的接口如下所示： 1long splice(int fdin, int fdout, size_t len, unsigned int flags); 调用 splice() 系统调用会导致操作系统内核从数据源 fdin 移动最多 len 个字节的数据到 fdout 中去，这个数据的移动过程只是经过操作系统内核空间，需要最少的拷贝次数。使用 splice() 系统调用需要这两个文件描述符中的一个必须是用来表示一个管道设备的。不难看出，这种设计具有局限性，Linux 的后续版本针对这一问题将会有所改进。参数 flags 用于表示拷贝操作的执行方法，当前的 flags 有如下这些取值： SPLICE_F_NONBLOCK：splice 操作不会被阻塞。然而，如果文件描述符没有被设置为不可被阻塞方式的 I/O ，那么调用 splice 有可能仍然被阻塞。 SPLICE_F_MORE：告知操作系统内核下一个 splice 系统调用将会有更多的数据传来。 SPLICE_F_MOVE：如果输出是文件，这个值则会使得操作系统内核尝试从输入管道缓冲区直接将数据读入到输出地址空间，这个数据传输过程没有任何数据拷贝操作发生。 Splice() 系统调用利用了 Linux 提出的管道缓冲区（ pipe buffer ）机制，这就是为什么这个系统调用的两个文件描述符参数中至少有一个必须要指代管道设备的原因。为了支持 splice 这种机制，Linux 在用于设备和文件系统的 file_operations 结构中增加了下边这两个定义： 12ssize_t (*splice_write)(struct inode *pipe, strucuct file *out, size_t len, unsigned int flags);ssize_t (*splice_read)(struct inode *in, strucuct file *pipe, size_t len, unsigned int flags); 这两个新的操作可以根据 flags 的设定在 pipe 和 in 或者 out 之间移动 len 个字节。Linux 文件系统已经实现了具有上述功能并且可以使用的操作，而且还实现了一个 generic_splice_sendpage() 函数用于和 socket 之间的接合。 对应用程序地址空间和内核之间的数据传输进行优化的零拷贝技术 前面提到的几种零拷贝技术都是通过尽量避免用户应用程序和操作系统内核缓冲区之间的数据拷贝来实现的，使用上面那些零拷贝技术的应用程序通常都要局限于某些特殊的情况：要么不能在操作系统内核中处理数据，要么不能在用户地址空间中处理数据。而这一小节提出的零拷贝技术保留了传统在用户应用程序地址空间和操作系统内核地址空间之间传递数据的技术，但却在传输上进行优化。我们知道，数据在系统软件和硬件之间的传递可以通过 DMA 传输来提高效率，但是对于用户应用程序和操作系统之间进行数据传输这种情况来说，并没有类似的工具可以使用。本节介绍的技术就是针对这种情况提出来的。 利用写时复制(copy on write) 在某些情况下，Linux 操作系统内核中的页缓存可能会被多个应用程序所共享，操作系统有可能会将用户应用程序地址空间缓冲区中的页面映射到操作系统内核地址空间中去。如果某个应用程序想要对这共享的数据调用 write() 系统调用，那么它就可能破坏内核缓冲区中的共享数据，传统的 write() 系统调用并没有提供任何显示的加锁操作，Linux 中引入了写时复制这样一种技术用来保护数据。 什么是写时复制 写时复制是计算机编程中的一种优化策略，它的基本思想是这样的：如果有多个应用程序需要同时访问同一块数据，那么可以为这些应用程序分配指向这块数据的指针，在每一个应用程序看来，它们都拥有这块数据的一份数据拷贝，当其中一个应用程序需要对自己的这份数据拷贝进行修改的时候，就需要将数据真正地拷贝到该应用程序的地址空间中去，也就是说，该应用程序拥有了一份真正的私有数据拷贝，这样做是为了避免该应用程序对这块数据做的更改被其他应用程序看到。这个过程对于应用程序来说是透明的，如果应用程序永远不会对所访问的这块数据进行任何更改，那么就永远不需要将数据拷贝到应用程序自己的地址空间中去。这也是写时复制的最主要的优点。 写时复制的实现需要 MMU 的支持，MMU 需要知晓进程地址空间中哪些特殊的页面是只读的，当需要往这些页面中写数据的时候，MMU 就会发出一个异常给操作系统内核，操作系统内核就会分配新的物理存储空间，即将被写入数据的页面需要与新的物理存储位置相对应。 写时复制的最大好处就是可以节约内存。不过对于操作系统内核来说，写时复制增加了其处理过程的复杂性。 数据传输的实现及其局限性 数据发送端 对于数据传输的发送端来说，实现相对来说是比较简单的，对与应用程序缓冲区相关的物理页面进行加锁，并将这些页面映射到操作系统内核的地址空间，并标识为“ write only ”。当系统调用返回的时候，用户应用程序和网络堆栈就都可以读取该缓冲区中的数据。在操作系统已经传送完所有的数据之后，应用程序就可以对这些数据进行写操作。如果应用程序尝试在数据传输完成之前对数据进行写操作，那么就会产生异常，这个时候操作系统就会将数据拷贝到应用程序自己的缓冲区中去，并且重置应用程序端的映射。数据传输完成之后，对加锁的页面进行解锁操作，并重置 COW(copy on write) 标识。 数据接收端 对于数据接收端来说，该技术的实现则需要处理复杂得多的情况。如果 read() 系统调用是在数据包到达之前发出的，并且应用程序是被阻塞的，那么 read() 系统调用就会告知操作系统接收到的数据包中的数据应该存放到什么地方去。在这种情况下，根本没有必要进行页面重映射，网络接口卡可以提供足够的支持让数据直接存入用户应用程序的缓冲区中去。如果数据接收是异步的，在 read() 系统调用发出之前，操作系统不知道该把数据写到哪里，因为它不知道用户应用程序缓冲区的位置，所以操作系统内核必须要先把数据存放到自己的缓冲区中去。 局限性 写时复制技术有可能会导致操作系统的处理开销很大．所有相关的缓冲区都必须要进行页对齐处理，并且使用的 MMU (MMU是Memory Management Unit的缩写，中文名是内存管理单元，它是中央处理器（CPU）中用来管理虚拟存储器、物理存储器的控制线路，同时也负责虚拟地址映射为物理地址，以及提供硬件机制的内存访问授权，多用户多进程操作系统) 页面一定要是整数个的。对于发送端来说，这不会造成什么问题。但是对于接收端来说，它需要有能力处理更加复杂的情况。 首先，数据包的尺寸大小要合适，大小需要恰到好处能够覆盖一整页的数据，这就限制了那些 MTU 大小大于系统内存页的网络，比如 FDDI 和 ATM。其次，为了在没有任何中断的情况下将页面重映射到数据包的流，数据包中的数据部分必须占用整数个页面。对于异步接收数据的情况来说，为了将数据高效地移动到用户地址空间中去，可以使用这样一种方法：利用网络接口卡的支持，传来的数据包可以被分割成包头和数据两部分，数据被存放在一个单独的缓冲区内，虚拟存储系统然后就会将数据映射到用户地址空间缓冲区去。 使用这种方法需要满足两个先决条件，也就是上面提到过的：一是应用程序缓冲区必须是页对齐的，并且在虚拟存储上是连续的；二是传来的数据有一页大小的时候才可以对数据包进行分割。事实上，这两个先决条件是很难满足的。如果应用程序缓冲区不是页对齐的，或者数据包的大小超过一个页，那么数据就需要被拷贝。对于数据发送端来说，就算数据在传输的过程中对于应用程序来说是写保护的，应用程序仍然需要避免使用这些忙缓冲区，这是因为写时拷贝操作所带来的开销是很大的。如果没有端到端这一级别的通知，那么应用程序很难会知道某缓冲区是否已经被释放还是仍然在被占用。 这种零拷贝技术比较适用于那种写时复制事件发生比较少的情况，因为写时复制事件所产生的开销要远远高于一次 CPU 拷贝所产生的开销。实际情况中，大多数应用程序通常都会多次重复使用相同的缓冲区，所以，一次使用完数据之后，不要从操作系统地址空间解除页面的映射，这样会提高效率。考虑到同样的页面可能会被再次访问，所以保留页面的映射可以节省管理开销，但是，这种映射保留不会减少由于页表往返移动和 TLB 冲刷所带来的开销，这是因为每次页面由于写时复制而进行加锁或者解锁的时候，页面的只读标志都要被更改。 缓冲区共享 还有另外一种利用预先映射机制的共享缓冲区的方法也可以在应用程序地址空间和操作系统内核之间快速传输数据。采用缓冲区共享这种思想的架构最先在 Solaris 上实现，该架构使用了“ fbufs ”这个概念。这种方法需要修改 API。应用程序地址空间和操作系统内核地址空间之间的数据传递需要严格按照 fbufs 体系结构来实现，操作系统内核之间的通信也是严格按照 fbufs 体系结构来完成的。每一个应用程序都有一个缓冲区池，这个缓冲区池被同时映射到用户地址空间和内核地址空间，也可以在必要的时候才创建它们。通过完成一次虚拟存储操作来创建缓冲区，fbufs 可以有效地减少由存储一致性维护所引起的大多数性能问题。 为什么要扩展 Linux I/O API 传统的 Linux 输入输出接口，比如读和写系统调用，都是基于拷贝的，也就是说，数据需要在操作系统内核和应用程序定义的缓冲区之间进行拷贝。对于读系统调用来说，用户应用程序呈现给操作系统内核一个预先分配好的缓冲区，内核必须把读进来的数据放到这个缓冲区内。对于写系统调用来说，只要系统调用返回，用户应用程序就可以自由重新利用数据缓冲区。 为了支持上面这种机制，Linux 需要能够为每一个操作都进行建立和删除虚拟存储映射。这种页面重映射的机制依赖于机器配置、cache 体系结构、TLB 未命中处理所带来的开销以及处理器是单处理器还是多处理器等多种因素。如果能够避免处理 I/O 请求的时候虚拟存储 / TLB 操作所产生的开销，则会极大地提高 I/O 的性能。fbufs 就是这样一种机制。使用 fbufs 体系结构就可以避免虚拟存储操作。由数据显示，fbufs 这种结构在 DECStation™ 5000/200 这个单处理器工作站上会取得比上面提到的页面重映射方法好得多的性能。如果要使用 fbufs 这种体系结构，必须要扩展 Linux API，从而实现一种有效而且全面的零拷贝技术。 快速缓冲区（ Fast Buffers ）原理介绍 I/O 数据存放在一些被称作 fbufs 的缓冲区内，每一个这样的缓冲区都包含一个或者多个连续的虚拟存储页。应用程序访问 fbuf 是通过保护域来实现的，有如下这两种方式： 如果应用程序分配了 fbuf，那么应用程序就有访问该 fbuf 的权限 如果应用程序通过 IPC 接收到了 fbuf，那么应用程序对这个 fbuf 也有访问的权限 对于第一种情况来说，这个保护域被称作是 fbuf 的“ originator ”；对于后一种情况来说，这个保护域被称作是 fbuf 的“ receiver ”。 传统的 Linux I/O 接口支持数据在应用程序地址空间和操作系统内核之间交换，这种交换操作导致所有的数据都需要进行拷贝。如果采用 fbufs 这种方法，需要交换的是包含数据的缓冲区，这样就消除了多余的拷贝操作。应用程序将 fbuf 传递给操作系统内核，这样就能减少传统的 write 系统调用所产生的数据拷贝开销。同样的，应用程序通过 fbuf 来接收数据，这样也可以减少传统 read 系统调用所产生的数据拷贝开销。如下图所示： I/O 子系统或者应用程序都可以通过 fbufs 管理器来分配 fbufs。一旦分配了 fbufs，这些 fbufs 就可以从程序传递到 I/O 子系统，或者从 I/O 子系统传递到程序。使用完后，这些 fbufs 会被释放回 fbufs 缓冲区池。 fbufs 在实现上有如下这些特性： fbuf 需要从 fbufs 缓冲区池里分配。每一个 fbuf 都存在一个所属对象，要么是应用程序，要么是操作系统内核。fbuf 可以在应用程序和操作系统之间进行传递，fbuf 使用完之后需要被释放回特定的 fbufs 缓冲区池，在 fbuf 传递的过程中它们需要携带关于 fbufs 缓冲区池的相关信息。 每一个 fbufs 缓冲区池都会和一个应用程序相关联，一个应用程序最多只能与一个 fbufs 缓冲区池相关联。应用程序只有资格访问它自己的缓冲区池。 fbufs 不需要虚拟地址重映射，这是因为对于每个应用程序来说，它们可以重新使用相同的缓冲区集合。这样，虚拟存储转换的信息就可以被缓存起来，虚拟存储子系统方面的开销就可以消除。4,。 I/O 子系统（设备驱动程序，文件系统等）可以分配 fbufs，并将到达的数据直接放到这些 fbuf 里边。这样，缓冲区之间的拷贝操作就可以避免。 前面提到，这种方法需要修改 API，如果要使用 fbufs 体系结构，应用程序和 Linux 操作系统内核驱动程序都需要使用新的 API，如果应用程序要发送数据，那么它就要从缓冲区池里获取一个 fbuf，将数据填充进去，然后通过文件描述符将数据发送出去。接收到的 fbufs 可以被应用程序保留一段时间，之后，应用程序可以使用它继续发送其他的数据，或者还给缓冲区池。但是，在某些情况下，需要对数据包内的数据进行重新组装，那么通过 fbuf 接收到数据的应用程序就需要将数据拷贝到另外一个缓冲区内。再者，应用程序不能对当前正在被内核处理的数据进行修改，基于这一点，fbufs 体系结构引入了强制锁的概念以保证其实现。对于应用程序来说，如果 fbufs 已经被发送给操作系统内核，那么应用程序就不会再处理这些 fbufs。 fbufs 存在的一些问题 管理共享缓冲区池需要应用程序、网络软件、以及设备驱动程序之间的紧密合作。对于数据接收端来说，网络硬件必须要能够将到达的数据包利用 DMA 传输到由接收端分配的正确的存储缓冲区池中去。 而且，应用程序稍微不注意就会更改之前发到共享存储中的数据的内容，从而导致数据被破坏，但是这种问题在应用程序端是很难调试的。 同时，共享存储这种模型很难与其他类型的存储对象关联使用，但是应用程序、网络软件以及设备驱动程序之间的紧密合作是需要其他存储管理器的支持的。 对于共享缓冲区这种技术来说，虽然这种技术看起来前景光明，但是这种技术不但需要对 API 进行更改，而且需要对驱动程序也进行更改，并且这种技术本身也存在一些未解决的问题，这就使得这种技术目前还只是出于试验阶段。在测试系统中，这种技术在性能上有很大的改进，不过这种新的架构的整体安装目前看起来还是不可行的。这种预先分配共享缓冲区的机制有时也因为粒度问题需要将数据拷贝到另外一个缓冲区中去。 总结 针对 Linux 操作系统平台提出并实现了很多种零拷贝技术，但是并不是所有这些零拷贝技术都被广泛应用于现实中的操作系统中的。比如，fbufs 体系结构，它在很多方面看起来都很吸引人，但是使用它需要更改 API 以及驱动程序，它还存在其他一些实现上的困难，这就使得 fbufs 还只是停留在实验的阶段。动态地址重映射技术只是需要对操作系统做少量修改，虽然不需要修改用户软件，但是当前的虚拟存储体系结构并不能很好地支持频繁的虚拟地址重映射操作。而且为了保证存储的一致性，重映射之后还必须对 TLB 和一级缓存进行刷新。事实上，利用地址重映射实现的零拷贝技术适用的范围是很小的，这是因为虚拟存储操作所带来的开销往往要比 CPU 拷贝所产生的开销还要大。此外，为了完全消除 CPU 访问存储，通常都需要额外的硬件来支持，而这种硬件的支持并不是很普及，同时也是非常昂贵的。 本文的目的是帮助读者理清这些出现在 Linux 操作系统中的零拷贝技术都是从何种角度来帮助改善数据传输过程中遇到的性能问题的。关于各种零拷贝技术的具体实现细节，本文没有做详细描述。同时，零拷贝技术一直是在不断地发展和完善当中的，本文并没有涵盖 Linux 上出现的所有零拷贝技术。 出处 阅读完后会明白零拷贝技术的发展及原因，能够梳理自己的知识体系，为自己平常的使用提供基础(在原文上做了补充及修改) 转载自：https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy2/index.html","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"零拷贝","slug":"零拷贝","permalink":"http://roux.top/tags/零拷贝/"}]},{"title":"从内核文件系统看文件读写过程","slug":"文件读写过程","date":"2017-10-24T16:00:00.000Z","updated":"2018-04-22T05:56:04.314Z","comments":true,"path":"2017/10/25/文件读写过程/","link":"","permalink":"http://roux.top/2017/10/25/文件读写过程/","excerpt":"系统调用 操作系统的主要功能是为管理硬件资源和为应用程序开发人员提供良好的环境，但是计算机系统的各种硬件资源是有限的，因此为了保证每一个进程都能安全的执行。处理器设有两种模式：“用户模式”与“内核模式”。一些容易发生安全问题的操作都被限制在只有内核模式下才可以执行，例如I/O操作，修改基址寄存器内容等。而连接用户模式和内核模式的接口称之为系统调用。 应用程序代码运行在用户模式下，当应用程序需要实现内核模式下的指令时，先向操作系统发送调用请求。操作系统收到请求后，执行系统调用接口，使处理器进入内核模式。当处理器处理完系统调用操作后，操作系统会让处理器返回用户模式，继续执行用户代码。","text":"系统调用 操作系统的主要功能是为管理硬件资源和为应用程序开发人员提供良好的环境，但是计算机系统的各种硬件资源是有限的，因此为了保证每一个进程都能安全的执行。处理器设有两种模式：“用户模式”与“内核模式”。一些容易发生安全问题的操作都被限制在只有内核模式下才可以执行，例如I/O操作，修改基址寄存器内容等。而连接用户模式和内核模式的接口称之为系统调用。 应用程序代码运行在用户模式下，当应用程序需要实现内核模式下的指令时，先向操作系统发送调用请求。操作系统收到请求后，执行系统调用接口，使处理器进入内核模式。当处理器处理完系统调用操作后，操作系统会让处理器返回用户模式，继续执行用户代码。 进程的虚拟地址空间可分为两部分，内核空间和用户空间。内核空间中存放的是内核代码和数据，而进程的用户空间中存放的是用户程序的代码和数据。不管是内核空间还是用户空间，它们都处于虚拟空间中，都是对物理地址的映射。 应用程序中实现对文件的操作过程就是典型的系统调用过程。 虚拟文件系统 一个操作系统可以支持多种底层不同的文件系统（比如NTFS, FAT, ext3, ext4），为了给内核和用户进程提供统一的文件系统视图，Linux在用户进程和底层文件系统之间加入了一个抽象层，即虚拟文件系统(Virtual File System, VFS)，进程所有的文件操作都通过VFS，由VFS来适配各种底层不同的文件系统，完成实际的文件操作。 通俗的说，VFS就是定义了一个通用文件系统的接口层和适配层，一方面为用户进程提供了一组统一的访问文件，目录和其他对象的统一方法，另一方面又要和不同的底层文件系统进行适配。如图所示： 虚拟文件系统主要模块 超级块（super_block），用于保存一个文件系统的所有元数据，相当于这个文件系统的信息库，为其他的模块提供信息。因此一个超级块可代表一个文件系统。文件系统的任意元数据修改都要修改超级块。超级块对象是常驻内存并被缓存的。 目录项模块，管理路径的目录项。比如一个路径 /home/foo/hello.txt，那么目录项有home, foo, hello.txt。目录项的块，存储的是这个目录下的所有的文件的inode号和文件名等信息。其内部是树形结构，操作系统检索一个文件，都是从根目录开始，按层次解析路径中的所有目录，直到定位到文件。 inode模块，管理一个具体的文件，是文件的唯一标识，一个文件对应一个inode。通过inode可以方便的找到文件在磁盘扇区的位置。同时inode模块可链接到address_space模块，方便查找自身文件数据是否已经缓存。 打开文件列表模块，包含所有内核已经打开的文件。已经打开的文件对象由open系统调用在内核中创建，也叫文件句柄。打开文件列表模块中包含一个列表，每个列表表项是一个结构体struct file，结构体中的信息用来表示打开的一个文件的各种状态参数。 file_operations模块。这个模块中维护一个数据结构，是一系列函数指针的集合，其中包含所有可以使用的系统调用函数，例如open、read、write、mmap等。每个打开文件（打开文件列表模块的一个表项）都可以连接到file_operations模块，从而对任何已打开的文件，通过系统调用函数，实现各种操作。 address_space模块，它表示一个文件在页缓存中已经缓存了的物理页。它是页缓存和外部设备中文件系统的桥梁。如果将文件系统可以理解成数据源，那么address_space可以说关联了内存系统和文件系统。我们会在文章后面继续讨论。 模块间的相互作用和逻辑关系如下图所示： 由图可以看出： 每个模块都维护了一个X_op指针指向它所对应的操作对象X_operations。 超级块维护了一个s_files指针指向了“已打开文件列表模块”，即内核所有的打开文件的链表，这个链表信息是所有进程共享的。 目录操作模块和inode模块都维护了一个X_sb指针指向超级块，从而可以获得整个文件系统的元数据信息。 目录项对象和inode对象各自维护了指向对方的指针，可以找到对方的数据。 已打开文件列表上每一个file结构体实例维护了一个f_dentry指针，指向了它对应的目录项，从而可以根据目录项找到它对应的inode信息。 已打开文件列表上每一个file结构体实例维护了一个f_op指针，指向可以对这个文件进行操作的所有函数集合file_operations。 inode中不仅有和其他模块关联的指针，重要的是它可以指向address_space模块，从而获得自身文件在内存中的缓存信息。 address_space内部维护了一个树结构来指向所有的物理页结构page，同时维护了一个host指针指向inode来获得文件的元数据。 进程和虚拟文件系统交互 内核使用task_struct来表示单个进程的描述符，其中包含维护一个进程的所有信息。task_struct结构体中维护了一个 files的指针（和“已打开文件列表”上的表项是不同的指针）来指向结构体files_struct，files_struct中包含文件描述符表和打开的文件对象信息。 file_struct中的文件描述符表实际是一个file类型的指针列表（和“已打开文件列表”上的表项是相同的指针），可以支持动态扩展，每一个指针指向虚拟文件系统中文件列表模块的某一个已打开的文件。 file结构一方面可从f_dentry链接到目录项模块以及inode模块，获取所有和文件相关的信息，另一方面链接file_operations子模块，其中包含所有可以使用的系统调用函数，从而最终完成对文件的操作。这样，从进程到进程的文件描述符表，再关联到已打开文件列表上对应的文件结构，从而调用其可执行的系统调用函数，实现对文件的各种操作。 进程 vs 文件列表 vs Inode 多个进程可以同时指向一个打开文件对象（文件列表表项），例如父进程和子进程间共享文件对象； 一个进程可以多次打开一个文件，生成不同的文件描述符，每个文件描述符指向不同的文件列表表项。但是由于是同一个文件，inode唯一，所以这些文件列表表项都指向同一个inode。通过这样的方法实现文件共享（共享同一个磁盘文件）； I/O 缓冲区 概念 如高速缓存（cache）产生的原理类似，在I/O过程中，读取磁盘的速度相对内存读取速度要慢的多。因此为了能够加快处理数据的速度，需要将读取过的数据缓存在内存里。而这些缓存在内存里的数据就是高速缓冲区（buffer cache），下面简称为“buffer”。 具体来说，buffer（缓冲区）是一个用于存储速度不同步的设备或优先级不同的设备之间传输数据的区域。一方面，通过缓冲区，可以使进程之间的相互等待变少，从而使从速度慢的设备读入数据时，速度快的设备的操作进程不发生间断。另一方面，可以保护硬盘或减少网络传输的次数。 Buffer和Cache buffer和cache是两个不同的概念：cache是高速缓存，用于CPU和内存之间的缓冲；buffer是I/O缓存，用于内存和硬盘的缓冲；简单的说，cache是加速“读”，而buffer是缓冲“写”，前者解决读的问题，保存从磁盘上读出的数据，后者是解决写的问题，保存即将要写入到磁盘上的数据。 Buffer Cache和 Page Cache buffer cache和page cache都是为了处理设备和内存交互时高速访问的问题。buffer cache可称为块缓冲器，page cache可称为页缓冲器。在linux不支持虚拟内存机制之前，还没有页的概念，因此缓冲区以块为单位对设备进行。在linux采用虚拟内存的机制来管理内存后，页是虚拟内存管理的最小单位，开始采用页缓冲的机制来缓冲内存。Linux-6之后内核将这两个缓存整合，页和块可以相互映射，同时，页缓存page cache面向的是虚拟内存，块I/O缓存Buffer cache是面向块设备。需要强调的是，页缓存和块缓存对进程来说就是一个存储系统，进程不需要关注底层的设备的读写。 buffer cache和page cache两者最大的区别是缓存的粒度。buffer cache面向的是文件系统的块。而内核的内存管理组件采用了比文件系统的块更高级别的抽象：页page，其处理的性能更高。因此和内存管理交互的缓存组件，都使用页缓存。 Page Cache 页缓存是面向文件，面向内存的。通俗来说，它位于内存和文件之间缓冲区，文件IO操作实际上只和page cache交互，不直接和内存交互。page cache可以用在所有以文件为单元的场景下，比如网络文件系统等等。page cache通过一系列的数据结构，比如inode, address_space, struct page，实现将一个文件映射到页的级别： struct page结构标志一个物理内存页，通过page + offset就可以将此页帧定位到一个文件中的具体位置。同时struct page还有以下重要参数： 标志位flags来记录该页是否是脏页，是否正在被写回等等； mapping指向了地址空间address_space，表示这个页是一个页缓存中页，和一个文件的地址空间对应； index记录这个页在文件中的页偏移量； 文件系统的inode实际维护了这个文件所有的块block的块号，通过对文件偏移量offset取模可以很快定位到这个偏移量所在的文件系统的块号，磁盘的扇区号。同样，通过对文件偏移量offset进行取模可以计算出偏移量所在的页的偏移量。 page cache缓存组件抽象了地址空间address_space这个概念来作为文件系统和页缓存的中间桥梁。地址空间address_space通过指针可以方便的获取文件inode和struct page的信息，所以可以很方便地定位到一个文件的offset在各个组件中的位置，即通过：文件字节偏移量 –&gt; 页偏移量 –&gt; 文件系统块号 block –&gt; 磁盘扇区号 页缓存实际上就是采用了一个基数树结构将一个文件的内容组织起来存放在物理内存struct page中。一个文件inode对应一个地址空间address_space。而一个address_space对应一个页缓存基数树。它们之间的关系如下： Address Space 下面我们总结已经讨论过的address_space所有功能。address_space是Linux内核中的一个关键抽象，它被作为文件系统和页缓存的中间适配器，用来指示一个文件在页缓存中已经缓存了的物理页。因此，它是页缓存和外部设备中文件系统的桥梁。如果将文件系统可以理解成数据源，那么address_space可以说关联了内存系统和文件系统。 由图中可以看到，地址空间address_space链接到页缓存基数树和inode，因此address_space通过指针可以方便的获取文件inode和page的信息。那么页缓存是如何通过address_space实现缓冲区功能的？我们再来看完整的文件读写流程。 - 文件读写基本流程 读文件 进程调用库函数向内核发起读文件请求； 内核通过检查进程的文件描述符定位到虚拟文件系统的已打开文件列表表项； 调用该文件可用的系统调用函数read() read()函数通过文件表项链接到目录项模块，根据传入的文件路径，在目录项模块中检索，找到该文件的inode； 在inode中，通过文件内容偏移量计算出要读取的页； 通过inode找到文件对应的address_space； 在address_space中访问该文件的页缓存树，查找对应的页缓存结点： 如果页缓存命中，那么直接返回文件内容； 如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页；重新进行第6步查找页缓存； 文件内容读取成功。 写文件 前6步和读文件一致，在address_space中查询对应页的页缓存是否存在： 如果页缓存命中，直接把文件内容修改更新在页缓存的页中。写文件就结束了。这时候文件修改位于页缓存，并没有写回到磁盘文件中去。 如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过inode找到文件该页的磁盘地址，读取相应的页填充该缓存页。此时缓存页命中，进行第6步。 一个页缓存中的页如果被修改，那么会被标记成脏页。脏页需要写回到磁盘中的文件块。有两种方式可以把脏页写回磁盘： 手动调用sync()或者fsync()系统调用把脏页写回 pdflush进程会定时把脏页写回到磁盘 同时注意，脏页不能被置换出内存，如果脏页正在被写回，那么会被设置写回标记，这时候该页就被上锁，其他写请求被阻塞直到锁释放。 出处 说明：本文读写操作从底层说起，在后面学习零拷贝等技术时，能有更好的理解！ 转载自：http://www.cnblogs.com/huxiao-tee/p/4657851.html","categories":[{"name":"OS","slug":"OS","permalink":"http://roux.top/categories/OS/"}],"tags":[{"name":"Others","slug":"Others","permalink":"http://roux.top/tags/Others/"}]},{"title":"Linux下文件权限判断和目录操作","slug":"文件权限判断","date":"2017-10-23T16:00:00.000Z","updated":"2018-04-22T05:55:14.758Z","comments":true,"path":"2017/10/24/文件权限判断/","link":"","permalink":"http://roux.top/2017/10/24/文件权限判断/","excerpt":"access函数 说明：按照实际用户ID和实际组进行访问权限测试 头文件：#include &lt;unistd.h&gt; 原型：int access(const char *pathname, int mode)","text":"access函数 说明：按照实际用户ID和实际组进行访问权限测试 头文件：#include &lt;unistd.h&gt; 原型：int access(const char *pathname, int mode) mode取值: F_OK:测试文件是否存在 R_OK:测试读权限 W_OK:测试写权限 X_OK:测试执行权限 返回值：文件路径为空或者不存在返回（失败）-1，成功返回0 示例： 123456789101112131415#define FILESIZE 20int main(int argc, char *argv[])&#123; char fileName[FILESIZE]; bzero(fileName, FILESIZE); printf(\"please input fileName:\"); scanf(\"%s\", &amp;fileName); if(access(fileName, R_OK) == -1)&#123; perror(\"access error:\"); exit(1); &#125; return 0;&#125; opendir函数与readdir函数 说明： opendir()用来打开参数name 指定的目录, 并返回DIR*形态的目录流, 和open()类似, 接下来对目录的读取和搜索都要使用此返回值 readdir()返回参数dir 目录流的下个目录进入点 头文件：#include &lt;sys/types.h&gt; #include &lt;dirent.h&gt; 原型： DIR *opendir（const char *name） struct dirent * readdir(DIR * dir) DIR结构体： 12345678910111213struct __dirstream&#123; void *__fd; char *__data; int __entry_data; char *__ptr; int __entry_ptr; size_t __allocation; size_t __size; __libc_lock_define (, __lock)&#125;;typedef struct __dirstream DIR; diret结构体： 12345678struct dirent&#123; ino_t d_ino; //d_ino 此目录进入点的inode ff_t d_off; //d_off 目录文件开头至此目录进入点的位移 signed short int d_reclen; //d_reclen _name 的长度, 不包含NULL 字符 unsigned char d_type; //d_type d_name 所指的文件类型 d_name 文件名 har d_name[256];&#125;; 返回值： opendir()函数成功则返回DIR* 型态的目录流, 打开失败则返回NULL readdir()函数成功则返回下个目录进入点. 有错误发生或读取到目录文件尾则返回NULL 错误代码： EACCESS 权限不足。 EMFILE 已达到进程可同时打开的文件数上限。 ENFILE 已达到系统可同时打开的文件数上限。 ENOTDIR 参数name 非真正的目录。 ENOENT 参数name 指定的目录不存在, 或是参数name 为一空字符串。 ENOMEM 核心内存不足。 注意： 在操作完毕后，记住调用int closedir(DIR *dir)函数进行关闭 示例： 123456789101112131415#include &lt;sys/types.h&gt;#include &lt;dirent.h&gt;#include &lt;unistd.h&gt;int main(void)&#123; DIR *dir; struct dirent *ptr; int i = 0; dir = opendir(\"/etc/rc.d\"); while((ptr = readdir(dir)) != NULL)&#123; printf(\"d_name : %s\\n\", ptr-&gt;d_name); &#125; closedir(dir);&#125;","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"Function","slug":"Function","permalink":"http://roux.top/tags/Function/"}]},{"title":"stat系列函数","slug":"stat系列函数","date":"2017-10-23T16:00:00.000Z","updated":"2018-04-22T05:53:30.857Z","comments":true,"path":"2017/10/24/stat系列函数/","link":"","permalink":"http://roux.top/2017/10/24/stat系列函数/","excerpt":"前言 说明： stat系列函数有三种情况:分别对应文件名称(stat)、文件描述符(fstat)和符号链接文件(lstat) stat结构：(不同的Linux下有小的区别，不影响使用) 123456789101112131415struct stat &#123; mode_t st_mode; // 文件权限和文件类型信息 ino_t st_ino; // 与该文件关联的inode dev_t st_dev; // 保存文件的设备 number(filesystem) dev_t st_rdev; // 若此文件为装置设备文件, 则为其设备编号 nlink_t st_nlink; // 该文件上硬连接的个数 uid_t st_uid; // 文件属主的UID号 gid_t st_gid; // 文件属主的GID号 off_t st_size; // 普通文件的大小 time_t st_atime; // 文件上一次被访问的时间 time_t st_mtime; // 文件的内容上一次被修改的时间 time_t st_ctime; // 文件的权限、属主、组或内容上一次被修改的时间 long st_blksize; // I/O 文件系统的I/O 缓冲区大小 long st_blocks; // 占用文件区块的个数, 每一区块大小为512 个字节&#125;;","text":"前言 说明： stat系列函数有三种情况:分别对应文件名称(stat)、文件描述符(fstat)和符号链接文件(lstat) stat结构：(不同的Linux下有小的区别，不影响使用) 123456789101112131415struct stat &#123; mode_t st_mode; // 文件权限和文件类型信息 ino_t st_ino; // 与该文件关联的inode dev_t st_dev; // 保存文件的设备 number(filesystem) dev_t st_rdev; // 若此文件为装置设备文件, 则为其设备编号 nlink_t st_nlink; // 该文件上硬连接的个数 uid_t st_uid; // 文件属主的UID号 gid_t st_gid; // 文件属主的GID号 off_t st_size; // 普通文件的大小 time_t st_atime; // 文件上一次被访问的时间 time_t st_mtime; // 文件的内容上一次被修改的时间 time_t st_ctime; // 文件的权限、属主、组或内容上一次被修改的时间 long st_blksize; // I/O 文件系统的I/O 缓冲区大小 long st_blocks; // 占用文件区块的个数, 每一区块大小为512 个字节&#125;; st_mode相关宏(这些宏就是一些特定位置为1的二进制数的定义,用它们和st_mode进行”&amp;”操作，从而就可以得到某些特定的信息) 文件类型标志 S_IFBLK：文件是一个特殊的块设备 S_IFDIR：文件是一个目录 S_IFCHR：文件是一个特殊的字符设备 S_IFIFO：文件是一个FIFO设备 S_IFREG：文件是一个普通文件（REG即使regular啦） S_IFLNK：文件是一个符号链接 用于解释st_mode标志的掩码 S_IFMT：文件类型 S_IRWXU：属主的读/写/执行权限，可以分成S_IXUSR, S_IRUSR, S_IWUSR S_IRWXG：属组的读/写/执行权限，可以分成S_IXGRP, S_IRGRP, S_IWGRP S_IRWXO：其他用户的读/写/执行权限，可以分为S_IXOTH, S_IROTH, S_IWOTH 我们可以通过stat获取文件的类型和文件大小等信息。文件类型有：普通文件、目录文件、块特殊文件、字符特殊文件、FIFO、套接字和符号链接。要想通过stat系列函数来判断文件或者目录是否存在，当执行stat函数，如果文件存在时，还需进一步判断该文件是普通文件还是目录文件 错误代码： ENOENT 参数file_name 指定的文件不存在 ENOTDIR 路径中的目录存在但却非真正的目录 ELOOP 欲打开的文件有过多符号连接问题, 上限为16 符号连接 EFAULT 参数buf 为无效指针, 指向无法存在的内存空间 EACCESS 存取文件时被拒绝 ENOMEM 核心内存不足 ENAMETOOLONG 参数file_name 的路径名称太长 stat系列函数 头文件：#include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;sys.stat.h&gt; 原型： int stat(const char *path, struct stat *buf) int fstat(int fd, struct stat *buf) int lstat(const char *path, struct stat *buf) 说明： stat() 用来将参数 path 所指的文件状态, 复制到参数 buf 所指的结构中 fstat() 用来将参数 fd 所指的文件状态, 复制到参数 buf 所指的结构中(struct stat) lstat() 与 stat()作用完全相同, 都是取得参数 path 所指的文件状态, 其差别在于, 当文件为符号连接时, lstat()会返回该 link 本身的状态 返回值：若成功则为0，若出错则为-1 示例： 123456789101112131415161718#include &lt;sys/stat.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main(void)&#123; struct stat buf; stat(\"/etc/hosts\", &amp;buf); printf(\"stat: /etc/hosts file size = %d\\n\", buf.st_size); int filefd = open(\"test.txt\", O_RDONLY); fstat(filefd, &amp;buf); printf(\"fstat: /etc/hosts file size = %d\\n\", buf.st_size); lstat(\"/etc/hosts\", &amp;buf); printf(\"lstat: /etc/hosts file size = %d\\n\", buf.st_size); return 0;&#125;","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"Function","slug":"Function","permalink":"http://roux.top/tags/Function/"}]},{"title":"零拷贝技术分析","slug":"零拷贝技术","date":"2017-10-23T16:00:00.000Z","updated":"2018-04-22T05:57:14.073Z","comments":true,"path":"2017/10/24/零拷贝技术/","link":"","permalink":"http://roux.top/2017/10/24/零拷贝技术/","excerpt":"前言 传统的 Linux 操作系统的标准 I/O 接口是基于数据拷贝操作的，即 I/O 操作会导致数据在操作系统内核地址空间的缓冲区和应用程序地址空间定义的缓冲区之间进行传输。这样做最大的好处是可以减少磁盘 I/O 的操作，因为如果所请求的数据已经存放在操作系统的高速缓冲存储器中，那么就不需要再进行实际的物理磁盘 I/O 操作。但是数据传输过程中的数据拷贝操作却导致了极大的 CPU 开销，限制了操作系统有效进行数据传输操作的能力。 零拷贝（ zero-copy ）这种技术可以有效地改善数据传输的性能，在内核驱动程序（比如网络堆栈或者磁盘存储驱动程序）处理 I/O 数据的时候，零拷贝技术可以在某种程度上减少甚至完全避免不必要的 CPU 数据拷贝操作。现代的 CPU 和存储体系结构提供了很多特征可以有效地实现零拷贝技术，但是因为存储体系结构非常复杂，而且网络协议栈有时需要对数据进行必要的处理，所以零拷贝技术有可能会产生很多负面的影响，甚至会导致零拷贝技术自身的优点完全丧失。","text":"前言 传统的 Linux 操作系统的标准 I/O 接口是基于数据拷贝操作的，即 I/O 操作会导致数据在操作系统内核地址空间的缓冲区和应用程序地址空间定义的缓冲区之间进行传输。这样做最大的好处是可以减少磁盘 I/O 的操作，因为如果所请求的数据已经存放在操作系统的高速缓冲存储器中，那么就不需要再进行实际的物理磁盘 I/O 操作。但是数据传输过程中的数据拷贝操作却导致了极大的 CPU 开销，限制了操作系统有效进行数据传输操作的能力。 零拷贝（ zero-copy ）这种技术可以有效地改善数据传输的性能，在内核驱动程序（比如网络堆栈或者磁盘存储驱动程序）处理 I/O 数据的时候，零拷贝技术可以在某种程度上减少甚至完全避免不必要的 CPU 数据拷贝操作。现代的 CPU 和存储体系结构提供了很多特征可以有效地实现零拷贝技术，但是因为存储体系结构非常复杂，而且网络协议栈有时需要对数据进行必要的处理，所以零拷贝技术有可能会产生很多负面的影响，甚至会导致零拷贝技术自身的优点完全丧失。 为什么需要零拷贝技术 如今，很多网络服务器都是基于客户端 - 服务器(C-S)这一模型的。在这种模型中，客户端向服务器端请求数据或者服务；服务器端则需要响应客户端发出的请求，并为客户端提供它所需要的数据。随着网络服务的逐渐普及，video 这类应用程序发展迅速。当今的计算机系统已经具备足够的能力去处理 video 这类应用程序对客户端所造成的重负荷，但是对于服务器端来说，它应付由 video 这类应用程序引起的网络通信量就显得捉襟见肘了。而且，客户端的数量增长迅速，那么服务器端就更容易成为性能瓶颈。而对于负荷很重的服务器来说，操作系统通常都是引起性能瓶颈的罪魁祸首。举个例子来说，当数据“写”操作或者数据“发送”操作的系统调用发出时，操作系统通常都会将数据从应用程序地址空间的缓冲区拷贝到操作系统内核的缓冲区中去。操作系统这样做的好处是接口简单，但是却在很大程度上损失了系统性能，因为这种数据拷贝操作不单需要占用 CPU 时间片，同时也需要占用额外的内存带宽。 一般来说，客户端通过网络接口卡向服务器端发送请求，操作系统将这些客户端的请求传递给服务器端应用程序，服务器端应用程序会处理这些请求，请求处理完成以后，操作系统还需要将处理得到的结果通过网络适配器传递回去。 Linux中传统服务器进行数据传输的流程 Linux中传统的 I/O 操作是一种缓冲 I/O，I/O 过程中产生的数据传输通常需要在缓冲区中进行多次的拷贝操作。一般来说，在传输数据的时候，用户应用程序需要分配一块大小合适的缓冲区用来存放需要传输的数据。应用程序从文件中读取一块数据，然后把这块数据通过网络发送到接收端去。用户应用程序只是需要调用两个系统调用 read() 和 write() 就可以完成这个数据传输操作，应用程序并不知晓在这个数据传输的过程中操作系统所做的数据拷贝操作。对于 Linux 操作系统来说，基于数据排序或者校验等各方面因素的考虑，操作系统内核会在处理数据传输的过程中进行多次拷贝操作。在某些情况下，这些数据拷贝操作会极大地降低数据传输的性能，如：(如果我们需要传递的是一个容量很大的数据，它们不能长期存储于内存中，就会涉及到从磁盘取出，然后传递给目标进程，目标进程再把数据发给磁盘或socket fd的情景。在这个情况下，由于多次数据复制和CPU状态的切换，会导致数据传输性能低下，严重制约整体服务的负载能力)。 当应用程序需要访问某块数据的时候，操作系统内核会先检查这块数据是不是因为前一次对相同文件的访问而已经被存放在操作系统内核地址空间的缓冲区内，如果在内核缓冲区中找不到这块数据，Linux 操作系统内核会先将这块数据从磁盘读出来放到操作系统内核的缓冲区里去。如果这个数据读取操作是由 DMA 完成的，那么在 DMA 进行数据读取的这一过程中，CPU 只是需要进行缓冲区管理，以及创建和处理 DMA ，除此之外，CPU 不需要再做更多的事情，DMA 执行完数据读取操作之后，会通知操作系统做进一步的处理。Linux 操作系统会根据 read() 系统调用指定的应用程序地址空间的地址，把这块数据存放到请求这块数据的应用程序的地址空间中去，在接下来的处理过程中，操作系统需要将数据再一次从用户应用程序地址空间的缓冲区拷贝到与网络堆栈相关的内核缓冲区中去，这个过程也是需要占用 CPU 的。数据拷贝操作结束以后，数据会被打包，然后发送到网络接口卡上去。在数据传输的过程中，应用程序可以先返回进而执行其他的操作。之后，在调用 write() 系统调用的时候，用户应用程序缓冲区中的数据内容可以被安全的丢弃或者更改，因为操作系统已经在内核缓冲区中保留了一份数据拷贝，当数据被成功传送到硬件上之后，这份数据拷贝就可以被丢弃。 从上面的描述可以看出，在这种传统的数据传输过程中，数据至少发生了四次拷贝操作，即便是使用了 DMA 来进行与硬件的通讯，CPU 仍然需要访问数据两次。在 read() 读数据的过程中，数据并不是直接来自于硬盘，而是必须先经过操作系统的文件系统层。在 write() 写数据的过程中，为了和要传输的数据包的大小相吻合，数据必须要先被分割成块，而且还要预先考虑包头，并且要进行数据校验和操作。 零拷贝（zero copy）技术概述 什么是零拷贝？ 简单一点来说，零拷贝就是一种避免 CPU 将数据从一块存储拷贝到另外一块存储的技术。针对操作系统中的设备驱动程序、文件系统以及网络协议堆栈而出现的各种零拷贝技术极大地提升了特定应用程序的性能，并且使得这些应用程序可以更加有效地利用系统资源。这种性能的提升就是通过在数据拷贝进行的同时，允许 CPU 执行其他的任务来实现的。零拷贝技术可以减少数据拷贝和共享总线操作的次数，消除传输数据在存储器之间不必要的中间拷贝次数，从而有效地提高数据传输效率。而且，零拷贝技术减少了用户应用程序地址空间和操作系统内核地址空间之间因为上下文切换而带来的开销。进行大量的数据拷贝操作其实是一件简单的任务，从操作系统的角度来说，如果 CPU 一直被占用着去执行这项简单的任务，那么这将会是很浪费资源的；如果有其他比较简单的系统部件可以代劳这件事情，从而使得 CPU 解脱出来可以做别的事情，那么系统资源的利用则会更加有效。综上所述，零拷贝技术的目标可以概括如下： 避免数据拷贝 避免操作系统内核缓冲区之间进行数据拷贝操作。 避免操作系统内核和用户应用程序地址空间这两者之间进行数据拷贝操作。 用户应用程序可以避开操作系统直接访问硬件存储。 数据传输尽量让 DMA 来做。 将多种操作结合在一起 避免不必要的系统调用和上下文切换。 需要拷贝的数据可以先被缓存起来。 对数据进行处理尽量让硬件来做。 前文提到过，对于高速网络来说，零拷贝技术是非常重要的。这是因为高速网络的网络链接能力与 CPU 的处理能力接近，甚至会超过 CPU 的处理能力。如果是这样的话，那么 CPU 就有可能需要花费几乎所有的时间去拷贝要传输的数据，而没有能力再去做别的事情，这就产生了性能瓶颈，限制了通讯速率，从而降低了网络链接的能力。一般来说，一个 CPU 时钟周期可以处理一位的数据。举例来说，一个 1 GHz 的处理器可以对 1Gbit/s 的网络链接进行传统的数据拷贝操作，但是如果是 10 Gbit/s 的网络，那么对于相同的处理器来说，零拷贝技术就变得非常重要了。对于超过 1 Gbit/s 的网络链接来说，零拷贝技术在超级计算机集群以及大型的商业数据中心中都有所应用。然而，随着信息技术的发展，1 Gbit/s，10 Gbit/s 以及 100 Gbit/s 的网络会越来越普及，那么零拷贝技术也会变得越来越普及，这是因为网络链接的处理能力比 CPU 的处理能力的增长要快得多。传统的数据拷贝受限于传统的操作系统或者通信协议，这就限制了数据传输性能。零拷贝技术通过减少数据拷贝次数，简化协议处理的层次，在应用程序和网络之间提供更快的数据传输方法，从而可以有效地降低通信延迟，提高网络吞吐率。零拷贝技术是实现主机或者路由器等设备高速网络接口的主要技术之一。 现代的 CPU 和存储体系结构提供了很多相关的功能来减少或避免 I/O 操作过程中产生的不必要的 CPU 数据拷贝操作，但是，CPU 和存储体系结构的这种优势经常被过高估计。存储体系结构的复杂性以及网络协议中必需的数据传输可能会产生问题，有时甚至会导致零拷贝这种技术的优点完全丧失。 零拷贝技术分类 零拷贝技术的发展很多样化，现有的零拷贝技术种类也非常多，而当前并没有一个适合于所有场景的零拷贝技术的出现。对于 Linux 来说，现存的零拷贝技术也比较多，这些零拷贝技术大部分存在于不同的 Linux 内核版本，有些旧的技术在不同的 Linux 内核版本间得到了很大的发展或者已经渐渐被新的技术所代替。本文针对这些零拷贝技术所适用的不同场景对它们进行了划分。概括起来，Linux 中的零拷贝技术主要有下面这几种： 直接 I/O：对于这种数据传输方式来说，应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输：这类零拷贝技术针对的是操作系统内核并不需要对数据进行直接处理的情况，数据可以在应用程序地址空间的缓冲区和磁盘之间直接进行传输，完全不需要 Linux 操作系统内核提供的页缓存的支持。 在数据传输的过程中，避免数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间进行拷贝。有的时候，应用程序在数据进行传输的过程中不需要对数据进行访问，那么，将数据从 Linux 的页缓存拷贝到用户进程的缓冲区中就可以完全避免，传输的数据在页缓存中就可以得到处理。在某些特殊的情况下，这种零拷贝技术可以获得较好的性能。Linux 中提供类似的系统调用主要有 mmap()，sendfile() 以及 splice()。 对数据在 Linux 的页缓存和用户进程的缓冲区之间的传输过程进行优化。该零拷贝技术侧重于灵活地处理数据在用户进程的缓冲区和操作系统的页缓存之间的拷贝操作。这种方法延续了传统的通信方式，但是更加灵活。在 Linux 中，该方法主要利用了写时复制技术。 总结 前两类方法的目的主要是为了避免应用程序地址空间和操作系统内核地址空间这两者之间的缓冲区拷贝操作。这两类零拷贝技术通常适用在某些特殊的情况下，比如要传送的数据不需要经过操作系统内核的处理或者不需要经过应用程序的处理。第三类方法则继承了传统的应用程序地址空间和操作系统内核地址空间之间数据传输的概念，进而针对数据传输本身进行优化。 我们知道，硬件和软件之间的数据传输可以通过使用 DMA 来进行，DMA 进行数据传输的过程中几乎不需要 CPU 参与，这样就可以把 CPU 解放出来去做更多其他的事情，但是当数据需要在用户地址空间的缓冲区和 Linux 操作系统内核的页缓存之间进行传输的时候，并没有类似 DMA 这种工具可以使用，CPU 需要全程参与到这种数据拷贝操作中，所以第三类方法的目的是可以有效地改善数据在用户地址空间和操作系统内核地址空间之间传递的效率。 DMA解释 DMA(Direct Memory Access，直接内存存取) 是所有现代电脑的重要特色，它允许不同速度的硬件装置来沟通，而不需要依赖于 CPU 的大量中断负载。否则，CPU 需要从来源把每一片段的资料复制到暂存器，然后把它们再次写回到新的地方。在这个时间中，CPU 对于其他的工作来说就无法使用 出处 说明：本文包含了自己的理解与参考了一些资料的补充 转载自：https://www.ibm.com/developerworks/cn/linux/l-cn-zerocopy1/index.html","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"零拷贝","slug":"零拷贝","permalink":"http://roux.top/tags/零拷贝/"}]},{"title":"C语言NULL和0的区别详解","slug":"NULL和0的区别详解","date":"2017-10-16T16:00:00.000Z","updated":"2018-04-22T05:58:50.258Z","comments":true,"path":"2017/10/17/NULL和0的区别详解/","link":"","permalink":"http://roux.top/2017/10/17/NULL和0的区别详解/","excerpt":"分析0 would digit zero, that is, a numerical value. &apos;0&apos; could be the character capital oh or the character zero. For example: char word[10] = &quot;Oxford&quot;; char number[10] = &quot;01234&quot;; Depending on typeface used &apos;O&apos; may look exactly like &apos;0&apos; making it difficult to tell them apart out of context. &apos;\\0&apos; is the null character used to terminate strings in C/C++. &quot;\\0&quot; is an empty string. 在C语言及其派生语言中，\\0不是一个单独的转义序列，而是一个以八进制表示常数，而常数的数值为0，\\0后面不能接0至7的数字，不然会视为是一个八进制的数字。","text":"分析0 would digit zero, that is, a numerical value. &apos;0&apos; could be the character capital oh or the character zero. For example: char word[10] = &quot;Oxford&quot;; char number[10] = &quot;01234&quot;; Depending on typeface used &apos;O&apos; may look exactly like &apos;0&apos; making it difficult to tell them apart out of context. &apos;\\0&apos; is the null character used to terminate strings in C/C++. &quot;\\0&quot; is an empty string. 在C语言及其派生语言中，\\0不是一个单独的转义序列，而是一个以八进制表示常数，而常数的数值为0，\\0后面不能接0至7的数字，不然会视为是一个八进制的数字。 NULL和0的值都是一样的，但是为了目的和用途及容易识别的原因，NULL用于指针和对象，0用于数值。对于字符串的结尾，使用’\\0’，它的值也是0，但是让人一看就知道这是字符串的结尾，不是指针，也不是普通的数值。 在不同的系统中，NULL并非总是和0等同，NULL仅仅代表空值，也就是指向一个不被使用的地址，在大多数系统中，都将0作为不被使用的地址，所以就有了类似这样的定义。但并非总是如此，也有些系统不将0地址作为NULL，而是用其他的地址，所以说，千万别将NULL和0等价起来，特别是在一些跨平台的代码中，这更是将给你带来灾难 #define NULL 0 空指针常量An integer constant expression with the value 0, or such an expression cast to type void *, is called a null pointer constant NULL在stdio.h中的定义： 1234567#if !defined(NULL) &amp;&amp; defined(__NEEDS_NULL)#ifdef __cplusplus#define NULL 0#else#define NULL ((void *)0)#endif#endif 在c++定义为0，在c中定义为(void *)0;的原因： 注意： 0、0L、’\\0’、3 - 3、0 * 17 （它们都是“integer constant expression”）以及 (void*)0 等都是空指针常量（注意 (char*) 0 不叫空指针常量，只是一个空指针值） 一般的 C 系统选择 (void*)0 或者 0 的居多（也有个别的选择 0L）；至于 C++ 系统，由于存在严格的类型转化的要求，void* 不能象 C 中那样自由转换为其它指针类型，所以通常选 0 作为空指针常量 3.空指针If a null pointer constant is converted to a pointer type, the resulting pointer, called a null pointer, is guaranteed to compare unequal to a pointer to any object or function. char *p=0；此时p就是一个空指针，不指向任何实际对象。因此，如果 p 是一个指针变量，则 p = 0;、p = 0L;、p = ‘\\0’;、p = 3 - 3;、p = 0 * 17; 中的任何一种赋值操作之后(对于 C 来说还可以是 p = (void*)0;)，p 都成为一个空指针，由系统保证空指针不指向任何实际的对象或者函数。反过来说，任何对象或者函数的地址都不可能是空指针。（tyc: 比如这里的(void*)0就是一个空指针 NULLThe macro NULL is defined in &lt;stddef.h&gt; (and other headers) as a null pointer constant 即 NULL 是一个标准规定的宏定义，用来表示空指针常量。因此，除了上面的各种赋值方式之外，还可以用 p = NULL; 来使 p 成为一个空指针。（tyc：很多系统中的实现：#define NULL (void*)0，与这里的“a null pointer constant”并不是完全一致的） 空指针的内部实现 标准并没有对空指针指向内存中的什么地方这一个问题作出规定，我们常见的空指针一般指向 0 地址，即空指针的内部用全 0 来表示（zero null pointer，零空指针）；也有一些系统用一些特殊的地址值或者特殊的方式表示空指针（nonzero null pointer，非零空指针） 注意：不要把空指针的内部表示等同于整数 0 的对象表示 判断一个指针是否是一个空指针 假设 p 是一个指针变量，q 是一个同类型的空指针，要检查 p 是否是一个空指针，可以采用下列任意形式之一 if ( p == 0 ) if ( p == &apos;\\0&apos; ) if ( p == 3 - 3 ) if ( p == NULL ) if ( NULL == p ) if ( !p ) if ( p == q ) 注意：不可以用 memset 函数来得到一个空指针。因为有的系统存在着“非零空指针” （nonzero null pointer），所以这时 memset( &amp;p, 0, sizeof(p) ); 和 p = 0; 这两者不等价 自定义NULLIf the program declares or defines an identifier in a context in which it is reserved (other than as allowed by 7.1.4), or defines a reserved identifier as a macro name, the behavior is undefined. 所以，如果包含了相应的标准头文件而引入了 NULL 的话，则再在程序中重新定义NULL为不同的内容是非法的，其行为是未定义的。即NULL只能是 0 malloc分配内存失败的的返回If the space cannot be allocated, a null pointer is returned. malloc 函数是标准C规定的库函数。在标准中明确规定了在其内存分配失败时返回的是一个 “null pointer”（空指针） 字符的结束符’\\0’ ‘\\0’是C++中字符串的结尾标志，存储在字符串的结尾。 eg: char cha[5]表示可以放5个字符的字符串，由于c/c++中规定字符串的结尾标志为’\\0’,它虽然不计入串长，但要占内存空间. 一个汉字一般用两个字节表示，且c/c++中如一个数组cha[5]，有5个变量，分别是 cha[0] , cha[1] , cha[2] , cha[3] , cha[4] , 所以cha[5]可以放5个字母或者放2个汉字（1个汉字占2个字节，1个字母占一个字节），cha[5]占5个字节内存空间. 参考文章链接： http://www.cnblogs.com/youxin/archive/2012/03/27/2420023.html https://zh.wikipedia.org/wiki/%E7%A9%BA%E5%AD%97%E7%AC%A6","categories":[{"name":"C","slug":"C","permalink":"http://roux.top/categories/C/"}],"tags":[{"name":"Others","slug":"Others","permalink":"http://roux.top/tags/Others/"}]},{"title":"进程的终止方式","slug":"进程的终止方式","date":"2017-10-15T16:00:00.000Z","updated":"2018-04-22T05:56:50.592Z","comments":true,"path":"2017/10/16/进程的终止方式/","link":"","permalink":"http://roux.top/2017/10/16/进程的终止方式/","excerpt":"终止类别 正常终止 从main函数返回 调用exit(标准c库函数) 调用_exit或者_Exit(系统调用) 最后一个线程从其启动例程(进程)返回 启动例程会搜集命令行参数给main传参，并搜集环境信息构建环境表给main函数，还会登记进程的终止函数 在进程的main函数执行前内核会启动 编译器在编译时会将启动例程编译进可执行文件中 最后一个线程调用pthread_exit","text":"终止类别 正常终止 从main函数返回 调用exit(标准c库函数) 调用_exit或者_Exit(系统调用) 最后一个线程从其启动例程(进程)返回 启动例程会搜集命令行参数给main传参，并搜集环境信息构建环境表给main函数，还会登记进程的终止函数 在进程的main函数执行前内核会启动 编译器在编译时会将启动例程编译进可执行文件中 最后一个线程调用pthread_exit 异常终止 调用abort 接收到一个信号并终止 最后一个线程对取消请求做处理响应 进程返回 通常进程运行成功返回0，否则返回非0 在shell中可以查看进程的返回值(echo $?) 自定义终止函数 atexit函数 原型：int atexit(void (*function) (void)); 返回：成功返回0，出错返回-1 功能：向内核登记终止函数 注意： 每个启动的进程都默认的登记了一个标准的终止函数 终止函数在进程终止时释放进程所占用的一些资源 登记的多个终止函数的执行顺序是以栈的方式进行，即先登记后执行 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;//定义进程的终止函数void term_fun1(void)&#123; printf(\"first term fucntion\\n\");&#125;void term_fun2(void)&#123; printf(\"second term fucntion\\n\");&#125;void term_fun3(void)&#123; printf(\"third term fucntion\\n\");&#125;int main(int argc, char *argv[])&#123; if(argc &lt; 3)&#123; fprintf(stderr, \"usage: %s file [exit|_exit|return]\\n\", argv[0]); exit(1); &#125; //向内核登记终止函数 atexit(term_fun1); atexit(term_fun2); atexit(term_fun3); FILE *fp = fopen(argv[1], \"w\"); fprintf(fp, \"hello iotek\"); //全缓存函数 if(!strcmp(argv[2], \"exit\"))&#123; exit(0); &#125; else if(!strcmp(argv[2], \"_exit\"))&#123; _exit(0); &#125; else if(!strcmp(argv[2], \"return\"))&#123; return 0; &#125; else&#123; fprintf(stderr, \"usage: %s file [exit|_exit|return]\\n\", argv[0]); &#125;&#125; 运行测试 return 说明：前面说过终止函数的方式是以栈的方式进行，所以看到3,2,1的顺序 exit 说明：前面说过终止函数的方式是以栈的方式进行，所以看到3,2,1的顺序，和return不同的是只释放一次资源 _exit(_Exit) 说明：在调用的时候，因为fprintf是c语言的带缓冲的库函数，所以存放数据是先存放在自己的缓冲区，等待写满，但是在这之前调用_exit函数导致没有清缓存，最终文件里面也没有数据 总结 return exit _exit (_Exit) 是否刷新标准I/O缓存 是 是 否 是否自动调用终止函数 是 是 否 注意：在网络编程时，调用return几次，就释放几次内核资源，调用exit多次，只释放一次。","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"进程","slug":"进程","permalink":"http://roux.top/tags/进程/"}]},{"title":"mem函数源码","slug":"mem博客总结","date":"2017-10-14T16:00:00.000Z","updated":"2018-04-22T05:51:58.781Z","comments":true,"path":"2017/10/15/mem博客总结/","link":"","permalink":"http://roux.top/2017/10/15/mem博客总结/","excerpt":"memcpy函数 原型：void *memcpy(void *dest, const void *src, int count) 作用：由src指定内存区域拷贝count个字符到dest所指定的内存区域。 代码： 1234567891011121314151617181920212223void *my_memcpy(void *dest, const void *src, int count)&#123; /*由src指定内存区域拷贝count个字符到dest所指定的内存区域。 src和dest内存区域不能重叠，函数返回指向dest的指针。*/ //拷贝完成不会自动加上'\\0' unsigned char *p = (unsigned char *)dest; unsigned char *q = (unsigned char *)src; while(count--) &#123; *p++ = *q++; &#125; return dest;&#125;int main()&#123; char a[20]; char *p; p = (char *)my_memcpy(a, \"hello world!\", 12); *(p+12) = '\\0'; //为puts做准备 puts(a); return 0;&#125;","text":"memcpy函数 原型：void *memcpy(void *dest, const void *src, int count) 作用：由src指定内存区域拷贝count个字符到dest所指定的内存区域。 代码： 1234567891011121314151617181920212223void *my_memcpy(void *dest, const void *src, int count)&#123; /*由src指定内存区域拷贝count个字符到dest所指定的内存区域。 src和dest内存区域不能重叠，函数返回指向dest的指针。*/ //拷贝完成不会自动加上'\\0' unsigned char *p = (unsigned char *)dest; unsigned char *q = (unsigned char *)src; while(count--) &#123; *p++ = *q++; &#125; return dest;&#125;int main()&#123; char a[20]; char *p; p = (char *)my_memcpy(a, \"hello world!\", 12); *(p+12) = '\\0'; //为puts做准备 puts(a); return 0;&#125; memccpy函数 原型：void *memccpy(void *dest, const void *src, char ch, int count) 作用：如果src前n个字节中存在’ch’，返回指向字符’ch’后的第一个字符的指针；返回NULL，并且复制src。 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;string.h&gt;void *my_memccpy(void *dest, const void *src, char ch, int count)&#123; /*如果src前n个字节中存在’ch’，返回指向字符’ch’后的第一个字符的指针； 返回NULL，并且复制src。 一个条件达到就结束*/ //对于数字字符，遇见空格则停止，并返回指向空格的指针 while(count--) &#123; *(char *)dest = *(char *)src; dest = (char *)dest + 1; if(*(char *)src == (char)ch) break; src = (char *)src + 1; &#125; return (count ? (char *)dest : NULL);&#125;int main()&#123; char a[20]; char *p; char *str =\"hello world!\"; char ch; ch = '9'; p = (char *)my_memccpy(a, str, ch, strlen(str)+1); if(p == NULL) printf(\"Can't not find character.\\n\"); else &#123; printf(\"Find the character! \\n\"); *p= '\\0'; //为下面的puts函数准备 &#125; printf(\"The String which has been copied is: \"); puts(a); //puts()从string的开头往stdout中输出字符，直到遇见结束标志 '\\0'，'\\0'不会被输出到stdout。 printf(\"************************************\"); ch = 'b'; p = (char *)my_memccpy(a, str, ch, strlen(str)+1); if(p == NULL) printf(\"Can't not find character.\\n\"); else &#123; printf(\"\\nFind the character! \\n\"); *p = '\\0'; &#125; printf(\"The String which has been copied is: \"); puts(a); return 0;&#125; memmove函数 原型：void *memmove(void *dest, const void *src, int count) 作用：由src所指定的内存区域赋值count个字符到dest所指定的内存区域。src和dest所指内存区域可以重叠 代码： 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;string.h&gt;void * my_memmove(void *dest, const void *src, int count)&#123; /*由src所指定的内存区域赋值count个字符到dest所指定的内存区域。 src和dest所指内存区域可以重叠， 但复制后src的内容会被更改,最终函数返回指向dest的指针。*/ //可以自己考虑count的大小，大于0，小于src的大小 if((unsigned char *)dest &gt;= ((unsigned char *)src + count)) &#123; /*若果没有重叠*/ dest = memcpy (dest, src, count); &#125; else &#123; /*如果有重叠,则从尾部进行拷贝*/ unsigned char *p = (unsigned char *)dest + count; unsigned char *q = (unsigned char *)src + count; while (count--) &#123; *--p = *--q; &#125; &#125; return dest;&#125;int main()&#123; /*正常的复制*/ char a[20]; puts((char *)my_memmove(a, \"hello world!\", 16)); /*内存重叠*/ char str[] = \"memmove can be very useful......\"; my_memmove (str+20, str+15, 11); puts (str); return 0;&#125; memcmp函数 原型：int memcmp(const void *buffer1, const void *buffer2, int count) 作用：比较内存区域buffer1和buffer2的前count个字节。 代码： 123456789101112131415161718192021222324252627282930313233343536int my_memcmp(const void *buffer1, const void *buffer2, int count)&#123; /*比较内存区域buffer1和buffer2的前count个字节。 当buffer1 &lt; buffer2时，返回值 &lt; 0； 当buffer1 = buffer2时，返回值 0； 当buffer1 &gt; buffer2时，返回值 &gt; 0。*/ if(!count) return 0; while(--count &amp;&amp; *(char *)buffer1 == *(char *)buffer2) &#123; //判断前count个字符是否相等 buffer1 = (char *)buffer1 + 1; buffer2 = (char *)buffer2 + 1; &#125; //返回两个字符串的首个字符的差值 return ( *((unsigned char *)buffer1) - *((unsigned char *)buffer2) );&#125;int main()&#123; char *str1 = \"hello\"; char *str2 = \"world\"; int n = 0; scanf(\"%d\", &amp;n); int res = my_memcmp(str1, str2, n); if(res &gt; 0) printf(\"%s Upper Than %s\\n\", str1, str2); else if(res &lt; 0) printf(\"%s Lower Than %s\\n\", str1, str2); else printf(\"%s Equal %s\\n\", str1, str2); return 0;&#125; memchr函数 原型：void *memchr(const void *buffer, int ch, int count) 作用：从buffer所指内存区域的前count个字节查找字符ch，当第一次遇到字符ch时停止查找。 代码： 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;string.h&gt;void * my_memchr(const void *buffer, int ch, int count)&#123; /*从buffer所指内存区域的前count个字节查找字符ch， 当第一次遇到字符ch时停止查找。 如果成功，返回指向字符ch的指针,否则返回NULL*/ //对于数字字符，遇见空格则停止，并返回指向空格的指针 while(count-- &amp;&amp; (unsigned char)ch != *(unsigned char *)buffer) &#123; buffer = (unsigned char *)buffer + 1; &#125; return(count ? (void *)buffer : NULL);&#125;int main()&#123; char *str = \"hello world!\"; char *p; char ch; ch = '1'; p = (char *)my_memchr(str, ch, strlen(str)+1); if(p == NULL) printf(\"Can't find the character %c !\\n\", ch); else printf(\"Find the character %c !\\n\", *p); ch = 'd'; p = (char *)my_memchr(str ,ch, strlen(str)+1); if(p == NULL) printf(\"Can't find the character %c !\\n\", ch); else printf(\"Find the character %c !\\n\", *p); return 0;&#125; 参考文章链接：http://www.cnblogs.com/jiangyinglin/p/3247087.html","categories":[{"name":"C","slug":"C","permalink":"http://roux.top/categories/C/"}],"tags":[{"name":"Function","slug":"Function","permalink":"http://roux.top/tags/Function/"}]},{"title":"mem函数源码","slug":"str博客总结","date":"2017-10-14T16:00:00.000Z","updated":"2018-06-24T05:10:22.095Z","comments":true,"path":"2017/10/15/str博客总结/","link":"","permalink":"http://roux.top/2017/10/15/str博客总结/","excerpt":"##str函数的源码 ###1、strcpy函数 原型：char * strcpy(char * destin, const char * source) 作用：把source指向的字符串拷贝到destin指向的字符串中 代码： 1234567891011121314151617181920212223char * my_strcpy(char * destin, const char * source)&#123; /***把source指向的字符串拷贝到destin指向的字符串中***/ assert(destin != NULL &amp;&amp; source != NULL); //检查source和destin的指向是否为空 char *tmp = destin; do &#123; *destin++ = *source++ &#125;while(*destin &amp;&amp; *source); //将source指向的字符复制给destin指向的字符 return tmp; //返回指向最终结果的指针&#125;int main()&#123; char destination[100] = &#123;1&#125;; const char *source = \"abcdefgh\"; char *destion = my_strcpy(destination, source); printf(\"%s\\n\", destion); return 0;&#125;","text":"##str函数的源码 ###1、strcpy函数 原型：char * strcpy(char * destin, const char * source) 作用：把source指向的字符串拷贝到destin指向的字符串中 代码： 1234567891011121314151617181920212223char * my_strcpy(char * destin, const char * source)&#123; /***把source指向的字符串拷贝到destin指向的字符串中***/ assert(destin != NULL &amp;&amp; source != NULL); //检查source和destin的指向是否为空 char *tmp = destin; do &#123; *destin++ = *source++ &#125;while(*destin &amp;&amp; *source); //将source指向的字符复制给destin指向的字符 return tmp; //返回指向最终结果的指针&#125;int main()&#123; char destination[100] = &#123;1&#125;; const char *source = \"abcdefgh\"; char *destion = my_strcpy(destination, source); printf(\"%s\\n\", destion); return 0;&#125; ###2、strncpy函数 原型：char * strncpy(char * str1, char * str2, int count) 作用：把str2指向的前count个字符拷贝到str1指向的字符串中 代码： 12345678910111213141516171819202122232425262728#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;assert.h&gt;char * my_strncpy(char * str1, char * str2, int count)&#123; assert(str1 != NULL); //检验str1是否为空 while(count &amp;&amp; (*str1++ = *str2++)) //把str2的前n个字符复制给str1 &#123; count--; //长度随着复制的进行而减少 &#125; while(count--) &#123; *str1++ = '\\0'; //如果str2的长度小于count那就用NULL填充str1的剩余 &#125; return str1;&#125;int main()&#123; char destination[10] = &#123;0&#125;; char *source = \"abcdefgh\"; int count = 5; my_strncpy(destination, source, count); printf(\"%s\\n\", destination); return 0;&#125; ###3、strcmp函数 原型：int strcmp(const char * str1, const char * str2) 作用：比较str1和str2，str1 &gt; str2返回1，str1 == str2返回0 代码： 123456789101112131415161718192021222324252627282930313233int my_strcmp(const char * str1, const char * str2)&#123; /***比较str1和str2，str1 &gt; str2返回大于0的数，str1 == str2返回0，str1 &lt; str2返回小于0的数***/ while( ! ((*str1 != *str2) &amp;&amp; str1 != '\\0')) &#123; //如果str1和str2的字符相等且字符str1没有到末尾则进入循环 str1++; //指针str1向后加一位 str2++; //指针str2向后加一位 &#125; return (*str1 - *str2); //返回跳出循环的str1和str2当前的字符的差值比较的结果(0或1或-1)&#125;int main()&#123; char *buf1 = \"aaaa\", *buf2 = \"aaaab\", *buf3 = \"aaaac\"; int ptr = 0; //定义变量用来存放my_strcmp返回的值 ptr = my_strcmp(buf2, buf1); if (ptr &gt; 0) printf(\"string 2 is bigger than string 1\\n\"); else printf(\"string 2 is smaller than string 1\\n\"); ptr = my_strcmp(buf2, buf3); if (ptr &gt; 0) printf(\"string 2 is bigger than string 3\\n\"); else printf(\"string 2 is smaller than string 3\\n\"); return 0;&#125; ###4、strncmp函数 原型：int strncmp(const char * str1, const char * str2, int count) 作用：比较str1和str2的前n个字符 代码： 12345678910111213141516171819202122232425int my_strncmp(const char * str1, const char * str2, int count)&#123; /***比较str1和str2的前n个字符***/ if(!count) return 0; while(--count &amp;&amp; *str1 &amp;&amp; *str1 == *str2) &#123; str1++; str2++; &#125; return (*str1 - *str2);&#125;int main()&#123; char *str1 = \"China is a nation!\"; char *str2 = \"French is a nation!\"; int count = 5, ptr = 0; ptr = my_strncmp(str1, str2, count); if(ptr != 0) printf(\"str1 is not equal to str2!\\n\"); return 0;&#125; ###5、stricmp函数 原型：int my_stricmp(const char *str1, const char *str2) 作用：不区分大小写的比较str1和str2 代码： 12345678910111213141516171819202122232425262728293031323334353637383940int my_stricmp(const char *str1, const char *str2)&#123; /***不区分大小写的比较str1和str2***/ char ch1 = '0', ch2 = '0'; do &#123; if((ch1 = (unsigned char)(*(str1++))) &gt;= 'A' &amp;&amp; ch1 &lt;= 'Z') ch1 += 0x20; if((ch2 = (unsigned char)(*(str2++))) &gt;= 'A' &amp;&amp; ch2 &lt;= 'Z') ch2 += 0x20; &#125;while(ch1 &amp;&amp; (ch1 == ch2)); // 判断是否相等且str1不为'\\0'，是则进入循环 return (ch1 - ch2); //返回两个数的大小&#125;int main()&#123; char *str1= \"ammana\"; char *str2 = \"bibi\"; char *str3 = \"AMMANA\"; int ptr = 0, ptr1 = 0; ptr = my_stricmp(str1, str2); if(ptr &gt; 0) printf(\"str1 bigger than str2!\\n\"); else printf(\"str1 smaller than str2!\\n\"); ptr1 = my_stricmp(str1, str3); if(ptr1 &gt; 0) printf(\"str1 bigger than str3!\\n\"); else if(ptr1 &lt; 0) printf(\"str1 smaller than str3!\\n\"); else printf(\"str1 equal to str3!\\n\"); return 0;&#125; ###6、strlen函数 原型：unsigned int strlen(const char * str) 作用：计算str的长度并返回 代码： 12345678910111213141516171819202122unsigned int my_strlen(const char * str)&#123; /***计算str的长度并返回***/ unsigned length = 0; //定义无符号变量length统计str的长度 while(*str != '\\0') //判断str指向的字符是否为'\\0' &#123; length++; //长度加1 str++; //指向的地址向后加1位 &#125; return length;&#125;int main()&#123; char * str = \"abcdefgh\"; int len = 0; len = my_strlen(str); printf(\"%d\\n\", len); return 0;&#125; ###7、strcat函数 原型：char * strcat(char* destin, const char *source) 作用：连接两个字符串，将source连接到destin 代码： 12345678910111213141516171819202122232425262728293031char * my_strcat(char* destin, const char *source)&#123; /***连接两个字符串，将source连接到destin***/ char * temp = destin; //定义temp指针变量存放destin的地址 while(*temp) //判断temp字符串是否读到了'\\0' &#123; temp++; //将temp指针读到字符串末尾 &#125; while(*temp++ = *source++) //把source字符串从temp末尾开始复制给temp &#123;&#125;; return temp; //返回链接好的字符串的指针&#125;int main()&#123; /***对函数Strcat的调用***/ char destination[25]; //定义一个大小为25的数组 char *space = \" \", *String = \"C++!\", *Hello = \"Hello\"; strcpy(destination, Hello); //进行拷贝 my_strcat(destination, space); my_strcat(destination, String); printf(\"%s\\n\", destination); //打印最终结果 return 0;&#125; ###8、strchr函数 原型：char * strchr(char * str, const char c) 作用：查找str中c首次出现的位置，并返回位置或者NULL 代码： 12345678910111213141516171819202122232425char * my_strchr(char * str, const char c)&#123; /***查找str中c首次出现的位置，并返回位置或者NULL***/ while(*str != '\\0' &amp;&amp; *str != c) //判断str是否为'\\0'且等于c &#123; str++; &#125; //判断如果str等于c则返回与c匹配的str否则返回NULL return (*str == c ? str : NULL);&#125;int main()&#123; char * string = \"abcdefgh\"; char c = 'd', *ptr = NULL, //存放my_strchr的返回值 ptr = my_strchr(string, c); if(ptr) printf(\"%c\\n\", c); else printf(\"Not Found!\\n\"); return 0;&#125; ###9、strrchr函数 原型：char * strrchr(char * str, const char c) 作用：查找str中c最后一次出现的位置，并返回位置或者NULL 代码： 123456789101112131415161718192021222324252627282930char * my_strrchr(char * str, const char c)&#123; /***查找str中c最后一次出现的位置，并返回位置或者NULL***/ char * end = str + strlen(str); //定义指针end存放str的末尾地址 while(*str != *end &amp;&amp; *end != c) //判断end没有到头部且没找到和c匹配的字符 &#123; end--; //向前进行移动 &#125; if(*end == *str &amp;&amp; *end != c) //如果没找到则返回NULL return NULL; return end;&#125;int main()&#123; char * string = \"abcdefgh\"; char c = 'd', *ptr = NULL, //存放my_strchr的返回值 ptr = my_strrchr(string, c); if(ptr) printf(\"%c\\n\", c); else printf(\"Not Found!\\n\"); return 0;&#125; ###10、strrev函数 原型：char * strrev(char * str) 作用：翻转字符串并返回字符串指针 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657char * my_strrev(char * str)&#123; /***翻转字符串并返回字符串指针***/ assert(str != NULL); char *end = str; char *head = str; char temp = '0'; while(*end++) &#123;&#125;; end--; /* 与end++抵消 */ end--; /* 回跳过结束符'\\0' */ /* 当head和end未重合时，交换它们所指向的字符 */ while(head &lt; end) &#123; temp = *head; *head++ = *end; /* head向尾部移动 */ *end-- = temp; /* end向头部移动 */ &#125; return str;&#125;#if 0/*第二种实现方式*/char * my_strrev(char * str)&#123; /***翻转字符串并返回字符串指针***/ assert(str != NULL); char *end = strlen(str) + str -1; char temp = '0'; while(str &lt; end) &#123; temp = *str; *str = *end; *end = temp; str++; end--; &#125; return str;&#125;#endifint main()&#123; /***只能逆置字符数组，而不能逆置字符串指针指向的字符串， 因为字符串指针指向的是字符串常量，常量不能被修改***/ char str[] = \"Hello World\"; //定义str数组 printf(\"Before reversal: %s\\n\", str); my_strrev(str); printf(\"After reversal: %s\\n\", str); return 0;&#125; ###11、strdup函数 原型：char * strdup(const char * str) 作用：拷贝字符串到新申请的内存中返回内存指针，否则返回NULL 代码： 12345678910111213141516171819202122#include &lt;assert.h&gt;char * my_strdup(const char * str)&#123; /***拷贝字符串到新申请的内存中返回内存指针，否则返回NULL***/ char * temp = (char*)malloc(strlen(str) + 1); //给temp申请内存 assert(str != NULL &amp;&amp; temp != NULL); //进行检查是否为NULL strcpy(temp, str); //进行拷贝 return temp; //返回的内存在堆中需要手动释放内存&#125;int main()&#123; char *str = NULL, *string = \"abcde\"; str = my_strdup(string); printf(\"%s\\n\", str); free(str); //释放内存 return 0;&#125; ###12、strstr函数 原型：char * strstr(const char * str1, char * str2) 作用：查找str2在str1中出现的位置，找到返回位置，否则返回NULL 代码： 1234567891011121314151617181920212223242526272829char * my_strstr(const char * str1, char * str2)&#123; /***查找str2在str1中出现的位置，找到返回位置，否则返回NULL***/ assert(str1 != NULL &amp; str2 != NULL); //检查str1和str2 int len1 = strlen(str1); //定len1来获取str1的长度 int len2 = strlen(str2); //定len2来获取str2的长度 while(len1 &gt;= len2) //必须str1的长度大于str2的长度 &#123; len1--; //str1的长度每一次减去一个 if(!strncmp(str1, str2, len2)) //进行比较str2和str1的前len2个字符 &#123; return str2; //如果匹配返回str2 &#125; str1++; //str1每一次都要向后走一步 &#125; return NULL;&#125;int main()&#123; char *str1 = \"China is a nation!\", *str2 = \"nation\", *ptr = NULL; ptr = my_strstr(str1, str2); printf(\"The string is: %s\\n\", ptr); return 0;&#125; ###13、strpbrk函数 原型：char *strpbrk(const char *str1, const char *str2) 作用：从str1的第一个字符向后检索，直到’\\0’，如果当前字符存在于str2中，那么返回当前字符的地址，并停止检索. 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;assert.h&gt;char *my_strpbrk(const char *str1, const char *str2)&#123; /***strpbrk()从str1的第一个字符向后检索，直到'\\0'，如果当前字符存在于str2中， 那么返回当前字符的地址，并停止检索***/ assert(str1 != NULL &amp;&amp; str2 != NULL); const char *str3 = str2; while(*str1) //判断石头人字符串str1是否结束 &#123; for(str3 = str2; *str3; ++str3) //str2进行循环与str1的自费比较 &#123; if(*str1 == *str3) //如果相等则进行str1的下一个判断 break; &#125; if(*str3) //如果str3结束则结束比较 break; str1++; &#125; if(*str3 == '\\0') //如果str1到末尾则返回NULL str1 = NULL; return (char*)str1;&#125;int main()&#123; char s1[] = \"http://see.xidian.edu.cn/cpp/u/xitong/\"; char s2[] = \"see\"; char *p = my_strpbrk(s1, s2); if(p) &#123; printf(\"The result is: %s\\n\",p); &#125; else &#123; printf(\"Sorry!\\n\"); &#125; return 0;&#125; ###14、strspn函数 原型：int my_strspn(const char *str1, const char *str2) 作用：从参数str1字符串的开头计算连续的字符,而这些字符都完全是str2所指字符串中的字符。 代码： 123456789101112131415161718192021222324252627282930313233343536#include &lt;assert.h&gt;/***strspn()函数检索区分大小写***/int my_strspn(const char *str1, const char *str2)&#123; /***从参数str1字符串的开头计算连续的字符,而这些字符都完全是str2所指字符串中的字符。 简单的说,若strspn()返回的数值为n,则代表字符串str1开头连续有n个字符都是属于字符串str2内的字符***/ assert(str1 != NULL &amp;&amp; str2 != NULL); const char *tmp = str1; //临时变量存储str1的地址 const char *str3; while(*tmp) &#123; for(str3 = str2; *str3; ++str3) &#123; if(*str3 == *tmp) //判断str1是否存在str2的字符 break; &#125; if(*str3 == '\\0') //如果str2结束则跳出循环str1++ break; tmp++; &#125; return tmp - str1; //返回差值，即str1共有几个连续的字符是str2中存在的&#125;int main()&#123; char s1[] = \"hello world!\"; char s2[] = \"i am lihua\"; int p = my_strspn(s1, s2); printf(\"The result is:%d\\n\", p); return 0;&#125; ###15、strtok函数 原型：char *my_strtok(char *sou, char *delim) 作用：将字符串分割成一个个片段 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/***因strtok函数内部使用了静态指针，因此它不是线程安全的***/static char *olds; //定义全局变量来进行定位char *my_strtok(char *sou, char *delim)&#123; /***strtok函数用来将字符串分割成一个个片段， 在参数sou的字符串中发现到参数delim的分割字符时则会将该字符改为\\0 字符***/ //参数sou指向欲分割的字符串，参数delim为分割字符串 //在第一次调用时，strtok()必需给予参数sou字符串，往后的调用则将参数sou设置成NULL //每次调用成功则返回下一个分割后的字符串指针 char *token = NULL; if(sou == NULL) //如果sou为空则将上一次的位置给sou &#123; sou = olds; &#125; /*将指针移到第一个非delim的位置*/ sou += strspn(sou, delim); if(*sou == '\\0') //如果是结束符，则将结束符保存并退出函数 &#123; olds = sou; return NULL; &#125; /*获取delim的字符在字符串sou中第一次出现的位置*/ token = sou; sou = strpbrk(token, delim); if(sou == NULL) &#123; olds = __rawmemchr (token, '\\0'); //参考http://dev.wikl.net/89401.html &#125; else &#123; *sou = '\\0'; //将分隔符的位置用'\\0'替换 olds = sou + 1; //将olds指向下一次需要操作的位置 &#125; return token;&#125;int main()&#123; //strtok处理的是函数的局部状态信息，所以不能同时解析两个字符串 char sou[100] = \" Micael_SX is so good\"; char *delim = \" \"; char *token; token = my_strtok(sou, delim); while(token != NULL) &#123; printf(\"%s\\n\", token); token = my_strtok(NULL, delim); &#125; return 0;&#125; ###16、strsep函数 原型：char *my_strsep(char **stringp, const char *delim) 作用：将字符串分割成一个个片段 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/***********************************************************a：如果*stringp为NULL，则该函数不进行任何操作，直接返回NULL；b：strsep每次都是从*stringp指向的位置开始搜索，搜索到任一分割字符之后，将其置为’\\0’， 并使*stringp指向它的下一个字符。如果找不到任何分割字符，则将*stringp置为NULL。c：strsep内部没有使用静态指针，因而strsep是线程安全的。d：strsep返回的子串有可能是空字符串，实际上，就是因为strtok无法返回空子串，才引入的strsep函数。 不过strtok符合C89/C99标准，因而移植性更好。但strsep却不是。e: \"二八定律\",即80%情况下分隔符只有一个字节，使用strchr完成,20%情况有多个字节,调用strpbrk完成*************************************************************/char *my_strsep(char **stringp, const char *delim)&#123; /***strsep函数用来将字符串分割成一个个片段***/ char *begin, *end; begin = *stringp; if(begin == NULL) &#123; return NULL; &#125; /*delim分隔符是单个字符的情况是非常频繁的，因此不需要使用代价昂贵的strpbrk函数 而只需要调用strchr就能解决*/ if(delim[0] == '\\0' || delim[1] == '\\0') &#123; char ch = delim[0]; if(ch == '\\0') &#123; end = NULL; &#125; else &#123; if(*begin == ch) &#123; end = begin; &#125; else if(*begin == '\\0') &#123; end = NULL; &#125; else &#123; end = strchr(begin + 1, ch); &#125; &#125; &#125; else &#123; /*delim有两个字符以上,才调用strpbrk*/ end = strpbrk(begin, delim); &#125; if(end) &#123; /*用0封闭这个token；返回stringp，指向一个null指针*/ *end++ = '\\0'; *stringp = end; &#125; else &#123; /*没有出现delim，这是最后一个token*/ *stringp = NULL; &#125; return begin;&#125;int main()&#123; char source[] = \"hello, world! welcome to China!\"; char delim[] = \" ,!\"; char *s = strdup(source); char *token; for(token = my_strsep(&amp;s, delim); token != NULL; token = my_strsep(&amp;s, delim)) &#123; printf(token); printf(\"+\"); &#125; printf(\"\\n\"); return 0;&#125; ###参考文章链接: http://blog.csdn.net/kangroger/article/details/24383571 http://zheng-ji.info/blog/2014/02/05/shen-ru-strtokhan-shu/ http://blog.csdn.net/gqtcgq/article/details/48399957","categories":[{"name":"C","slug":"C","permalink":"http://roux.top/categories/C/"}],"tags":[{"name":"Function","slug":"Function","permalink":"http://roux.top/tags/Function/"}]},{"title":"127.0.0.1和0.0.0.0分析","slug":"127.0.0.1和0.0.0.0","date":"2017-10-12T16:00:00.000Z","updated":"2018-04-22T05:57:45.584Z","comments":true,"path":"2017/10/13/127.0.0.1和0.0.0.0/","link":"","permalink":"http://roux.top/2017/10/13/127.0.0.1和0.0.0.0/","excerpt":"说明： IP地址表示: -IP地址由两个部分组成，net-id和host-id，即网络号和主机号。 net-id:表示ip地址所在的网络号。 host-id：表示ip地址所在网络中的某个主机号码。 -IP-address ::= { &lt;Network-number&gt;, &lt;Host-number&gt; }","text":"说明： IP地址表示: -IP地址由两个部分组成，net-id和host-id，即网络号和主机号。 net-id:表示ip地址所在的网络号。 host-id：表示ip地址所在网络中的某个主机号码。 -IP-address ::= { &lt;Network-number&gt;, &lt;Host-number&gt; } IP地址分类: IP地址一共分为5类，即A～E，它们分类的依据是网络号和主机号，全0和全1的都保留不用。 A类地址：第一个字节为网络号，后三个字节为主机号。该类IP地址的最前面为“0”，所以地址的网络号取值于1~126之间。一般用于大型网络。 B类地址：前两个字节为网络号，后两个字节为主机号。该类IP地址的最前面为“10”，所以地址的网络号取值于128~191之间。一般用于中等规模网络。 C类地址：前三个字节为网络号，最后一个字节为主机号。该类IP地址的最前面为“110”，所以地址的网络号取值于192~223之间。一般用于小型网络。 D类地址：是多播地址。该类IP地址的最前面为“1110”，所以地址的网络号取值于224~239之间。一般用于多路广播用户。 E类地址：是保留地址。该类IP地址的最前面为“1111”，所以地址的网络号取值于240~255之间。其中，ABC三类地址为单播地址（unicast),用于一对一通信，是最常用的。 特殊IP地址: {0,0}:网络号和主机号都全部为0，表示“本网络上的本主机”，只能用作源地址。 {0，host-id}:本网络上的某台主机。只能用作源地址。 {-1,-1}：表示网络号和主机号的所有位上都是1（二进制），用于本网络上的广播，只能用作目的地址，发到该地址的数据包不能转发到源地址所在网络之外。 {net-id,-1}:直接广播到指定网络的所有子网络上。只能用作目的地址。 {net-id,subnet-id,-1}:直接广播到指定网络的指定子网络上。只用作目的地址。 {net-id,-1,-1}:直接广播到指定网络的所有子网络上。只能用作目的地址。 {127，}:即网络号为127的任意ip地址。都是内部主机回环地址(loopback),永远都不能出现在主机外部的网络中。 二、127.0.0.1 127.0.0.1是一个回环地址，这个地址也是给本机loop back接口所预留的IP地址，但是并不表示”本机”。 测试使用： -收到127.0.0.1的响应表示主机的TCP/IP安装成功。-此方法只是测试网络层的ip联通性。此响应来自网络层。-无法测试出具体TCP/IP的配置(地址、掩码、和网关)是否正确，也无法测试出网卡是否正常，因为数据在离开IP层之前就已经被送回去了。 本机进程间的通信： -如apache+php+mysql这样的应用环境，应用程序与mysql数据库同时存在于同一个系统上面，常用环回地址127.0.0.1做套接字的ip地址。-使用环回地址主要的原因是方便和稳定，如：网络接口的地址可能因为某种原因被更改（如服务器搬迁到别的地理位置），或者应用被迁移到另外的系统，导致ip改变，而使用环回地址就不会受ip地址改变的影响。 DDos攻击防御： 网站收到DDos攻击之后，将域名A记录到127.0.0.1，即让攻击者自己攻击自己。 三、0.0.0.0 说明：0.0.0.0表示整个网络(此网络上的此主机的源地址) RFC:0.0.0.0/8 - Addresses in this block refer to source hosts on &quot;this&quot; network. Address 0.0.0.0/32 may be used as a source address for this host on this network; other addresses within 0.0.0.0/8 may be used to refer to specified hosts on this network ([RFC1122], Section 3.2.1.3). 0.0.0.0/8可以表示本网络中的所有主机 0.0.0.0/32可以用作本机的源地址 0.0.0.0/8也可表示本网络上的某个特定主机 注：在路由器配置中可用0.0.0.0/0表示默认路由，作用是帮助路由器发送路由表中无法查询的包。如果设置了全零网络的路由，路由表中无法查询的包都将送到全零网络的路由中去。 作用： 当一台主机还没有被(DHCP)分配一个IP地址的时候，用于表示主机本身。 用作默认路由，表示”任意IPV4主机”。 用来表示目标机器不可用。 用作服务端，表示本机上的任意IPV4地址。 四、总结： 127.0.0.1 是一个环回地址。并不表示“本机”。 0.0.0.0才是真正表示“本网络中的本机”。 一般我们在服务端绑定端口的时候可以选择绑定到0.0.0.0，这样我的服务访问方就可以通过我的多个ip地址访问我的服务(只需要内网访问的服务，可以只绑定内网地址，否则会出现内网能访问，外网不能访问) 五、参考： 链接： https://tools.ietf.org/html/rfc5735#section-3 https://en.wikipedia.org/wiki/0.0.0.0 https://fossbytes.com/ip-address-0-0-0-0-meaning-default-route-uses/ http://baike.baidu.com/item/127.0.0.1 http://www.cnblogs.com/hnrainll/archive/2011/10/13/2210101.html http://blog.onlycatch.com/post/7e371ca28621","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"Others","slug":"Others","permalink":"http://roux.top/tags/Others/"}]},{"title":"Sublime Text3--打造完美的Markdown编辑器","slug":"Markdown编辑器","date":"2017-10-10T16:00:00.000Z","updated":"2018-04-22T05:51:26.330Z","comments":true,"path":"2017/10/11/Markdown编辑器/","link":"","permalink":"http://roux.top/2017/10/11/Markdown编辑器/","excerpt":"前言 注意：由于在前面已经讲过了插件的安装和一些配置、操作等，这里就不在赘述。 不了解的请移步：Sublime Text3–插件安装","text":"前言 注意：由于在前面已经讲过了插件的安装和一些配置、操作等，这里就不在赘述。 不了解的请移步：Sublime Text3–插件安装 所需的插件 Markdown Editing 提供辅助提示，比如输入 ，编辑器应当自动补上一个 ，并使光标保持在两 * 之间， 又比如应当支持选中一段文字快捷键添加链接 Markdown Extended 让 Markdown 格式在 Sublime 中支持高亮 Monokai Extended 提供主题支持 Markdown 的高亮（包括 Markdown 代码块内的代码） MarkdownTOC 编写 heading 较多的长文档，希望能够自动生成目录方便跳转，MarkdownTOC 可以帮助我们实现 Table Editor 键入表格是个体力活，Table Editor 可以帮助我们减轻工作量 OmniMarkupPreviewer 提供了LaTex的数学公式渲染的支持，用浏览器打开以后支持浏览器的实时渲染和更新预览 插件的配置(默认都是在:Setting - User) [MarkdownTOC]: 12345&#123; \"default_autolink\": true, \"default_bracket\": \"round\", \"default_depth\": 0&#125; [OmniMarkupPreviewer] 12345678&#123; \"renderer_options-MarkdownRenderer\": &#123; \"extensions\": [\"tables\", \"fenced_code\", \"codehilite\"], \"parser\": \"markdown\", \"enabled_parsers\": [\"markdown\"] &#125;&#125; 注意：这个插件在配置完成后，有可能会出现无法使用，并且报错： 404错误预览...“buffer_id（29）无效（关闭或不支持的文件格式）”(我就是这个错) 这里给出解决方案(上面的配置文件已经好了)： 如上面的配置去掉了原文件 &quot;extensions&quot;: [&quot;tables&quot;, &quot;strikeout&quot;, &quot;fenced_code&quot;, &quot;codehilite&quot;]的“strikeout” 找到python-markdown Sublime Text3的包。 Mac: subl &quot;/Users/&lt;username&gt;/Library/Application Support/Sublime Text 3/Packages/OmniMarkupPreviewer/OmniMarkupLib/Renderers/libs/mdx_strikeout.py&quot; 用以下makeExtension()方法替换方法：def makeExtension(*args, **kwargs): return StrikeoutExtension(*args, **kwargs) 保存，退出并重新加载升级文本。 链接：https://github.com/timonwong/OmniMarkupPreviewer/issues/85 [OmniMarkupPreviewer]续： 打开OmniMarkupPreviewer的默认配置文件Setting-Default 查看参数：&quot;server_host&quot;: &quot;127.0.0.1&quot;, (开启预览服务的 IP 地址, 默认为 localhost)&quot;html_template_name&quot;: &quot;github&quot;, (预览使用的模板名称，默认为 Github)&quot;browser_command&quot;: [], (预览默认为跟随系统默认浏览器，[“open”, “-a”, “Google Chrome”, “{url}”]亦可利用这样的格式进行指定)&quot;ignored_renderers&quot;: [&quot;LiterateHaskellRenderer&quot;],(忽略/关闭的标记语言渲染器)&quot;mathjax_enabled&quot;: false,(公式的渲染使用了MathJax库，所以需要在OmniMarkupPreviewer的设置中，将”mathjax_enabled”设置为“true”) 快捷键 [MarkdownEditing] Option + Command + K - 插入链接；Option + Command + V - 粘贴为链接格式；Shift + Command + K - 插入图片。 快捷键设定 自己没有其他的快捷键，所以就不写了大家可以自己设定快捷键(自行Google) 参考文章 http://webcache.googleusercontent.com/search?q=cache:http://www.itwendao.com/article/detail/75735.html https://blog.mariusschulz.com/2014/12/16/how-to-set-up-sublime-text-for-a-vastly-better-markdown-writing-experience","categories":[{"name":"Tools","slug":"Tools","permalink":"http://roux.top/categories/Tools/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://roux.top/tags/Markdown/"}]},{"title":"wait函数和waitpid函数","slug":"wait函数","date":"2017-10-10T16:00:00.000Z","updated":"2018-04-22T05:54:17.512Z","comments":true,"path":"2017/10/11/wait函数/","link":"","permalink":"http://roux.top/2017/10/11/wait函数/","excerpt":"僵尸进程 说明 子进程结束但是没有完全释放内存(在内核中的task_struct没有释放)，该进程就会成为僵尸进程 当僵尸进程的父进程结束后就会被init进程(1号进程)接管，最终被回收 僵尸进程的危害 如果你不处理僵尸进程的话，那么保留的那段信息就不会释放，其进程号就会一定被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程","text":"僵尸进程 说明 子进程结束但是没有完全释放内存(在内核中的task_struct没有释放)，该进程就会成为僵尸进程 当僵尸进程的父进程结束后就会被init进程(1号进程)接管，最终被回收 僵尸进程的危害 如果你不处理僵尸进程的话，那么保留的那段信息就不会释放，其进程号就会一定被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程 避免僵尸进程 让僵尸进程的父进程来回收，父进程每隔一段时间来查询子进程是否结束并被回收，调用wait或者waitpid函数，通知内核释放僵尸进程 采用信号SIGCHLD通知处理，并在信号处理程序中调用wait函数 让僵尸进程成为孤儿进程，并有init进程回收 避免僵尸进程方法一说明 头文件 12#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt; 区别 在一个进程终止前，wait 使其调用者阻塞 waitpid 函数有一个选择项，可以使调用者不阻塞 waitpid 等待一个指定的子进程，wait 等待所有的子进程，返回任一子进程的终止状态 参数 status参数 为空时，代表任意状态结束的子进程，若不为空，则代表指定状态结束的子进程 options参数 WNOHANG：若由pid指定的子进程没有退出则立即返回，则waitpid不阻塞，此时返回值为0 WUNTRACED：若某实现支持作业控制，则由pid指定的任一子进程状态已暂停，且其状态自暂停以来还未报告过，则返回其状态 检查 wait 和 waitpid 函数返回终止状态的宏(前面判断，后面获得状态码) WIFEXITED/WEXITSTATUS(status)：若为正常终止子进程的返回的状态，则为真 WIFSIGNALED/WTERMSIG(status)：若为异常终止子进程的返回的状态，则为真(接到一个不能捕捉的信号) WIFSTOPED/WSTOPSIG(status)：若为当前暂停子进程的返回的状态，则为真(如果当前进程在终止前暂停过，则获得暂停的状态码) wait函数 原型： pid_t wait(int *status) 返回：成功返回子进程ID，出错返回-1 作用：等待子进程退出并回收，防止僵尸进程产生 waitpid函数 原型：pid_t waitpid(pid_t pid, int *status, int options) 返回：成功返回子进程ID，出错返回-1 功能：wait函数的非阻塞版本 pid参数： pid == -1：等待任一子进程，与功能 wait 相等 pid &gt; 0：等待其进程ID与 pid 相等的子进程 pid == 0：等待其组ID等于调用进程的组ID的任一子进程 pid &lt; -1：等待其组ID等于 pid 的绝对值的任一子进程 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/wait.h&gt;#include &lt;sys/types.h&gt;void out_status(int status)&#123; if(WIFEXITED(status))&#123; //正常终止 printf(\"normal exit: %d\\n\", WEXITSTATUS(status)); &#125; else if(WIFSIGNALED(status))&#123; //异常终止 printf(\"abnormal term: %d\\n\", WTERMSIG(status)); &#125; else if(WIFSTOPPED(status))&#123; //终止前暂停或者等待过 printf(\"stopped sig: %d\\n\", WSTOPSIG(status)); //kill -19 测试结果 &#125; else&#123; printf(\"unknow sig\\n\"); &#125;&#125;int main(void)&#123; int status; pid_t pid; if((pid = fork()) &lt; 0)&#123; perror(\"fork error\"); exit(1); &#125; else if(pid == 0)&#123; printf(\"pid: %d, ppid: %d\\n\", getpid(), getppid()); exit(3); //子进程终止运行 &#125; //父进程阻塞，等待子进程结束并回收 wait(&amp;status); out_status(status); printf(\"--------------------------\\n\"); if((pid = fork()) &lt; 0)&#123; perror(\"fork error\"); exit(1); &#125; else if(pid == 0)&#123; printf(\"pid: %d, ppid: %d\\n\", getpid(), getppid()); int i = 3, j = 0; int k = i / j; //异常测试 printf(\"k: %d\\n\", k); &#125; wait(&amp;status); out_status(status); printf(\"--------------------------\\n\"); if((pid = fork()) &lt; 0)&#123; perror(\"fork error\"); exit(1); &#125; else if(pid == 0)&#123; printf(\"pid: %d, ppid: %d\\n\", getpid(), getppid()); pause(); //暂停测试 &#125; do&#123; //暂停测试需要用waitpid来捕获暂停的信号，并返回 pid = waitpid(pid, &amp;status, WNOHANG | WUNTRACED); if(pid == 0)&#123; sleep(1); &#125; &#125;while(pid == 0); out_status(status); return 0;&#125; 运行测试 运行程序 发送信号给程序 测试结果","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://roux.top/categories/网络编程/"}],"tags":[{"name":"Function","slug":"Function","permalink":"http://roux.top/tags/Function/"}]},{"title":"解决锐捷校园网环境下VMware虚拟机无法上网问题","slug":"VMware无法上网","date":"2017-10-10T16:00:00.000Z","updated":"2018-04-22T05:48:29.326Z","comments":true,"path":"2017/10/11/VMware无法上网/","link":"","permalink":"http://roux.top/2017/10/11/VMware无法上网/","excerpt":"1.介绍： 在介绍笨方法之前首先得说一下VMware虚拟机无法上网的原因，虚拟机要想要上网主机里的VMnetDHCP和VMware NAT Service就必须要开启，可能很多人都没留意这个问题，因为这两个服务好像装好软件之后是默认开启的，在其他网络环境下虚拟机直接选择NAT方式就可以上网了，所以网上请教很多大牛时他们对我们的虚拟机无法上网感到非常费解呀。 不过在校园网的话，情况又不一样了，我不知道其他的校园网客户端有没有这种情况，可是使用锐捷校园网客户端的话会自动阻断VMware NAT Service服务的开启，也就是说即使你手动开启了VMware NAT Service过了一会又会被自动关闭，这样就导致不管在虚拟机里面怎么设置都无法上网（注意这里使用的NAT方式，或许其他连接方式有新的解决方法，这里只说NAT方式）。","text":"1.介绍： 在介绍笨方法之前首先得说一下VMware虚拟机无法上网的原因，虚拟机要想要上网主机里的VMnetDHCP和VMware NAT Service就必须要开启，可能很多人都没留意这个问题，因为这两个服务好像装好软件之后是默认开启的，在其他网络环境下虚拟机直接选择NAT方式就可以上网了，所以网上请教很多大牛时他们对我们的虚拟机无法上网感到非常费解呀。 不过在校园网的话，情况又不一样了，我不知道其他的校园网客户端有没有这种情况，可是使用锐捷校园网客户端的话会自动阻断VMware NAT Service服务的开启，也就是说即使你手动开启了VMware NAT Service过了一会又会被自动关闭，这样就导致不管在虚拟机里面怎么设置都无法上网（注意这里使用的NAT方式，或许其他连接方式有新的解决方法，这里只说NAT方式）。 如果有人对虚拟机的三种连接方式不是很了解的，可以看看这篇博客: http://blog.csdn.net/collection4u/article/details/14127671 。 那么知道是因为VMware NAT Service服务自动关闭的话解决的方法自然是让其一直打开，（VirtualBox在锐捷下都是可以上网的），最后想到使用windows批处理的方法，这其实真的是一个笨方法来的，只要写一个无限循序语句判断VMware NAT Service服务是否开启，没有开启就打开，一直循环判断，我试了一下效果，这样虚拟机是可以一直上网的，中间的断网也是不到1s，还是可以接受的，聊胜于无啦。 2.笨方法1：(1)新建一个记事本文件，文件名后缀改成:.bat(2)用记事本打开或者其他编辑工具也可以(3)把下面的代码复制进去后保存： 12345678910111213@echo off:firstfor /f &quot;skip=3 tokens=4&quot; %%i in (&apos;sc query &quot;VMware NAT Service&quot;&apos;) do set &quot;zt=%%i&quot; &amp;goto :second:secondif /i &quot;%zt%&quot;==&quot;RUNNING&quot; (echo 该服务已经在运行) else (echo 该服务处于停止状态net start &quot;VMware NAT Service&quot;)ping 127.0.0.1 -n 25&gt;nulgoto :first 注意格式，最好保持相同状态，保存退出。 (4)使用管理员权限打开该文件，然后让其一直运行不要关闭，直到你不使用虚拟机上网为止。(5)注意虚拟机VMware装好之后默认的就是NAT方式上网，打开了这个文件之后虚拟机不用做任何设置，如果你更改过， 请到虚拟机的setting里面把连接方式改回NAT，网上很多关于设置这些的资料，可以去找找。 3.笨办法2:(1)打开任务管理器，找到进程，第一个就是8021.exe然后结束此进程(2)打开VMware NAT Service服务，然后就不用管了，这样就可以直接上网 说明：结束的8021的进程是锐捷客户端的进程，但是不影响锐捷客户端的上网功能，也就是说要不要这个进程都可以。 本内容只针对锐捷校园网下虚拟机无法上网问题、VMware NAT Service自动关闭情况做出的解决方法，有错漏之处或者有更好方法欢迎回复交流，希望以后有大牛可以解决锐捷自动关闭VMware NAT Service的问题笨方法解决锐捷校园网环境下VMware虚拟机无法上网问题（centos试用上网成功） 4.笨办法3：(1)下载安装WinHex(2)修改客户端，把VMware NAT Service改成了MMware NAT Service的(或者你自己认为没用的都可以)， 于是VMware NAT Service服务就不会被禁用了 5.参考文章 说明：本人参考网上的文章，根据自己的经验与探索总结出此文章，内容有原创有转载。 链接：http://blog.sina.com.cn/s/blog_66cd08930102w28v.html#cmt_3092817","categories":[{"name":"Tools","slug":"Tools","permalink":"http://roux.top/categories/Tools/"}],"tags":[{"name":"VMware","slug":"VMware","permalink":"http://roux.top/tags/VMware/"}]},{"title":"TCP三次握手","slug":"TCP三次握手","date":"2017-10-09T16:00:00.000Z","updated":"2018-04-22T05:43:25.261Z","comments":true,"path":"2017/10/10/TCP三次握手/","link":"","permalink":"http://roux.top/2017/10/10/TCP三次握手/","excerpt":"TCP特性 说明： TCP提供一种面向连接的、可靠的字节流服务 在一个TCP连接中，仅有两方进行彼此通信。广播和多播不能用于TCP TCP使用校验和，确认和重传机制来保证可靠传输 TCP给数据分节(给每一个传送的数据字节都编号)进行排序，并使用累积确认保证数据的顺序不变和非重复 TCP使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制 注意： TCP 并不能保证数据一定会被对方接收到，因为这是不可能的。TCP 能够做到的是，如果有可能，就把数据递送到接收方，否则就（通过放弃重传并且中断连接）通知用户。因此准确说 TCP 也不是 100% 可靠的协议，它所能提供的是数据的可靠递送或故障的可靠通知。","text":"TCP特性 说明： TCP提供一种面向连接的、可靠的字节流服务 在一个TCP连接中，仅有两方进行彼此通信。广播和多播不能用于TCP TCP使用校验和，确认和重传机制来保证可靠传输 TCP给数据分节(给每一个传送的数据字节都编号)进行排序，并使用累积确认保证数据的顺序不变和非重复 TCP使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制 注意： TCP 并不能保证数据一定会被对方接收到，因为这是不可能的。TCP 能够做到的是，如果有可能，就把数据递送到接收方，否则就（通过放弃重传并且中断连接）通知用户。因此准确说 TCP 也不是 100% 可靠的协议，它所能提供的是数据的可靠递送或故障的可靠通知。 TCP首部 说明： TCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的、基于字节流的通信协议，数据在传输前要建立连接，传输完毕后还要断开连接。 客户端在收发数据前要使用 connect() 函数和服务器建立连接。建立连接的目的是保证IP地址、端口、物理链路等正确无误，为数据的传输开辟通道。 TCP建立连接时要传输三个数据包，俗称三次握手（Three-way Handshaking）。 解释： 序号：seq（Sequence）序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。 确认序号：ack（Acknowledge）序号，占32位，只有ACK标志位为1时，确认序号字段才有效，ack=seq+1。 标志位：每个标志位占用1Bit，共6个，即URG、ACK、PSH、RST、SYN、FIN等，具体含义如下： URG：紧急指针（urgent pointer）有效。 ACK(Acknowledge)：确认序号有效。 PSH(Push)：接收方应该尽快将这个报文交给应用层。 RST(Reset)：重置连接。 SYN(Synchronous)：发起一个新连接。 FIN(Finish)：释放一个连接。 需要注意的是： 不要将确认序号 ack(表示确认信息)与标志位中的 ACK(为1表示确认有效)搞混了。 确认方 ack等于发起方 seq+1，两端配对。 三次握手 说明： 所谓三次握手(Three-way Handshake)，是指建立一个 TCP 连接时，需要客户端和服务器总共发送3个包。 三次握手的目的是连接服务器指定端口，建立 TCP连接，并同步连接双方的序列号和确认号，交换 TCP窗口大小信息。在 socket 编程中，客户端执行 connect() 时。将触发三次握手。 解释： 第一次握手(SYN=1, seq=x): 客户端发送一个 TCP的 SYN 标志位置1的包，指明客户端打算连接的服务器的端口(请求同步)，并选择序号 seq=x，表明传送数据时的第一个数据字节的序号是 x。(seq是个随机值) 发送完毕后，客户端进入 SYN_SEND 状态。 第二次握手(SYN=1, ACK=1, seq=y, ack=x+1): 服务器的TCP收到连接请求报文段后，如同意，则发回确认包(ACK)应答。即 SYN 标志位和 ACK 标志位均为1。服务器端选择自己 ISN 序列号(随机值y)，放到seq 域里，同时将确认序号ack设置为客户的 ISN 加1，即 x+1(即回复对方确认收到了序列号为x开始的包，且希望下次的数据从x+1的位置开始)。 发送完毕后，服务器端进入 SYN_RCVD 状态。 第三次握手(ACK=1，ack=y+1，seq=x+1) 客户端收到此报文段后再次发送确认包(ACK)，SYN 标志位为0，ACK 标志位为1，并且把服务器发来 ACK 的序号字段+1，放在确定字段ack中发送给对方，并且告诉服务器自己的seq=x+1 发送完毕后，客户端进入 ESTABLISHED 状态，当服务器端接收到这个包时，也进入 ESTABLISHED 状态，TCP握手结束。 问题解决： 为什么初始seq要取随机值呢? 首先这个随机值并不是随机的，而是可以预测的。 其次,它一般基于时钟产生,在rfc793中讲到“The generator is bound to a (possibly fictitious) 32 bit clock whose low order bit is incremented roughly every 4 microseconds.”大概就是每 4ms加1,这样ISN循环一次需要4.55小时,而一个连接中传送的 segment在网络中存在的最大时间小于4.55小时。如我们需要 segment的seq为1,则至少4.55小时前的segment其seq才可能为1,而segment不可能在网络中存在4.55小时,所以如果我们接收到seq为 1 的segment则必然是我们需要的segment(恶意攻击除外^_^)。 这样可以防止上一次连接产生的segment被本次连接错误接收，同时也可以从某种程度上防止其它用户恶意攻击。 为什么要三次握手，而不是两次握手或者四次握手 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误或者说是解决网络中存在延迟的重复分组的问题。 已失效的连接请求报文段的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。 本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。 假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。 因为在上述的三次握手中已经确认并建立了连接，那么就没有必要去进行第四次握手，这样可以节约资源。 补充： 半链接队列 半连接队列： 在三次握手协议中，服务器维护一个半连接队列，该队列为每个客户端的SYN包开设一个条目（服务器端在接收到SYN包时，就已经创建了request_sock结构，存储在半连接队列中），该条目表明服务器已收到SYN 包，并向客户发出确认，正在等待客户的确认包。这些条目所识别的连接在服务器处于SYN_RCVD状态，当服务器收到客户端的确认包时，删除该条目，服务器进入ESTABLISHED状态。 未连接队列的大小为max（64， /proc/sys/net/ipv4/tcp_max_syn_backlog），也就是可以在说未连接队列的大小可以在/proc/sys/net/ipv4/tcp_max_syn_backlog中修改配置，如果服务器经常出现过载，可尝试增加这个数字（tcp_max_syn_backlog）。 半连接（half-open connect）存活时间： 是指半连接队列的条目存活的最大时间，也即服务器端从收到SYN包确认这个报文无效的最长时间，该时间值是所有重传请求包的最长等待时间总和，有时我们也称半连接存活时间为Timeout时间、SYN_RCVD存活时间。 完全连接队列 完全连接队列： 在第三次握手时，当Server接收到ACK报之后，会进入一个新的叫ACCEPT的队列，该队列的长度为min（backlog， /proc/sys/net/core/somaxconn），默认情况下，somaxconn的值为128，表示最多有128个ESTABLISHED的连接等待accept()，而backlog值则是由int listen（int sockfd， int backlog）中的第二个参数指定（指定的backlog与半连接状态的backlog无关系），listen里面的backlog可以由我们的程序去指定。 当服务器绑定、监听某个端口后，这个端口的SYN队列和ACCEPT队列就建立好了。 半连接队列未满但是全连接队列已满： 客户端发出SYN分节，服务器端收下SYN分节并向客户端发送SYN+ACK，客户端收到服务器端SYN+ACK后，成为ESTABLISHED状态，并向服务器端发送第三次握手ACK，服务器端收到ACK后发现全连接队列已满，默认情况下服务器端什么也不做，状态依然是SYN_RCVD，此时ListenOverflows+1， 同时服务器端通过对目录：/proc/sys/net/ipv4/tcp_abort_on_overflow进行修改来决定如何返回，0表示直接丢弃，1表示发送RST通知客户端（ListenOverflows默认为0，当全连接队列超过上限时，ListenOverflow+1），客户端会重传SYN（客户端第一次握手发起的请求）和ACK（客户端第三次握手期间发出的确认），并且内核会限制SYN队列的处理速度，如果在SYN队列中收到太多的SYN，服务器端将会丢弃一些，这样丢弃的SYN对应的客户端需要重发SUN包，当达到一定的阈（yù）值（可以理解为连接被动打开方的确认连接的应答最大重试数，即对于一个新建连接，内核需要发送多少SYN连接请求才决定放弃，阈值可以/proc/sys/net/ipv4/tcp_synack_retries中修改），客户端与服务器断开连接，服务器删除客户端在半连接队列中的SYN分节。 不论全连接满没满，若半连接队列已满： 不开启tcp_syncookies的时候，服务器端会丢弃新来的SYN包，而客户端多次重发SYN包得不到响应而返回超时错误（connection time out）。但是当服务器端开启了tcp_syncookies = 1，那么SYN半连接队列就没有逻辑上的最大值了，并且/proc/sys/net/ipv4/tcp_max_syn_backlog设置的值也会被忽略。 SYN攻击 在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。 SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。 SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了，使用如下命令可以让之现行：#netstat -nap | grep SYN_RECV SYN攻击处理 减少SYN-ACK数据包的重发次数:sysctl -w net.ipv4.tcp_synack_retries=3,sysctl -w net.ipv4.tcp_syn_retries=1 使用SYN cookie技术:sysctl -w net.ipv4.tcp_syncookies=1 增加半连接队列（默认为1024）:sysctl -w net.ipv4.tcp_max_syn_backlog=2048 限制SYN并发数：iptables -A INPUT -p tcp --syn -m limit --limit 1/s -j ACCEPT --limit 1/s","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://roux.top/tags/TCP/"}]},{"title":"TCP四次挥手","slug":"TCP四次挥手","date":"2017-10-09T16:00:00.000Z","updated":"2018-04-22T05:59:21.447Z","comments":true,"path":"2017/10/10/TCP四次挥手/","link":"","permalink":"http://roux.top/2017/10/10/TCP四次挥手/","excerpt":"前言 关于 TCP 三握手以及后面文章用到的东西可以查看我的这篇博文:三次握手 四次挥手 所谓四次挥手（Four-Way Wavehand）即终止 TCP 连接，就是指数据传送完毕需要断开一个 TCP 连接时，需要客户端和服务端总共发送 4 个包以确认连接的断开。在 socket 编程中，这一过程由客户端或服务端任一方执行close来触发，整个流程如下图所示： 由于 TCP 连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个FIN只意味着这一方向上没有数据流动，一个 TCP 连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。","text":"前言 关于 TCP 三握手以及后面文章用到的东西可以查看我的这篇博文:三次握手 四次挥手 所谓四次挥手（Four-Way Wavehand）即终止 TCP 连接，就是指数据传送完毕需要断开一个 TCP 连接时，需要客户端和服务端总共发送 4 个包以确认连接的断开。在 socket 编程中，这一过程由客户端或服务端任一方执行close来触发，整个流程如下图所示： 由于 TCP 连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个FIN只意味着这一方向上没有数据流动，一个 TCP 连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。 第一次挥手(FIN=1，seq=u) 假设客户端想要关闭连接，客户端发送一个FIN标志位置为 1 的包，表示自己已经没有数据可以发送了，但是仍然可以接受数据。因为有可能服务器还要发送数据，所以发送自己的序列号seq=u，等待服务器确认。 发送完毕后，客户端进入FIN_WAIT_1状态。 第二次挥手(ACK=1，seq=v，ack=u+1) 服务器端确认客户端的FIN包，发送一个确认包(ACK=1(确认)，seq=v(自己的序列号)，ack=u+1(确认收到序列号u以前的包，并希望下次发送数据从 u+1 开始))，表明自己接受到了客户端关闭连接的请求，但还没有准备好关闭连接(可能有数据发送)。 发送完毕后，服务器端进入CLOSE_WAIT状态，客户端接收到这个确认包之后，进入FIN_WAIT_2状态，等待服务器端关闭连接。 在这过程中 TCP 服务器进程会通知高层应用进程。然后从客户端到服务器这个方向的连接就释放了，TCP 连接处于半关闭状态。但是服务器若发送数据，客户端仍要接收。 第三次挥手(FIN=1，ACK=1，seq=w，ack=u+1) 若服务器已经没有要向客户端发送的数据，其应用进程就通知 TCP 释放连接。 服务器端准备好关闭连接时，向客户端发送结束连接请求FIN置为 1，ACK=1，seq=w(有数据发送过)，ack=u+1。 发送完毕后，服务器端进入LAST_ACK状态，等待来自客户端的最后一个ACK。 第四次挥手(ACK=1，seq=u+1，ack=w+1) 客户端接收到来自服务器端的关闭请求，发送一个确认包(在确认报文段中ACK=1，确认号ack=w+1，自己的序号seq=u+1)，并进入TIME_WAIT状态，等待可能出现的要求重传的ACK包。(这个确认包是内核进行发送的，上面不能发数据的是客户端的send函数) 服务器端接收到这个确认包之后，关闭连接，进入CLOSED状态。 客户端等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime）之后，没有收到服务器端的ACK，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入CLOSED状态。 问题 为什么关闭的时候是四次握手？ 当关闭连接时，服务器端收到了客户端的FIN报文通知，这仅仅表示客户端没有数据发送给服务器端了，我们知道 TCP 是全双工通信，所以未必服务器端的全部数据发送给了客户端，所以服务器端未必会马上关闭 socket ，也许服务器端还需要发送一些数据给客户端之后，再发送FIN报文给客户端，表示同意现在关闭连接，所以服务器端的ACK报文和FIN报文大多数情况下都是分开发送的。 由于网络服务的不可靠性，必须考虑到在释放连接时，可能由于数据包的失序而使释放连接请求的数据包会比其他数据包先到达目的端。此时，如果目的端由于收到了释放连接请求的数据包而立即释放该连接，则会造成那些先发而后至的数据包丢失。 TIME_WAIT存在的理由 可靠的实现TCP全双工链接的终止。 虽然双方都同意关闭连接了，而且握手的4个报文也都协调和发送完毕，按理可以直接回到CLOSED状态（就好比从SYN_SEND状态到ESTABLISH状态那样）；但是因为我们必须要假想网络是不可靠的，你无法保证你最后发送的ACK报文会一定被对方收到，因此对方处于LAST_ACK状态下的SOCKET可能会因为超时未收到ACK报文，而重发FIN报文，所以这个TIME_WAIT状态的作用就是用来重发可能丢失的ACK报文。 如果客户端不维护这个状态信息，服务器将响应一个以RST(另一种类型的 TCP 分节)，该分节将被解释为一个错误。如果TCP想要执行所有必要的工作以彻底终止某个连接上的两个方向上的数据流(全双工关闭)，那它必须正确处理连接终止序列 4 个分节中任何一个分节丢失的情况。 允许老的重复的分节在网络中消逝。 假设在12.106.32.254的 1500 端口和206.168.211.219的 21 端口之间有一个 TCP 连接。我们关闭这个链接，过一段时间后在 相同的 IP 地址和端口建立另一个连接。后一个链接成为前一个的化身。因为它们的 IP 地址和端口号都相同。TCP 必须防止来自某一个连接的老的重复分组在连接已经终止后再现，从而被误解成属于同一链接的某一个某一个新的化身。 为做到上面一点，TCP将不给处于TIME_WAIT状态的链接发起新的化身。既然TIME_WAIT状态的持续时间是MSL的 2倍，这就足以让某个方向上的分组最多存活MSL秒即被丢弃，另一个方向上的应答最多存活MSL秒也被丢弃。 通过实施这个规则，我们就能保证每成功建立一个TCP连接时，来自该链接先前化身的重复分组都已经在网络中消逝了。 为什么在第三次挥手时需要发送ack和seq 因为 TCP 是可靠的全双工传输，所以需要确保客户端的链接关闭正确，并且防止传送的数据包在网络中延迟出现的错误，如果后面又使用同样的端口建立了一个 TCP 链接而且现在要释放(完成了两次挥手)，刚才延迟的包现在到了，这时也许服务器还有数据要发送，但是客户端收到延迟的包，就直接确认返回ACK，从而出现非正常关闭。 为什么在第四次挥手的时候还需要发送ack和seq 因为 TCP 是可靠的全双工传输，所以需要确保客户端连接建立和关闭的正确，并且防止传送的数据包在网络中延迟出现的错误，如果后面又使用同样的端口要建立一个 TCP 链接(完成了两次握手)，刚才释放的确认的延迟的包现在到了，但是服务器收到延迟的包，就以为连接已经建立成功，如果这个时候客户端退出或者服务器需要先发数据，就会出现客户端没有建立成功连接但是服务器认为连接建立成功的错误。 TIME_WAIT状态所带来的影响 当某个连接的一端处于TIME_WAIT状态时，该连接将不能再被使用。事实上，对于我们比较有现实意义的是，这个端口将不能再被使用。 某个端口处于TIME_WAIT状态(其实应该是这个连接)时，这意味着这个 TCP 连接并没有断开(完全断开)，那么，如果你bind这个端口，就会失败。对于服务器而言，如果服务器突然坏掉了，那么它将无法再2MSL内重新启动，因为bind会失败。 解决这个问题的一个方法就是设置 socket 的SO_REUSEADDR选项。这个选项意味着你可以重用一个地址。 细节 默认情况下(不改变 socket 选项)，当你调用 close ( or closesocket，以下说 close 不再重复)时，如果发送缓冲中还有数据，TCP会继续把数据发送完。 发送了FIN只是表示这端不能继续发送数据(应用层不能再调用send发送)，但是还可以接收数据。 应用层如何知道对端关闭？通常，在最简单的阻塞模型中，当你调用recv时，如果返回 0，则表示对端关闭。在这个时候通常的做法就是也调用close，那么 TCP 层就发送FIN，继续完成四次握手。如果你不调用close，那么对端就会处于FIN_WAIT_2状态，而本端则会处于CLOSE_WAIT状态。 在很多时候，TCP连接的断开都会由TCP层自动进行，例如你CTRL+C终止你的程序，TCP连接依然会正常关闭。 当 TCP 连接发生一些物理上的意外情况时，例如网线断开，linux 上的 TCP 实现会依然认为该连接有效，而 windows 则会在一定时间后返回错误信息。 补充 2MSL MSL(Maximum Segment Lifetime)，也就是报文最大生存时间，引用《TCP/IP详解》中的话：“它(MSL)是任何报文段被丢弃前在网络内的最长时间。”那么，2MSL也就是这个时间的 2 倍。RFC 1122建议 MSL 的值为 2 分钟，不过源自Berkeley的实现传统上改用30秒这个值。(也就是说TIME_WAIT状态的持续时间在1-4分钟之间。) TTL TTL是网络数据包为了防止数据包在网络中无限循环，而设定的网络数据包在网络传输中的最大的转发次数，因为每转发一次在路由器，就会转向下一跳，通常称为最大跳数。 具体含义即就是：我们本地机器发出一个数据包，数据包经一定数量路由器后传送到目的主机，但由于多种原因，一些数据包不能正常传送到目的主机，那如果不给这些数据包一个生存时间的话，这些数据包就会在网络上不断的传送，导致网络开销的增大。当数据包传送到一个路由器之后，TTL就自动减 1，如果减到 0 了还没有传送到目的主机，那么数据就会自动消失，发送数据的一方则请求超时。 TTL的各个系统的默认值可以参考：TTL默认值 TCP的有限状态机 解释： TCP 有限状态机的图中每一个方框都是 TCP 可能具有的状态。 每个方框中的大写英文字符串是 TCP 标准所使用的 TCP 连接状态名。状态之间的箭头表示可能发生的状态变迁。 箭头旁边的字，表明引起这种变迁的原因，或表明发生状态变迁后又出现什么动作。 图中有三种不同的箭头。 粗实线箭头表示对客户进程的正常变迁。 粗虚线箭头表示对服务器进程的正常变迁。 另一种细线箭头表示异常变迁。 参考 链接：http://www.cnblogs.com/renyuan/p/3431022.html 链接：http://www.cnblogs.com/zmlctt/p/3690998.html 链接：http://blog.csdn.net/gc348342215/article/details/70230537 《UNIX网络编程卷1》 《计算机网络》(谢希仁)","categories":[{"name":"Protocol","slug":"Protocol","permalink":"http://roux.top/categories/Protocol/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://roux.top/tags/TCP/"}]},{"title":"从Google Chrome中删除“由企业策略安装的”扩展名","slug":"Chrome企业策略安装","date":"2017-10-08T16:00:00.000Z","updated":"2018-05-18T10:47:46.166Z","comments":true,"path":"2017/10/09/Chrome企业策略安装/","link":"","permalink":"http://roux.top/2017/10/09/Chrome企业策略安装/","excerpt":"前言 今天不小心点开了一个垃圾程序，然后就给我的Google Chrome安装了两个插件，其中一个是Cookies On-Off本来说手动删除就可以了，谁知道竟然显示是“企业策略安装”，无法删除。只能上网搜索，最终在国外的网站找到了解决方法：","text":"前言 今天不小心点开了一个垃圾程序，然后就给我的Google Chrome安装了两个插件，其中一个是Cookies On-Off本来说手动删除就可以了，谁知道竟然显示是“企业策略安装”，无法删除。只能上网搜索，最终在国外的网站找到了解决方法： 方法 通过（Win + R）打开中 windows 的运行框，然后输入cmd命令，进入终端模式 在命令提示符下键入（或复制/粘贴）以下命令： rd /S /Q &quot;%WinDir%\\System32\\GroupPolicyUsers&quot;按回车。 rd /S /Q &quot;%WinDir%\\System32\\GroupPolicy&quot;按回车。 gpupdate /force按回车。 运行命令后，应该会看到以下通知： 用户策略更新已成功完成。 计算机策略更新已成功完成 总结 平常注意，不要裸机运行 要学会解决问题，平常小心防范各种木马 这里只给出了一种方法，还有另外的方法参考下面的链接(如果打不开，证明被墙了) ，链接点我","categories":[{"name":"Tools","slug":"Tools","permalink":"http://roux.top/categories/Tools/"}],"tags":[{"name":"Chrome","slug":"Chrome","permalink":"http://roux.top/tags/Chrome/"}]}]}